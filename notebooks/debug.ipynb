{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm25_v2 import BM25Searcher\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import get_combined_df, Args\n",
    "from eval import SearchEvaluator, ModelEvaluator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"data/2_7/facebook_react\"\n",
    "repo_name = data_path.split(\"/\")[-1]\n",
    "combined_df = get_combined_df(data_path)\n",
    "index_path=f\"{data_path}/index_commit_tokenized\"\n",
    "# REPO_DIR = '/home/ssg2/ssg2/ds/repos/facebook_react'\n",
    "k=1000 # initial ranker depth\n",
    "n=100 # number of samples to evaluate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fid_to_path and path_to_fid json files to dicts\n",
    "with open(f\"facebook_react_FID_to_paths.json\") as f:\n",
    "    fid_to_path = json.load(f)\n",
    "\n",
    "# make all fids ints\n",
    "fid_to_path = {int(k): v for k, v in fid_to_path.items()}\n",
    "\n",
    "with open(f\"facebook_react_path_to_FID.json\") as f:\n",
    "    path_to_fid = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at data/2_7/facebook_react/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['MAP', 'P@1', 'P@10', 'P@20', 'P@30', 'MRR', 'R@1', 'R@10', 'R@100', 'R@1000']\n",
    "bm25_searcher = BM25Searcher(index_path, fid_to_path, path_to_fid)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df, fid_to_path, path_to_fid)\n",
    "gold_df = pd.read_parquet(f\"gold/{repo_name}/v2_{repo_name}_gpt4_gold.parquet\")\n",
    "#! rename commit_message to original_message\n",
    "gold_df = gold_df.rename(columns={'commit_message': 'original_message'})\n",
    "#!rename transformed_message to commit_message\n",
    "gold_df = gold_df.rename(columns={f'transformed_message_gpt4': 'commit_message'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Input properties 'value' and 'defaultValue' accepting and assigning functions and symbols leads to improper handling and inconsistencies in numeric equality checks.\",\n",
       " array(['packages/react-dom/src/__tests__/ReactDOMInput-test.js',\n",
       "        'packages/react-dom/src/client/ReactDOMFiberInput.js',\n",
       "        'packages/react-dom/src/events/ChangeEventPlugin.js',\n",
       "        'packages/react-dom/src/shared/DOMProperty.js'], dtype=object),\n",
       " [2869, 2717, 2752, 2780])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id, test_date, test_orig, test_files, test_query = gold_df.iloc[6]\n",
    "test_files_ids = [path_to_fid[f] for f in test_files]\n",
    "test_query, test_files, test_files_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = bm25_searcher.search(test_query, test_date, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results = bm25_searcher.aggregate_file_scores(bm25_results, 'sump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure why this file doesn't exist\n",
    "# path_to_fid['packages/react/src/ReactServerSharedInternals.js']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Input properties 'value' and 'defaultValue' accepting and assigning functions and symbols leads to improper handling and inconsistencies in numeric equality checks.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Use defaultValue instead of setAttribute('value') (#11534)\\n\\n* Use defaultValue instead of setAttribute('value')\\n\\nThis commit replaces the method of synchronizing an input's value\\nattribute from using setAttribute to assigning defaultValue. This has\\nseveral benefits:\\n\\n- Fixes issue where IE10+ and Edge password icon disappears (#7328)\\n- Fixes issue where toggling input types hides display value on dates\\n  in Safari (unreported)\\n- Removes mutationMethod behaviors from DOMPropertyOperations\\n\\n* initialValue in Input wrapperState is always a string\\n\\n* The value property is assigned before the value attribute. Fix related tests.\\n\\n* Remove initial value tests in ReactDOMInput\\n\\nI added these tests after removing the `value` mutation\\nmethod. However they do not add any additional value over existing\\ntests.\\n\\n* Improve clarity of value checks in ReactDOMInput.postMountWrapper\\n\\n* Remove value and defaultValue from InputWithWrapperState type\\n\\nThey are already included in the type definition for HTMLInputElement\\n\\n* Inline stringification of value in ReactDOMInput\\n\\nAvoids eagier stringification and makes usage more consistent.\\n\\n* Use consistent value/defaultValue presence in postMountHook\\n\\nOther methods in ReactDOMInput check for null instead of\\nhasOwnProperty.\\n\\n* Add missing semicolon\\n\\n* Remove unused value argument in ReactDOMInput test\\n\\n* Address cases where a value switches to undefined\\n\\nWhen a controlled input value switches to undefined, it reverts back\\nto the initial state of the controlled input.\\n\\nWe didn't have test coverage for this case, so I've added two describe\\nblocks to cover both null and undefined.\\n\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_results[0].contributing_results[0].commit_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.54,\n",
       " 'P@1': 1.0,\n",
       " 'P@10': 0.2,\n",
       " 'P@20': 0.1,\n",
       " 'P@30': 0.0667,\n",
       " 'MRR': 1.0,\n",
       " 'R@1': 0.25,\n",
       " 'R@10': 0.5,\n",
       " 'R@100': 1.0,\n",
       " 'R@1000': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(aggregated_results, test_files_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'microsoft/codebert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = test_query\n",
    "text2 = aggregated_results[0].contributing_results[0].commit_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text1, text2, return_tensors=\"pt\", padding=True, truncation='only_second', max_length=tokenizer.model_max_length, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5136816501617432"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "inputs.to('cuda')\n",
    "# Predict with model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Assuming the model has been fine-tuned for regression task\n",
    "# Convert logits to similarity score (sigmoid function to get value between 0 and 1)\n",
    "\n",
    "# get the similarity score\n",
    "similarity_score = torch.softmax(outputs.logits.squeeze(), dim=0)[1].item()\n",
    "model.train()\n",
    "similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe of (txt1, tx2, 1) repeating for 100 rows\n",
    "# train_df = pd.DataFrame({'txt1': [text1]*100, 'txt2': [text2]*100, 'label': [1]*100})\n",
    "train_df = pd.read_pickle('data/2_7/facebook_react/cache/triplet_data_cache.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repo_paths = [\n",
    "    \"data/2_7/apache_spark\",\n",
    "    \"data/2_7/apache_kafka\",\n",
    "    \"data/2_7/facebook_react\",\n",
    "    \"data/2_8/angular_angular\",\n",
    "    \"data/2_8/django_django\",\n",
    "    \"data/2_8/pytorch_pytorch\",\n",
    "    \"data/2_7/julialang_julia\",\n",
    "    \"data/2_7/ruby_ruby\",\n",
    "    \"data/2_9/huggingface_transformers\",\n",
    "    \"data/2_9/redis_redis\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_triplet_data = pd.DataFrame()\n",
    "for data_path in tqdm(repo_paths, total=len(repo_paths)):\n",
    "    triplet_cache = os.path.join(data_path, 'cache', 'gpt_triplet_data_cache.pkl')\n",
    "    if os.path.exists(triplet_cache):\n",
    "        repo_triplet_data = pd.read_pickle(triplet_cache)\n",
    "        combined_triplet_data = pd.concat([combined_triplet_data, repo_triplet_data], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Warning: Triplet cache not found for {data_path}, skipping this repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = combined_triplet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example['query'], example['passage'], return_tensors=\"pt\", padding=True, truncation='only_second', max_length=tokenizer.model_max_length, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3cdc47594b420b881fc6bb477bf74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d729fa5d682b4403a1adb0121e5e7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.map(lambda examples: {'labels': examples['label']}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./tmp',          # output directory for model checkpoints\n",
    "    evaluation_strategy=\"no\",     # evaluation is done at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    weight_decay=0.01,               # strength of weight decay,\n",
    "    report_to='none',\n",
    "    fp16=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'passage', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 74385\n",
       "})"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=bert_reranker.model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9299' max='9299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9299/9299 24:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.588900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.536600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.482200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.446200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9299, training_loss=0.4829821280477277, metrics={'train_runtime': 1465.3526, 'train_samples_per_second': 50.763, 'train_steps_per_second': 6.346, 'total_flos': 1.95715158529536e+16, 'train_loss': 0.4829821280477277, 'epoch': 1.0})"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='data/2_7/facebook_react/index_commit_tokenized',\n",
    "    repo_path='data/2_7/facebook_react', k=10000, n=100,\n",
    "    model_path='microsoft/codebert-base', overwrite_cache=False,\n",
    "    batch_size=32, num_epochs=3, learning_rate=2e-05,\n",
    "    run_name='debug',\n",
    "    notes='debug (ignore)',\n",
    "    num_positives=10, num_negatives=10, train_depth=10000, num_workers=8,\n",
    "    train_commits=1000, psg_cnt=25, use_gpu=True,\n",
    "    rerank_depth=250, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4',\n",
    "    overwrite_eval=False, sanity_check=True, debug=False,\n",
    "    psg_len=350, psg_stride=250, ignore_gold_in_training=False,\n",
    "    eval_folder='debug', use_gpt_train=True,\n",
    "    aggregation_strategy='sump',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'microsoft/codebert-base',\n",
       " 'psg_cnt': 5,\n",
       " 'aggregation_strategy': 'sump',\n",
       " 'batch_size': 32,\n",
       " 'use_gpu': True,\n",
       " 'rerank_depth': 250,\n",
       " 'num_epochs': 3,\n",
       " 'lr': 2e-05,\n",
       " 'num_positives': 10,\n",
       " 'num_negatives': 10,\n",
       " 'train_depth': 10000,\n",
       " 'num_workers': 8,\n",
       " 'train_commits': 1000,\n",
       " 'bm25_aggr_strategy': 'maxp',\n",
       " 'output_length': 1000}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': 5,\n",
    "        'aggregation_strategy': 'sump',\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': 250,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'maxp',\n",
    "        'output_length': 1000\n",
    "    }\n",
    "bert_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BERTReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 5383.44 MB\n",
      "Using classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 5, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 250, 'num_epochs': 3, 'lr': 2e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 10000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'maxp', 'output_length': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_reranker = BERTReranker(bert_params, 'classification')\n",
    "bert_reranker.model.to(bert_reranker.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bert_reranker.rerank_pipeline(test_query, aggregated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.6771,\n",
       " 'P@1': 1.0,\n",
       " 'P@10': 0.3,\n",
       " 'P@20': 0.2,\n",
       " 'P@30': 0.1333,\n",
       " 'MRR': 1.0,\n",
       " 'R@1': 0.25,\n",
       " 'R@10': 0.75,\n",
       " 'R@100': 1.0,\n",
       " 'R@1000': 1.0}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(tmp, test_files_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25\n",
    "{'MAP': 0.54,\n",
    " 'P@1': 1.0,\n",
    " 'P@10': 0.2,\n",
    " 'P@20': 0.1,\n",
    " 'P@30': 0.0667,\n",
    " 'MRR': 1.0,\n",
    " 'R@1': 0.25,\n",
    " 'R@10': 0.5,\n",
    " 'R@100': 1.0,\n",
    " 'R@1000': 1.0}\n",
    "\n",
    "\n",
    "# bert without training\n",
    "{'MAP': 0.2716,\n",
    " 'P@1': 0.0,\n",
    " 'P@10': 0.2,\n",
    " 'P@20': 0.1,\n",
    " 'P@30': 0.0667,\n",
    " 'MRR': 0.5,\n",
    " 'R@1': 0.0,\n",
    " 'R@10': 0.5,\n",
    " 'R@100': 0.75,\n",
    " 'R@1000': 1.0}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
