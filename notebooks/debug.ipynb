{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils import get_combined_df, prepare_code_triplets, full_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bm25_v2 import BM25Searcher\n",
    "from eval import ModelEvaluator, SearchEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('../data/2_7/facebook_react/cache/4X_random_split/code_df.parquet').train_commit_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../data/2_7/facebook_react/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='../data/2_7/facebook_react/index_commit_tokenized', repo_path='../data/2_7/facebook_react', k=1000, n=100, model_path='microsoft/codebert-base', overwrite_cache=False, batch_size=32, num_epochs=10, learning_rate=5e-05, run_name='repr_0.1663', notes='reproducing current best 0.1663 MAP result for CodeReranker', num_positives=10, num_negatives=10, train_depth=1000, num_workers=8, train_commits=1000, psg_cnt=25, aggregation_strategy='sump', use_gpu=True, rerank_depth=100, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4', overwrite_eval=False, sanity_check=True, debug=False, best_model_path=None, bert_best_model='data/combined_commit_train/best_model', psg_len=350, psg_stride=250, ignore_gold_in_training=False, eval_folder='repr_0.1663', use_gpt_train=True\n",
    ")\n",
    "\n",
    "metrics =['MAP', 'P@1', 'P@10', 'P@20', 'P@30', 'MRR', 'R@1', 'R@10', 'R@100', 'R@1000']\n",
    "repo_path = args.repo_path\n",
    "repo_name = repo_path.split('/')[-1]\n",
    "index_path = args.index_path\n",
    "K = args.k\n",
    "n = args.n\n",
    "combined_df = get_combined_df(repo_path)\n",
    "BM25_AGGR_STRAT = 'sump'\n",
    "eval_path = os.path.join(repo_path, 'eval')\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "bm25_searcher = BM25Searcher(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "\n",
    "test_path = os.path.join('..', 'gold', 'facebook_react', 'v2_facebook_react_gpt4_gold.parquet')\n",
    "gold_df = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = os.path.join(args.repo_path, 'cache', 'X_diff_split')\n",
    "code_df = pd.read_parquet('../data/2_7/facebook_react/cache/repr_0.1663/code_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prep_line(line):\n",
    "    return line.rstrip().lstrip()\n",
    "\n",
    "def parse_diff_remove_minus(diff):\n",
    "    return [\n",
    "        line[1:] if line.startswith('+') else line\n",
    "        for line in diff.split('\\n')\n",
    "        if not (line.startswith('-') or len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "        and len(prep_line(line)) > 2\n",
    "    ]\n",
    "\n",
    "def full_parse_diffs(diff):\n",
    "   # keep both insertions and deletions to be passed to the model\n",
    "    return [\n",
    "        line[1:] if (line.startswith('+') or line.startswith('-')) else line\n",
    "        for line in diff.split('\\n')\n",
    "        if not (len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "    ]\n",
    "\n",
    "def full_parse_diffs_split(diff):\n",
    "   # keep both insertions and deletions to be passed to the model\n",
    "    res = []\n",
    "    cur = []\n",
    "    for line in diff.split('\\n'):\n",
    "        if not len(line) == 0:\n",
    "            if (line.startswith('@@') and line.count('@@') > 1):\n",
    "                if cur:\n",
    "                    res.append(cur)\n",
    "                cur = []\n",
    "            else:\n",
    "                cur.append(line[1:] if (line.startswith('+') or line.startswith('-')) else line)\n",
    "    if cur:\n",
    "        res.append(cur)\n",
    "    return res\n",
    "\n",
    "def full_tokenize(s, tokenizer):\n",
    "        return tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_tokens(diff):\n",
    "    ntokens = len(full_tokenize(diff, tokenizer))\n",
    "    return ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_df = pd.read_parquet('../data/merged_code_df/multi_code_df.parquet')\n",
    "# code_df.train_commit_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61173/61173 [02:48<00:00, 362.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95828835, 1598.1594176311664)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average token in each diff (only insertions)\n",
    "total_rows = 0\n",
    "total_diff_tokens = 0\n",
    "for i, row in tqdm(code_df.iterrows(), total=code_df.shape[0]):\n",
    "    diff = row.SR_diff\n",
    "    if diff or not pd.isna(diff):\n",
    "        total_diff_tokens += find_diff_tokens(diff)\n",
    "        total_rows += 1\n",
    "\n",
    "total_diff_tokens, total_diff_tokens / total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61173/61173 [02:46<00:00, 367.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(85946036, 326.5960472265606)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of tokens in each diff split\n",
    "total_diff_splits = 0\n",
    "total_diff_split_tokens = 0\n",
    "for i, row in tqdm(code_df.iterrows(), total=code_df.shape[0]):\n",
    "    diff = row.SR_diff\n",
    "    if diff or not pd.isna(diff):\n",
    "        diff_split_list = full_parse_diffs_split(diff)\n",
    "        total_diff_splits += len(diff_split_list)\n",
    "        for diff_split in diff_split_list:\n",
    "            total_diff_split_tokens += find_diff_tokens('\\n'.join(diff_split))\n",
    "\n",
    "total_diff_split_tokens, total_diff_split_tokens/total_diff_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.388729528701511"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average splits per diff (number of @@ -- @@ changes)\n",
    "# so this will be number of distinct places where the file is edited\n",
    "total_diff_splits / total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing code triplets with mode diff_subsplit for 6631 rows.\n",
      "Preparing triplets split by diff content (further subplit at @@)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6631/6631 [00:00<00:00, 7136.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               query  \\\n",
      "0  Malformed data types (`commitDetails`, `intera...   \n",
      "1  Malformed data types (`commitDetails`, `intera...   \n",
      "2  Malformed data types (`commitDetails`, `intera...   \n",
      "3  Malformed data types (`commitDetails`, `intera...   \n",
      "4  Malformed data types (`commitDetails`, `intera...   \n",
      "\n",
      "                                           file_path  \\\n",
      "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
      "1  packages/react-reconciler/src/ReactFiberSchedu...   \n",
      "2  packages/react-reconciler/src/ReactFiberSchedu...   \n",
      "3  packages/react-reconciler/src/ReactFiberSchedu...   \n",
      "4  packages/react-reconciler/src/ReactFiberSchedu...   \n",
      "\n",
      "                                             passage  label  \n",
      "0       firstBatch._defer &&\\n     firstBatch._ex...      0  \n",
      "1   }\\n \\n function prepareFreshStack(root, expir...      0  \n",
      "2       return null;\\n   }\\n \\n  if (root.pending...      0  \n",
      "3     // something suspended, wait to commit it a...      0  \n",
      "4         }\\n       // If we're already rendering...      0  \n"
     ]
    }
   ],
   "source": [
    "# triplets_df = pd.read_parquet(os.path.join(cache_path, 'diff_code_triplets.parquet'))\n",
    "triplets_df = prepare_code_triplets(code_df, args, mode='diff_subsplit', cache_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31734 entries, 0 to 31733\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   query      31734 non-null  object\n",
      " 1   file_path  31734 non-null  object\n",
      " 2   passage    31734 non-null  object\n",
      " 3   label      31734 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 991.8+ KB\n"
     ]
    }
   ],
   "source": [
    "triplets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting average query and passage length from the CodeSearchNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_string = '''def get_vid_from_url(url):\n",
    "        \"\"\"Extracts video ID from URL.\n",
    "        \"\"\"\n",
    "        return match1(url, r'youtu\\.be/([^?/]+)') or \\\n",
    "          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\n",
    "          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\n",
    "          match1(url, r'youtube\\.com/watch/([^/?]+)') or \\\n",
    "          parse_query_param(url, 'v') or \\\n",
    "          parse_query_param(parse_query_param(url, 'u'), 'v')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([tokenizer.decode(i) for i in full_tokenize(code_string, tokenizer)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Their notebook](https://github.com/github/CodeSearchNet/blob/master/notebooks/ExploreData.ipynb), which uses the tree-sitter tokenizer has ~52 tokens. So codebert's tokenizer is approx 4x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e1738a679548d284e87119bcb80b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275a1e9efaa94befab5699b95c8d409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7955452a8507412ba54d761081cba88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/488M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bddcdf36aff47a887058298cbb8a9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/112M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877d4344bffc474b8fb6128046c63b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/852M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5499bc678964fde91b522a9a0e9857a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17db926b12844a7ae68d0abf1cd7005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94ed79ef3649e6a5f872365ed7b84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1880853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4b04f389504680a0e4e7e99f0befdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100529 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30b1930c3f14a8d8339302ecc0f8392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/89154 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"code_search_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csn_df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1880853"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_ROWS = csn_df.shape[0]\n",
    "TOTAL_ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository_name</th>\n",
       "      <th>func_path_in_repository</th>\n",
       "      <th>func_name</th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>language</th>\n",
       "      <th>func_code_string</th>\n",
       "      <th>func_code_tokens</th>\n",
       "      <th>func_documentation_string</th>\n",
       "      <th>func_documentation_tokens</th>\n",
       "      <th>split_name</th>\n",
       "      <th>func_code_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mjirik/imcut</td>\n",
       "      <td>imcut/pycut.py</td>\n",
       "      <td>ImageGraphCut.__msgc_step3_discontinuity_local...</td>\n",
       "      <td>def __msgc_step3_discontinuity_localization(se...</td>\n",
       "      <td>python</td>\n",
       "      <td>def __msgc_step3_discontinuity_localization(se...</td>\n",
       "      <td>[def, __msgc_step3_discontinuity_localization,...</td>\n",
       "      <td>Estimate discontinuity in basis of low resolut...</td>\n",
       "      <td>[Estimate, discontinuity, in, basis, of, low, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/mjirik/imcut/blob/1b38e7cd1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mjirik/imcut</td>\n",
       "      <td>imcut/pycut.py</td>\n",
       "      <td>ImageGraphCut.__multiscale_gc_lo2hi_run</td>\n",
       "      <td>def __multiscale_gc_lo2hi_run(self):  # , pyed...</td>\n",
       "      <td>python</td>\n",
       "      <td>def __multiscale_gc_lo2hi_run(self):  # , pyed...</td>\n",
       "      <td>[def, __multiscale_gc_lo2hi_run, (, self, ), :...</td>\n",
       "      <td>Run Graph-Cut segmentation with refinement of ...</td>\n",
       "      <td>[Run, Graph, -, Cut, segmentation, with, refin...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/mjirik/imcut/blob/1b38e7cd1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mjirik/imcut</td>\n",
       "      <td>imcut/pycut.py</td>\n",
       "      <td>ImageGraphCut.__multiscale_gc_hi2lo_run</td>\n",
       "      <td>def __multiscale_gc_hi2lo_run(self):  # , pyed...</td>\n",
       "      <td>python</td>\n",
       "      <td>def __multiscale_gc_hi2lo_run(self):  # , pyed...</td>\n",
       "      <td>[def, __multiscale_gc_hi2lo_run, (, self, ), :...</td>\n",
       "      <td>Run Graph-Cut segmentation with simplifiyng of...</td>\n",
       "      <td>[Run, Graph, -, Cut, segmentation, with, simpl...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/mjirik/imcut/blob/1b38e7cd1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mjirik/imcut</td>\n",
       "      <td>imcut/pycut.py</td>\n",
       "      <td>ImageGraphCut.__ordered_values_by_indexes</td>\n",
       "      <td>def __ordered_values_by_indexes(self, data, in...</td>\n",
       "      <td>python</td>\n",
       "      <td>def __ordered_values_by_indexes(self, data, in...</td>\n",
       "      <td>[def, __ordered_values_by_indexes, (, self, ,,...</td>\n",
       "      <td>Return values (intensities) by indexes.\\n\\n   ...</td>\n",
       "      <td>[Return, values, (, intensities, ), by, indexe...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/mjirik/imcut/blob/1b38e7cd1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mjirik/imcut</td>\n",
       "      <td>imcut/pycut.py</td>\n",
       "      <td>ImageGraphCut.__hi2lo_multiscale_indexes</td>\n",
       "      <td>def __hi2lo_multiscale_indexes(self, mask, ori...</td>\n",
       "      <td>python</td>\n",
       "      <td>def __hi2lo_multiscale_indexes(self, mask, ori...</td>\n",
       "      <td>[def, __hi2lo_multiscale_indexes, (, self, ,, ...</td>\n",
       "      <td>Function computes multiscale indexes of ndarra...</td>\n",
       "      <td>[Function, computes, multiscale, indexes, of, ...</td>\n",
       "      <td>train</td>\n",
       "      <td>https://github.com/mjirik/imcut/blob/1b38e7cd1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  repository_name func_path_in_repository  \\\n",
       "0    mjirik/imcut          imcut/pycut.py   \n",
       "1    mjirik/imcut          imcut/pycut.py   \n",
       "2    mjirik/imcut          imcut/pycut.py   \n",
       "3    mjirik/imcut          imcut/pycut.py   \n",
       "4    mjirik/imcut          imcut/pycut.py   \n",
       "\n",
       "                                           func_name  \\\n",
       "0  ImageGraphCut.__msgc_step3_discontinuity_local...   \n",
       "1            ImageGraphCut.__multiscale_gc_lo2hi_run   \n",
       "2            ImageGraphCut.__multiscale_gc_hi2lo_run   \n",
       "3          ImageGraphCut.__ordered_values_by_indexes   \n",
       "4           ImageGraphCut.__hi2lo_multiscale_indexes   \n",
       "\n",
       "                                   whole_func_string language  \\\n",
       "0  def __msgc_step3_discontinuity_localization(se...   python   \n",
       "1  def __multiscale_gc_lo2hi_run(self):  # , pyed...   python   \n",
       "2  def __multiscale_gc_hi2lo_run(self):  # , pyed...   python   \n",
       "3  def __ordered_values_by_indexes(self, data, in...   python   \n",
       "4  def __hi2lo_multiscale_indexes(self, mask, ori...   python   \n",
       "\n",
       "                                    func_code_string  \\\n",
       "0  def __msgc_step3_discontinuity_localization(se...   \n",
       "1  def __multiscale_gc_lo2hi_run(self):  # , pyed...   \n",
       "2  def __multiscale_gc_hi2lo_run(self):  # , pyed...   \n",
       "3  def __ordered_values_by_indexes(self, data, in...   \n",
       "4  def __hi2lo_multiscale_indexes(self, mask, ori...   \n",
       "\n",
       "                                    func_code_tokens  \\\n",
       "0  [def, __msgc_step3_discontinuity_localization,...   \n",
       "1  [def, __multiscale_gc_lo2hi_run, (, self, ), :...   \n",
       "2  [def, __multiscale_gc_hi2lo_run, (, self, ), :...   \n",
       "3  [def, __ordered_values_by_indexes, (, self, ,,...   \n",
       "4  [def, __hi2lo_multiscale_indexes, (, self, ,, ...   \n",
       "\n",
       "                           func_documentation_string  \\\n",
       "0  Estimate discontinuity in basis of low resolut...   \n",
       "1  Run Graph-Cut segmentation with refinement of ...   \n",
       "2  Run Graph-Cut segmentation with simplifiyng of...   \n",
       "3  Return values (intensities) by indexes.\\n\\n   ...   \n",
       "4  Function computes multiscale indexes of ndarra...   \n",
       "\n",
       "                           func_documentation_tokens split_name  \\\n",
       "0  [Estimate, discontinuity, in, basis, of, low, ...      train   \n",
       "1  [Run, Graph, -, Cut, segmentation, with, refin...      train   \n",
       "2  [Run, Graph, -, Cut, segmentation, with, simpl...      train   \n",
       "3  [Return, values, (, intensities, ), by, indexe...      train   \n",
       "4  [Function, computes, multiscale, indexes, of, ...      train   \n",
       "\n",
       "                                       func_code_url  \n",
       "0  https://github.com/mjirik/imcut/blob/1b38e7cd1...  \n",
       "1  https://github.com/mjirik/imcut/blob/1b38e7cd1...  \n",
       "2  https://github.com/mjirik/imcut/blob/1b38e7cd1...  \n",
       "3  https://github.com/mjirik/imcut/blob/1b38e7cd1...  \n",
       "4  https://github.com/mjirik/imcut/blob/1b38e7cd1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def __msgc_step3_discontinuity_localization(self):\\n        \"\"\"\\n        Estimate discontinuity in basis of low resolution image segmentation.\\n        :return: discontinuity in low resolution\\n        \"\"\"\\n        import scipy\\n\\n        start = self._start_time\\n        seg = 1 - self.segmentation.astype(np.int8)\\n        self.stats[\"low level object voxels\"] = np.sum(seg)\\n        self.stats[\"low level image voxels\"] = np.prod(seg.shape)\\n        # in seg is now stored low resolution segmentation\\n        # back to normal parameters\\n        # step 2: discontinuity localization\\n        # self.segparams = sparams_hi\\n        seg_border = scipy.ndimage.filters.laplace(seg, mode=\"constant\")\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # logger.debug(str(np.max(seg_border)))\\n        # logger.debug(str(np.min(seg_border)))\\n        seg_border[seg_border != 0] = 1\\n        logger.debug(\"seg_border: %s\", scipy.stats.describe(seg_border, axis=None))\\n        # scipy.ndimage.morphology.distance_transform_edt\\n        boundary_dilatation_distance = self.segparams[\"boundary_dilatation_distance\"]\\n        seg = scipy.ndimage.morphology.binary_dilation(\\n            seg_border,\\n            # seg,\\n            np.ones(\\n                [\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                    (boundary_dilatation_distance * 2) + 1,\\n                ]\\n            ),\\n        )\\n        if self.keep_temp_properties:\\n            self.temp_msgc_lowres_discontinuity = seg\\n        else:\\n            self.temp_msgc_lowres_discontinuity = None\\n\\n        if self.debug_images:\\n            import sed3\\n\\n            pd = sed3.sed3(seg_border)  # ), contour=seg)\\n            pd.show()\\n            pd = sed3.sed3(seg)  # ), contour=seg)\\n            pd.show()\\n        # segzoom = scipy.ndimage.interpolation.zoom(seg.astype(\\'float\\'), zoom,\\n        #                                                order=0).astype(\\'int8\\')\\n        self.stats[\"t3\"] = time.time() - start\\n        return seg'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csn_df.iloc[0].whole_func_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42891"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tokenize('hello', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1880853/1880853 [09:56<00:00, 3152.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(118596716, 63.05475015857167)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_query_tokens = 0\n",
    "for i, row in tqdm(csn_df.iterrows(), total=TOTAL_ROWS):\n",
    "    query = row.func_documentation_string\n",
    "    if query:\n",
    "        tkns = full_tokenize(query, tokenizer)\n",
    "        if isinstance(tkns, int):\n",
    "            tkns = [tkns]\n",
    "        total_query_tokens += len(tkns)\n",
    "\n",
    "total_query_tokens, total_query_tokens/TOTAL_ROWS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1880853/1880853 [23:27<00:00, 1336.53it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(644719290, 342.7802651243877)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_func_tokens = 0\n",
    "for i, row in tqdm(csn_df.iterrows(), total=TOTAL_ROWS):\n",
    "    query = row.whole_func_string\n",
    "    if query:\n",
    "        tkns = full_tokenize(query, tokenizer)\n",
    "        if isinstance(tkns, int):\n",
    "            tkns = [tkns]\n",
    "        total_func_tokens += len(tkns)\n",
    "\n",
    "total_func_tokens, total_func_tokens/TOTAL_ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>file_path</th>\n",
       "      <th>previous_commit_id</th>\n",
       "      <th>previous_file_content</th>\n",
       "      <th>cur_file_content</th>\n",
       "      <th>diff</th>\n",
       "      <th>status</th>\n",
       "      <th>is_merge_request</th>\n",
       "      <th>file_extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696522497</td>\n",
       "      <td>dddfe688206dafa5646550d351eb9a8e9c53654a</td>\n",
       "      <td>pull implementations from the right react-dom ...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696521194</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>`react-dom/server-rendering-stub`: restore exp...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>16619f106ab5ba8e6aca19d55be46cce22e4a7ff</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-dom/src/__tests__/ReactDOMFizzS...</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-server/src/ReactFizzServer.js</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -1110,7 +1110,6 @@ function replaySuspenseB...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696450581</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>Move ReactCurrentDispatcher back to shared int...</td>\n",
       "      <td>packages/react-server/src/ReactFlightServer.js</td>\n",
       "      <td>ca237d6f0ab986e799f192224d3066f76d66b73b</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      owner repo_name  commit_date                                 commit_id  \\\n",
       "0  facebook     react   1696522497  dddfe688206dafa5646550d351eb9a8e9c53654a   \n",
       "1  facebook     react   1696521194  546178f9109424f6a0176ea8702a7620c4417569   \n",
       "2  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "3  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "4  facebook     react   1696450581  6f132439578ee11e04b41a278df51c52b0dc8563   \n",
       "\n",
       "                                      commit_message  \\\n",
       "0  pull implementations from the right react-dom ...   \n",
       "1  `react-dom/server-rendering-stub`: restore exp...   \n",
       "2  [Fizz] Reset error component stack and fix err...   \n",
       "3  [Fizz] Reset error component stack and fix err...   \n",
       "4  Move ReactCurrentDispatcher back to shared int...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0        packages/react-dom/server-rendering-stub.js   \n",
       "1        packages/react-dom/server-rendering-stub.js   \n",
       "2  packages/react-dom/src/__tests__/ReactDOMFizzS...   \n",
       "3       packages/react-server/src/ReactFizzServer.js   \n",
       "4     packages/react-server/src/ReactFlightServer.js   \n",
       "\n",
       "                          previous_commit_id  \\\n",
       "0  546178f9109424f6a0176ea8702a7620c4417569\n",
       "   \n",
       "1  16619f106ab5ba8e6aca19d55be46cce22e4a7ff\n",
       "   \n",
       "2  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "3  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "4  ca237d6f0ab986e799f192224d3066f76d66b73b\n",
       "   \n",
       "\n",
       "                               previous_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                    cur_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                                diff    status  \\\n",
       "0  @@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...  modified   \n",
       "1  @@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...  modified   \n",
       "2  @@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...  modified   \n",
       "3  @@ -1110,7 +1110,6 @@ function replaySuspenseB...  modified   \n",
       "4  @@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...  modified   \n",
       "\n",
       "   is_merge_request file_extension  \n",
       "0             False             js  \n",
       "1             False             js  \n",
       "2             False             js  \n",
       "3             False             js  \n",
       "4             False             js  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
