{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils import get_combined_df\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bm25_v2 import BM25Searcher\n",
    "from eval import ModelEvaluator, SearchEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../data/2_7/facebook_react/cache'\n",
    "repo_path = '../data/2_7/facebook_react'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_df(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df = pd.read_parquet(os.path.join(cache_path, 'code_df.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_commit_id</th>\n",
       "      <th>train_query</th>\n",
       "      <th>train_original_message</th>\n",
       "      <th>SR_file_path</th>\n",
       "      <th>SR_commit_id</th>\n",
       "      <th>SR_file_content</th>\n",
       "      <th>SR_diff</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>Empty for now, uncomment #317 in utils</td>\n",
       "      <td>@@ -569,8 +569,6 @@ function resolveLocksOnRoo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>src/renderers/shared/fiber/ReactChildFiber.js</td>\n",
       "      <td>c22b94f14a809abb376f07a53f36860a7c6a342e</td>\n",
       "      <td>Empty for now, uncomment #317 in utils</td>\n",
       "      <td>@@ -13,8 +13,7 @@\\n 'use strict';\\n \\n import ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>src/renderers/dom/fiber/__tests__/ReactDOMFibe...</td>\n",
       "      <td>1f74eca9937ad6f19b6291d21edfb8747bae88ca</td>\n",
       "      <td>Empty for now, uncomment #317 in utils</td>\n",
       "      <td>@@ -1004,6 +1004,81 @@ describe('ReactDOMFiber...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberRoot.js</td>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>Empty for now, uncomment #317 in utils</td>\n",
       "      <td>@@ -46,7 +46,7 @@ type BaseFiberRootProperties...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberUnwind...</td>\n",
       "      <td>9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b</td>\n",
       "      <td>Empty for now, uncomment #317 in utils</td>\n",
       "      <td>@@ -56,6 +56,7 @@ import {\\n } from './ReactPr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train_commit_id  \\\n",
       "0  76e569992b259b9e636ee68dcc7719539f4b9bb8   \n",
       "1  76e569992b259b9e636ee68dcc7719539f4b9bb8   \n",
       "2  76e569992b259b9e636ee68dcc7719539f4b9bb8   \n",
       "3  76e569992b259b9e636ee68dcc7719539f4b9bb8   \n",
       "4  76e569992b259b9e636ee68dcc7719539f4b9bb8   \n",
       "\n",
       "                                         train_query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                              train_original_message  \\\n",
       "0  Cleanup profile export/import data types, add ...   \n",
       "1  Cleanup profile export/import data types, add ...   \n",
       "2  Cleanup profile export/import data types, add ...   \n",
       "3  Cleanup profile export/import data types, add ...   \n",
       "4  Cleanup profile export/import data types, add ...   \n",
       "\n",
       "                                        SR_file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1      src/renderers/shared/fiber/ReactChildFiber.js   \n",
       "2  src/renderers/dom/fiber/__tests__/ReactDOMFibe...   \n",
       "3    packages/react-reconciler/src/ReactFiberRoot.js   \n",
       "4  packages/react-reconciler/src/ReactFiberUnwind...   \n",
       "\n",
       "                               SR_commit_id  \\\n",
       "0  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "1  c22b94f14a809abb376f07a53f36860a7c6a342e   \n",
       "2  1f74eca9937ad6f19b6291d21edfb8747bae88ca   \n",
       "3  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "4  9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b   \n",
       "\n",
       "                          SR_file_content  \\\n",
       "0  Empty for now, uncomment #317 in utils   \n",
       "1  Empty for now, uncomment #317 in utils   \n",
       "2  Empty for now, uncomment #317 in utils   \n",
       "3  Empty for now, uncomment #317 in utils   \n",
       "4  Empty for now, uncomment #317 in utils   \n",
       "\n",
       "                                             SR_diff  label  \n",
       "0  @@ -569,8 +569,6 @@ function resolveLocksOnRoo...      0  \n",
       "1  @@ -13,8 +13,7 @@\\n 'use strict';\\n \\n import ...      0  \n",
       "2  @@ -1004,6 +1004,81 @@ describe('ReactDOMFiber...      0  \n",
       "3  @@ -46,7 +46,7 @@ type BaseFiberRootProperties...      0  \n",
       "4  @@ -56,6 +56,7 @@ import {\\n } from './ReactPr...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_code_triplets = pd.read_parquet(os.path.join(cache_path, 'diff_code_triplets.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>file_path</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>&lt;s&gt;     firstBatch._defer &amp;&amp;     firstBatch._e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>WorkLoopTimer();   root.finishedWork = root.cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>msUntilTimeout,             );            ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>RootImpl so that it inherits the priority of t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>scheduled.   // Mark the time at which this p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "2  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "3  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "4  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "\n",
       "                                             passage  label  \n",
       "0  <s>     firstBatch._defer &&     firstBatch._e...      0  \n",
       "1  WorkLoopTimer();   root.finishedWork = root.cu...      0  \n",
       "2      msUntilTimeout,             );            ...      0  \n",
       "3  RootImpl so that it inherits the priority of t...      0  \n",
       "4   scheduled.   // Mark the time at which this p...      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_code_triplets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class BERTCodeReranker:\n",
    "    def __init__(self, parameters):\n",
    "        self.parameters = parameters\n",
    "        self.model_name = parameters['model_name']\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=1, problem_type='regression')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and parameters['use_gpu'] else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(f'Using device: {self.device}')\n",
    "\n",
    "        # print GPU info\n",
    "        if torch.cuda.is_available() and parameters['use_gpu']:\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f'GPU Device Count: {torch.cuda.device_count()}')\n",
    "            print(f\"GPU Memory Usage: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "\n",
    "        self.psg_len = parameters['psg_len']\n",
    "        self.psg_cnt = parameters['psg_cnt'] # how many contributing_results to use per file for reranking\n",
    "        self.psg_stride = parameters.get('psg_stride', self.psg_len)\n",
    "        self.aggregation_strategy = parameters['aggregation_strategy'] # how to aggregate the scores of the psg_cnt contributing_results\n",
    "        self.batch_size = parameters['batch_size'] # batch size for reranking efficiently\n",
    "        self.rerank_depth = parameters['rerank_depth']\n",
    "        self.max_seq_length = self.tokenizer.model_max_length # max sequence length for the model\n",
    "\n",
    "        print(f\"Initialized Code File BERT reranker with parameters: {parameters}\")\n",
    "\n",
    "\n",
    "    def rerank(self, query, aggregated_results):\n",
    "        \"\"\"\n",
    "        Rerank the BM25 aggregated search results using BERT model scores.\n",
    "\n",
    "        query: The issue query string.\n",
    "        aggregated_results: A list of AggregatedSearchResult objects from BM25 search.\n",
    "        \"\"\"\n",
    "        # aggregated_results = aggregated_results[:self.rerank_depth] # already done in the pipeline\n",
    "        # print(f'Reranking {len(aggregated_results)} results')\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        query_passage_pairs, per_result_contribution = self.split_into_query_passage_pairs(query, aggregated_results)\n",
    "\n",
    "\n",
    "        # for agg_result in aggregated_results:\n",
    "        #     query_passage_pairs.extend(\n",
    "        #         (query, result.commit_message)\n",
    "        #         for result in agg_result.contributing_results[: self.psg_cnt]\n",
    "        #     )\n",
    "\n",
    "        if not query_passage_pairs:\n",
    "            print('WARNING: No query passage pairs to rerank, returning original results from previous stage')\n",
    "            print(query, aggregated_results, self.psg_cnt)\n",
    "            return aggregated_results\n",
    "\n",
    "        # tokenize the query passage pairs\n",
    "        encoded_pairs = [self.tokenizer.encode_plus([query, passage], max_length=self.max_seq_length, truncation=True, padding='max_length', return_tensors='pt', add_special_tokens=True) for query, passage in query_passage_pairs]\n",
    "\n",
    "        # create tensors for the input ids, attention masks\n",
    "        input_ids = torch.stack([encoded_pair['input_ids'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "        attention_masks = torch.stack([encoded_pair['attention_mask'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "\n",
    "        # Create a dataloader for feeding the data to the model\n",
    "        dataset = TensorDataset(input_ids, attention_masks)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False) # shuffle=False very important for reconstructing the results back into the original order\n",
    "\n",
    "        scores = self.get_scores(dataloader, self.model)\n",
    "\n",
    "        score_index = 0\n",
    "        # Now assign the scores to the aggregated results by mapping the scores to the contributing results\n",
    "        for i, agg_result in enumerate(aggregated_results):\n",
    "            # Each aggregated result gets a slice of the scores equal to the number of contributing results it has which should be min(psg_cnt, len(contributing_results))\n",
    "            assert score_index < len(scores), f'score_index {score_index} is greater than or equal to scores length {len(scores)}'\n",
    "            end_index = score_index + per_result_contribution[i] # only use psg_cnt contributing_results\n",
    "            cur_passage_scores = scores[score_index:end_index]\n",
    "            score_index = end_index\n",
    "\n",
    "\n",
    "            # Aggregate the scores for the current aggregated result\n",
    "            agg_score = self.aggregate_scores(cur_passage_scores)\n",
    "            agg_result.score = agg_score  # Assign the aggregated score\n",
    "\n",
    "        assert score_index == len(scores), f'score_index {score_index} does not equal scores length {len(scores)}, indices probably not working correctly'\n",
    "\n",
    "        # Sort by the new aggregated score\n",
    "        aggregated_results.sort(key=lambda res: res.score, reverse=True)\n",
    "\n",
    "        return aggregated_results\n",
    "\n",
    "    def get_scores(self, dataloader, model):\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Unpack the batch and move it to GPU\n",
    "                b_input_ids, b_attention_mask = batch\n",
    "                b_input_ids = b_input_ids.to(self.device)\n",
    "                b_attention_mask = b_attention_mask.to(self.device)\n",
    "\n",
    "                # Get scores from the model\n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_mask)\n",
    "                scores.extend(outputs.logits.detach().cpu().numpy().squeeze(-1))\n",
    "        return scores\n",
    "\n",
    "    def aggregate_scores(self, passage_scores):\n",
    "        \"\"\"\n",
    "        Aggregate passage scores based on the specified strategy.\n",
    "        \"\"\"\n",
    "        if len(passage_scores) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        if self.aggregation_strategy == 'firstp':\n",
    "            return passage_scores[0]\n",
    "        if self.aggregation_strategy == 'maxp':\n",
    "            return max(passage_scores)\n",
    "        if self.aggregation_strategy == 'avgp':\n",
    "            return sum(passage_scores) / len(passage_scores)\n",
    "        if self.aggregation_strategy == 'sump':\n",
    "            return sum(passage_scores)\n",
    "        # else:\n",
    "        raise ValueError(f\"Invalid score aggregation method: {self.aggregation_strategy}\")\n",
    "\n",
    "\n",
    "    def split_into_query_passage_pairs(self, query, aggregated_results):\n",
    "        # Flatten the list of results into a list of (query, passage) pairs but only keep max psg_cnt passages per file\n",
    "        def full_tokenize(s):\n",
    "            return self.tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()\n",
    "        query_passage_pairs = []\n",
    "        per_result_contribution = []\n",
    "        for agg_result in aggregated_results:\n",
    "            agg_result.contributing_results.sort(key=lambda res: res.commit_date, reverse=True)\n",
    "            # get most recent file version\n",
    "            most_recent_search_result = agg_result.contributing_results[0]\n",
    "            # get the file_path and commit_id\n",
    "            file_path = most_recent_search_result.file_path\n",
    "            commit_id = most_recent_search_result.commit_id\n",
    "            # get the file content from combined_df\n",
    "            file_content = combined_df[(combined_df['commit_id'] == commit_id) & (combined_df['file_path'] == file_path)]['cur_file_content'].values[0]\n",
    "\n",
    "            # now need to split this file content into psg_cnt passages\n",
    "            # first tokenize the file content\n",
    "\n",
    "            # warning these asserts are useless since we are using NaNs\n",
    "            assert file_content is not None, f'file_content is None for commit_id: {commit_id}, file_path: {file_path}'\n",
    "            assert file_path is not None, f'file_path is None for commit_id: {commit_id}'\n",
    "            assert query is not None, f'query is None'\n",
    "\n",
    "            query_tokens = full_tokenize(query)\n",
    "            path_tokens = full_tokenize(file_path)\n",
    "\n",
    "            if pd.isna(file_content):\n",
    "                # if file_content is NaN, then we can just set file_content to empty string\n",
    "                print(f'WARNING: file_content is NaN for commit_id: {commit_id}, file_path: {file_path}, setting file_content to empty string')\n",
    "                file_content = ''\n",
    "\n",
    "            file_tokens = full_tokenize(file_content)\n",
    "\n",
    "\n",
    "            # now split the file content into psg_cnt passages\n",
    "            cur_result_passages = []\n",
    "            # get the input ids\n",
    "            # input_ids = file_content['input_ids'].squeeze()\n",
    "            # get the number of tokens in the file content\n",
    "            total_tokens = len(file_tokens)\n",
    "\n",
    "            for cur_start in range(0, total_tokens, self.psg_stride):\n",
    "                cur_passage = []\n",
    "                # add query tokens and path tokens\n",
    "                # cur_passage.extend(query_tokens) # ??????????????\n",
    "                cur_passage.extend(path_tokens)\n",
    "\n",
    "                # add the file tokens\n",
    "                cur_passage.extend(file_tokens[cur_start:cur_start+self.psg_len])\n",
    "\n",
    "                # now convert cur_passage into a string\n",
    "                cur_passage_decoded = self.tokenizer.decode(cur_passage)\n",
    "\n",
    "                # add the cur_passage to cur_result_passages\n",
    "                cur_result_passages.append(cur_passage_decoded)\n",
    "\n",
    "                if len(cur_result_passages) == self.psg_cnt:\n",
    "                    break\n",
    "\n",
    "            # now add the query, passage pairs to query_passage_pairs\n",
    "            per_result_contribution.append(len(cur_result_passages))\n",
    "            query_passage_pairs.extend((query, passage) for passage in cur_result_passages)\n",
    "        return query_passage_pairs, per_result_contribution\n",
    "\n",
    "    def rerank_pipeline(self, query, aggregated_results):\n",
    "        if len(aggregated_results) == 0:\n",
    "            return aggregated_results\n",
    "        top_results = aggregated_results[:self.rerank_depth]\n",
    "        bottom_results = aggregated_results[self.rerank_depth:]\n",
    "        reranked_results = self.rerank(query, top_results)\n",
    "        min_top_score = reranked_results[-1].score\n",
    "        # now adjust the scores of bottom_results\n",
    "        for i, result in enumerate(bottom_results):\n",
    "            result.score = min_top_score - i - 1\n",
    "        # combine the results\n",
    "        reranked_results.extend(bottom_results)\n",
    "        assert(len(reranked_results) == len(aggregated_results))\n",
    "        return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../smalldata/ftr/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='../smalldata/ftr/index_commit_tokenized', repo_path='../smalldata/ftr', k=1000, n=100, model_path='microsoft/codebert-base', overwrite_cache=False, batch_size=32, num_epochs=10, learning_rate=5e-05, num_positives=10, num_negatives=10, train_depth=1000, num_workers=8, train_commits=1000, psg_cnt=25, aggregation_strategy='sump', use_gpu=True, rerank_depth=100, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4', overwrite_eval=False, sanity_check=True, debug=False, best_model_path=None, bert_best_model='../data/combined_commit_train/best_model', psg_len=350, psg_stride=300, ignore_gold_in_training=False, eval_folder='code_rerank', use_gpt_train=True\n",
    ")\n",
    "\n",
    "metrics =['MAP', 'P@1', 'P@10', 'P@20', 'P@30', 'MRR', 'R@1', 'R@10', 'R@100', 'R@1000']\n",
    "repo_path = args.repo_path\n",
    "repo_name = repo_path.split('/')[-1]\n",
    "index_path = args.index_path\n",
    "K = args.k\n",
    "n = args.n\n",
    "combined_df = get_combined_df(repo_path)\n",
    "BM25_AGGR_STRAT = 'sump'\n",
    "eval_path = os.path.join(repo_path, 'eval')\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "bm25_searcher = BM25Searcher(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "\n",
    "test_path = os.path.join('..', 'gold', 'facebook_react', 'v2_facebook_react_gpt4_gold.parquet')\n",
    "gold_df = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Baseline Evaluation\n",
      "{'MAP': 0.1542, 'P@1': 0.11, 'P@10': 0.087, 'P@20': 0.063, 'P@30': 0.0517, 'MRR': 0.2133, 'R@1': 0.0509, 'R@10': 0.2285, 'R@100': 0.5077, 'R@1000': 0.6845}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bm25_baseline_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=BM25_AGGR_STRAT)\n",
    "\n",
    "print(\"BM25 Baseline Evaluation\")\n",
    "print(bm25_baseline_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 476.73 MB\n",
      "Initialized Code File BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 25, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 100, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump', 'psg_len': 350, 'psg_stride': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': args.psg_cnt,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': args.rerank_depth,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "        'psg_len': args.psg_len,\n",
    "        'psg_stride': args.psg_stride\n",
    "    }\n",
    "\n",
    "code_reranker = BERTCodeReranker(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def prepare_code_triplets(code_df, code_reranker, cache_file, combined_df, overwrite=False):\n",
    "    print(f'Preparing code triplets from scratch for {len(code_df)} diffs with psg_len: {code_reranker.psg_len}, psg_stride: {code_reranker.psg_stride}, psg_cnt: {code_reranker.psg_cnt}')\n",
    "\n",
    "    if cache_file and os.path.exists(cache_file) and not overwrite:\n",
    "        print(f\"Loading data from cache file: {cache_file}\")\n",
    "        return pd.read_parquet(cache_file)\n",
    "\n",
    "    def prep_line(line):\n",
    "        return line.rstrip().lstrip()\n",
    "\n",
    "    def parse_diff(diff):\n",
    "        return [\n",
    "            line[1:] if line.startswith('+') else line\n",
    "            for line in diff.split('\\n')\n",
    "            if not (line.startswith('-') or len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "            and len(prep_line(line)) > 2\n",
    "        ]\n",
    "\n",
    "    def parse_diff2(diff):\n",
    "        return [\n",
    "            line[1:] if (line.startswith('+') or line.startswith('-')) else line\n",
    "            for line in diff.split('\\n')\n",
    "            if not (len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "        ]\n",
    "\n",
    "    def full_tokenize(s):\n",
    "        return code_reranker.tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()\n",
    "\n",
    "    def count_matching_lines(passage_lines, diff_lines):\n",
    "        # Create a 2D array to store the lengths of the longest common subsequences\n",
    "        dp = [[0] * (len(diff_lines) + 1) for _ in range(len(passage_lines) + 1)]\n",
    "\n",
    "        # Fill the dp array\n",
    "        for i in range(1, len(passage_lines) + 1):\n",
    "            for j in range(1, len(diff_lines) + 1):\n",
    "                if prep_line(passage_lines[i - 1]) == prep_line(diff_lines[j - 1]):\n",
    "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "        return dp[-1][-1]\n",
    "\n",
    "    triplets = []\n",
    "\n",
    "    for _, row in tqdm(code_df.iterrows(), total=len(code_df)):\n",
    "        file_tokens = full_tokenize(row['SR_file_content'])\n",
    "        total_tokens = len(file_tokens)\n",
    "        cur_diff = combined_df[(combined_df['commit_id'] == row['SR_commit_id']) & (combined_df['file_path'] == row['SR_file_path'])]['diff'].values[0]\n",
    "\n",
    "        if pd.isna(cur_diff):\n",
    "            # if diff is NA/NaN, then skip this row\n",
    "            # possible when commit removes or renames this file or maybe god decided to remove the diff\n",
    "            continue\n",
    "\n",
    "        cur_diff_lines = parse_diff(cur_diff)\n",
    "        cur_triplets = []\n",
    "        for cur_start in range(0, total_tokens, code_reranker.psg_stride):\n",
    "            cur_passage = []\n",
    "\n",
    "            cur_passage.extend(file_tokens[cur_start:cur_start+code_reranker.psg_len])\n",
    "\n",
    "            # now convert cur_passage into a string\n",
    "            cur_passage_decoded = code_reranker.tokenizer.decode(cur_passage)\n",
    "\n",
    "            cur_passage_lines = cur_passage_decoded.split('\\n')\n",
    "\n",
    "            # remove lines with less than 2 characters\n",
    "            cur_passage_lines = [line for line in cur_passage_lines if len(prep_line(line)) > 2]\n",
    "\n",
    "            # check if there are lines matching the diff lines\n",
    "            # if there are, then we can add this directly to the triplets\n",
    "            # common_lines = set(cur_passage_lines).intersection(set(cur_diff_lines))\n",
    "            common_line_count = count_matching_lines(cur_passage_lines, cur_diff_lines)\n",
    "\n",
    "            # add the cur_passage to cur_result_passages\n",
    "            cur_triplets.append((common_line_count, (row['train_query'], row['SR_file_path'], cur_passage_decoded, row['label'])))\n",
    "\n",
    "        # sort the cur_triplets by the number of common lines\n",
    "        cur_triplets.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # now we want to filter cur_triplets to have all tuplets with x[0] > 3 to be in order and shuffle the rest\n",
    "\n",
    "        # now add the top code_reranker.psg_cnt to triplets\n",
    "        for triplet in cur_triplets[:code_reranker.psg_cnt]:\n",
    "            # print(f\"Found {triplet[0]} matching lines for diff in cur_passage at index\")\n",
    "            triplets.append(triplet[1])\n",
    "\n",
    "\n",
    "    # convert to pandas dataframe\n",
    "    triplets = pd.DataFrame(triplets, columns=['query', 'file_path', 'passage', 'label'])\n",
    "    if cache_file:\n",
    "        # with open(cache_file, 'wb') as file:\n",
    "        #     pickle.dump(triplets, file)\n",
    "        #     print(f\"Saved data to cache file: {cache_file}\")\n",
    "        print(f\"Saving data to cache file: {cache_file}\")\n",
    "        triplets.to_parquet(cache_file)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique files edited in 500 training queries is 983\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet('../gold/facebook_react/v2_facebook_react_gpt4_train.parquet')\n",
    "train_df = train_df.rename(columns={'commit_message': 'original_message', f'transformed_message_{args.openai_model}': 'commit_message'})\n",
    "res = []\n",
    "for arr in train_df.actual_files_modified.tolist():\n",
    "    res.extend(arr[:10])\n",
    "\n",
    "print(f'number of unique files edited in {train_df.commit_id.nunique()} training queries is {len(set(res))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique files in the code_df with label=1 is 533\n"
     ]
    }
   ],
   "source": [
    "out = len(code_df[code_df['label'] == 1]['SR_file_path'].unique())\n",
    "print(f'number of unique files in the code_df with label=1 is {out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5422177009155646"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "533/983 # % of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>original_message</th>\n",
       "      <th>actual_files_modified</th>\n",
       "      <th>commit_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>1557817141</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>[src/__tests__/profiling-test.js, src/__tests_...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d919e2c41c71fc7bc4ae037b3a3c60a4600d0a54</td>\n",
       "      <td>1612900575</td>\n",
       "      <td>Add tests for non-React discrete events flushi...</td>\n",
       "      <td>[packages/react-dom/src/__tests__/ReactDOMFibe...</td>\n",
       "      <td>Discrete events tests are outdated and use Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353c30252f67145fa8241b6979d570cb152c2b22</td>\n",
       "      <td>1669996435</td>\n",
       "      <td>Hold host functions in var (#25741)\n",
       "\n",
       "Calling a...</td>\n",
       "      <td>[packages/react-native-renderer/src/ReactFabri...</td>\n",
       "      <td>Repeated calls to the same host function on `n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77ba1618a528787baaa8e007fadaff93a86fb675</td>\n",
       "      <td>1679364473</td>\n",
       "      <td>Bugfix: Remove extra render pass when revertin...</td>\n",
       "      <td>[packages/react-dom/src/__tests__/ReactDOMServ...</td>\n",
       "      <td>During hydration, if an error occurs and there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f118b7cebf9c15d11c5973bfd40860b5f457df08</td>\n",
       "      <td>1680107275</td>\n",
       "      <td>[Flight] Gated test for dropped transport of u...</td>\n",
       "      <td>[packages/react-client/src/__tests__/ReactFlig...</td>\n",
       "      <td>Deserializing undefined object values on the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_id  commit_date  \\\n",
       "0  76e569992b259b9e636ee68dcc7719539f4b9bb8   1557817141   \n",
       "1  d919e2c41c71fc7bc4ae037b3a3c60a4600d0a54   1612900575   \n",
       "2  353c30252f67145fa8241b6979d570cb152c2b22   1669996435   \n",
       "3  77ba1618a528787baaa8e007fadaff93a86fb675   1679364473   \n",
       "4  f118b7cebf9c15d11c5973bfd40860b5f457df08   1680107275   \n",
       "\n",
       "                                    original_message  \\\n",
       "0  Cleanup profile export/import data types, add ...   \n",
       "1  Add tests for non-React discrete events flushi...   \n",
       "2  Hold host functions in var (#25741)\n",
       "\n",
       "Calling a...   \n",
       "3  Bugfix: Remove extra render pass when revertin...   \n",
       "4  [Flight] Gated test for dropped transport of u...   \n",
       "\n",
       "                               actual_files_modified  \\\n",
       "0  [src/__tests__/profiling-test.js, src/__tests_...   \n",
       "1  [packages/react-dom/src/__tests__/ReactDOMFibe...   \n",
       "2  [packages/react-native-renderer/src/ReactFabri...   \n",
       "3  [packages/react-dom/src/__tests__/ReactDOMServ...   \n",
       "4  [packages/react-client/src/__tests__/ReactFlig...   \n",
       "\n",
       "                                      commit_message  \n",
       "0  Malformed data types (`commitDetails`, `intera...  \n",
       "1  Discrete events tests are outdated and use Rea...  \n",
       "2  Repeated calls to the same host function on `n...  \n",
       "3  During hydration, if an error occurs and there...  \n",
       "4  Deserializing undefined object values on the c...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n",
      "Found gold_df, evaluating on 500 commits\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   commit_id              500 non-null    string\n",
      " 1   commit_date            500 non-null    int64 \n",
      " 2   original_message       500 non-null    string\n",
      " 3   actual_files_modified  500 non-null    object\n",
      " 4   commit_message         500 non-null    object\n",
      "dtypes: int64(1), object(2), string(2)\n",
      "memory usage: 19.7+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:03<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tmp: 983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.1424,\n",
       " 'P@1': 0.13,\n",
       " 'P@10': 0.0794,\n",
       " 'P@20': 0.0576,\n",
       " 'P@30': 0.048,\n",
       " 'MRR': 0.23,\n",
       " 'R@1': 0.0325,\n",
       " 'R@10': 0.1691,\n",
       " 'R@100': 0.4955,\n",
       " 'R@1000': 0.6618}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding out what is the R@1000 for the training queries, it SHOULD be close to 42%\n",
    "model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=BM25_AGGR_STRAT, gold_df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 metrics on training data. unexpected - R@1000 is quite good. so why are relevant files not present in triplets?\n",
    "\n",
    "# {'MAP': 0.1424,\n",
    "#  'P@1': 0.13,\n",
    "#  'P@10': 0.0794,\n",
    "#  'P@20': 0.0576,\n",
    "#  'P@30': 0.048,\n",
    "#  'MRR': 0.23,\n",
    "#  'R@1': 0.0325,\n",
    "#  'R@10': 0.1691,\n",
    "#  'R@100': 0.4955,\n",
    "#  'R@1000': 0.6618}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>actual_files_modified</th>\n",
       "      <th>transformed_message_gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76e569992b259b9e636ee68dcc7719539f4b9bb8</td>\n",
       "      <td>1557817141</td>\n",
       "      <td>Cleanup profile export/import data types, add ...</td>\n",
       "      <td>[src/__tests__/profiling-test.js, src/__tests_...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d919e2c41c71fc7bc4ae037b3a3c60a4600d0a54</td>\n",
       "      <td>1612900575</td>\n",
       "      <td>Add tests for non-React discrete events flushi...</td>\n",
       "      <td>[packages/react-dom/src/__tests__/ReactDOMFibe...</td>\n",
       "      <td>Discrete events tests are outdated and use Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353c30252f67145fa8241b6979d570cb152c2b22</td>\n",
       "      <td>1669996435</td>\n",
       "      <td>Hold host functions in var (#25741)\n",
       "\n",
       "Calling a...</td>\n",
       "      <td>[packages/react-native-renderer/src/ReactFabri...</td>\n",
       "      <td>Repeated calls to the same host function on `n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77ba1618a528787baaa8e007fadaff93a86fb675</td>\n",
       "      <td>1679364473</td>\n",
       "      <td>Bugfix: Remove extra render pass when revertin...</td>\n",
       "      <td>[packages/react-dom/src/__tests__/ReactDOMServ...</td>\n",
       "      <td>During hydration, if an error occurs and there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f118b7cebf9c15d11c5973bfd40860b5f457df08</td>\n",
       "      <td>1680107275</td>\n",
       "      <td>[Flight] Gated test for dropped transport of u...</td>\n",
       "      <td>[packages/react-client/src/__tests__/ReactFlig...</td>\n",
       "      <td>Deserializing undefined object values on the c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_id  commit_date  \\\n",
       "0  76e569992b259b9e636ee68dcc7719539f4b9bb8   1557817141   \n",
       "1  d919e2c41c71fc7bc4ae037b3a3c60a4600d0a54   1612900575   \n",
       "2  353c30252f67145fa8241b6979d570cb152c2b22   1669996435   \n",
       "3  77ba1618a528787baaa8e007fadaff93a86fb675   1679364473   \n",
       "4  f118b7cebf9c15d11c5973bfd40860b5f457df08   1680107275   \n",
       "\n",
       "                                      commit_message  \\\n",
       "0  Cleanup profile export/import data types, add ...   \n",
       "1  Add tests for non-React discrete events flushi...   \n",
       "2  Hold host functions in var (#25741)\n",
       "\n",
       "Calling a...   \n",
       "3  Bugfix: Remove extra render pass when revertin...   \n",
       "4  [Flight] Gated test for dropped transport of u...   \n",
       "\n",
       "                               actual_files_modified  \\\n",
       "0  [src/__tests__/profiling-test.js, src/__tests_...   \n",
       "1  [packages/react-dom/src/__tests__/ReactDOMFibe...   \n",
       "2  [packages/react-native-renderer/src/ReactFabri...   \n",
       "3  [packages/react-dom/src/__tests__/ReactDOMServ...   \n",
       "4  [packages/react-client/src/__tests__/ReactFlig...   \n",
       "\n",
       "                            transformed_message_gpt4  \n",
       "0  Malformed data types (`commitDetails`, `intera...  \n",
       "1  Discrete events tests are outdated and use Rea...  \n",
       "2  Repeated calls to the same host function on `n...  \n",
       "3  During hydration, if an error occurs and there...  \n",
       "4  Deserializing undefined object values on the c...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_df(recent_df, searcher, search_depth, num_positives, num_negatives, cache_file, overwrite=False):\n",
    "\n",
    "    # takes a bunch of train\n",
    "\n",
    "    if cache_file and os.path.exists(cache_file) and not overwrite:\n",
    "        print(f\"Loading data from cache file: {cache_file}\")\n",
    "        return pd.read_parquet(cache_file)\n",
    "\n",
    "    code_data = []\n",
    "    print(f'Preparing code data from dataframe of size: {len(recent_df)} with search_depth: {search_depth}')\n",
    "    total_positives, total_negatives = 0, 0\n",
    "    for _, row in tqdm(recent_df.iterrows(), total=len(recent_df)):\n",
    "        cur_positives = 0\n",
    "        cur_negatives = 0\n",
    "        train_original_message = row['original_message']\n",
    "        train_commit_message = row['commit_message']\n",
    "        actual_files_modified = row['actual_files_modified']\n",
    "        train_commit_id = row['commit_id']\n",
    "\n",
    "        agg_search_results = searcher.pipeline(train_commit_message, row['commit_date'], search_depth, 'sump', sort_contributing_result_by_date=True)\n",
    "\n",
    "        for agg_result in agg_search_results:\n",
    "            most_recent_search_result = agg_result.contributing_results[0] # get the most recent version at the time of train query\n",
    "            search_result_file_path = most_recent_search_result.file_path\n",
    "            search_result_commit_id = most_recent_search_result.commit_id\n",
    "            # search_result_current_file_content = 'Empty for now, uncomment #317 in utils'\n",
    "\n",
    "            if search_result_file_path in actual_files_modified and cur_positives < num_positives:\n",
    "                # this is a positive sample\n",
    "                code_data.append((train_commit_id, train_commit_message, train_original_message, search_result_file_path, search_result_commit_id, 1))\n",
    "                cur_positives += 1\n",
    "                total_positives += 1\n",
    "            elif search_result_file_path not in actual_files_modified and cur_negatives < num_negatives:\n",
    "                # this is a negative sample\n",
    "                code_data.append((train_commit_id, train_commit_message, train_original_message, search_result_file_path, search_result_commit_id, 0))\n",
    "                cur_negatives += 1\n",
    "                total_negatives += 1\n",
    "\n",
    "            if cur_positives == num_positives and cur_negatives == num_negatives:\n",
    "                break\n",
    "\n",
    "        # if _ == 3:\n",
    "        # break\n",
    "\n",
    "    code_df = pd.DataFrame(code_data, columns=['train_commit_id', 'train_query', 'train_original_message', 'SR_file_path', 'SR_commit_id' ,'label'])\n",
    "\n",
    "    # print distribution of labels\n",
    "    print(f\"Total positives: {total_positives}, Total negatives: {total_negatives}\")\n",
    "    denom = total_positives + total_negatives\n",
    "    print(f\"Percentage of positives: {total_positives / denom}, Percentage of negatives: {total_negatives / denom}\")\n",
    "\n",
    "\n",
    "    if cache_file:\n",
    "        print(f\"Saving data to cache file: {cache_file}\")\n",
    "        code_df.to_parquet(cache_file)\n",
    "\n",
    "    return code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df[code_df['label'] == 1].SR_file_path.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are there 533 label = 1 files in code_df, 423 in triplets when in reality it should be 1085? BM25 recall is also quite high for training so this is NOT expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_pickle(os.path.join(repo_path, 'cache', 'gpt_triplet_data_cache.pkl'))\n",
    "tmp[tmp['label']==1]['query'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': 5,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': 250,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 476.73 MB\n",
      "Initialized BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 5, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 250, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_path = os.path.join('data', 'combined_commit_train', 'best_model')\n",
    "bert_reranker = BERTReranker(bert_params)\n",
    "bert_reranker.model = AutoModelForSequenceClassification.from_pretrained(args.bert_best_model, num_labels=1, problem_type='regression')\n",
    "bert_reranker.model.to(bert_reranker.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 953.46 MB\n",
      "Initialized Code File BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 25, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 100, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump', 'psg_len': 350, 'psg_stride': 250}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerankers = [bert_reranker, code_reranker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n",
      "Found gold_df, evaluating on 1 commits\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 1 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   commit_id                 1 non-null      string\n",
      " 1   commit_date               1 non-null      int64 \n",
      " 2   commit_message            1 non-null      string\n",
      " 3   actual_files_modified     1 non-null      object\n",
      " 4   transformed_message_gpt4  1 non-null      object\n",
      "dtypes: int64(1), object(2), string(2)\n",
      "memory usage: 172.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "bert_gold_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=params['aggregation_strategy'], rerankers=rerankers, gold_df=gold_df.iloc[1:2])\n",
    "\n",
    "print(\"BERT Gold Evaluation\")\n",
    "print(bert_gold_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>file_path</th>\n",
       "      <th>previous_commit_id</th>\n",
       "      <th>previous_file_content</th>\n",
       "      <th>cur_file_content</th>\n",
       "      <th>diff</th>\n",
       "      <th>status</th>\n",
       "      <th>is_merge_request</th>\n",
       "      <th>file_extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696522497</td>\n",
       "      <td>dddfe688206dafa5646550d351eb9a8e9c53654a</td>\n",
       "      <td>pull implementations from the right react-dom ...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696521194</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>`react-dom/server-rendering-stub`: restore exp...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>16619f106ab5ba8e6aca19d55be46cce22e4a7ff</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-dom/src/__tests__/ReactDOMFizzS...</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-server/src/ReactFizzServer.js</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -1110,7 +1110,6 @@ function replaySuspenseB...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696450581</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>Move ReactCurrentDispatcher back to shared int...</td>\n",
       "      <td>packages/react-server/src/ReactFlightServer.js</td>\n",
       "      <td>ca237d6f0ab986e799f192224d3066f76d66b73b</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      owner repo_name  commit_date                                 commit_id  \\\n",
       "0  facebook     react   1696522497  dddfe688206dafa5646550d351eb9a8e9c53654a   \n",
       "1  facebook     react   1696521194  546178f9109424f6a0176ea8702a7620c4417569   \n",
       "2  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "3  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "4  facebook     react   1696450581  6f132439578ee11e04b41a278df51c52b0dc8563   \n",
       "\n",
       "                                      commit_message  \\\n",
       "0  pull implementations from the right react-dom ...   \n",
       "1  `react-dom/server-rendering-stub`: restore exp...   \n",
       "2  [Fizz] Reset error component stack and fix err...   \n",
       "3  [Fizz] Reset error component stack and fix err...   \n",
       "4  Move ReactCurrentDispatcher back to shared int...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0        packages/react-dom/server-rendering-stub.js   \n",
       "1        packages/react-dom/server-rendering-stub.js   \n",
       "2  packages/react-dom/src/__tests__/ReactDOMFizzS...   \n",
       "3       packages/react-server/src/ReactFizzServer.js   \n",
       "4     packages/react-server/src/ReactFlightServer.js   \n",
       "\n",
       "                          previous_commit_id  \\\n",
       "0  546178f9109424f6a0176ea8702a7620c4417569\n",
       "   \n",
       "1  16619f106ab5ba8e6aca19d55be46cce22e4a7ff\n",
       "   \n",
       "2  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "3  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "4  ca237d6f0ab986e799f192224d3066f76d66b73b\n",
       "   \n",
       "\n",
       "                               previous_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                    cur_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                                diff    status  \\\n",
       "0  @@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...  modified   \n",
       "1  @@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...  modified   \n",
       "2  @@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...  modified   \n",
       "3  @@ -1110,7 +1110,6 @@ function replaySuspenseB...  modified   \n",
       "4  @@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...  modified   \n",
       "\n",
       "   is_merge_request file_extension  \n",
       "0             False             js  \n",
       "1             False             js  \n",
       "2             False             js  \n",
       "3             False             js  \n",
       "4             False             js  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first row\n",
    "code = subdf.iloc[0].cur_file_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
