{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssg2/miniconda3/envs/ds/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils import get_combined_df\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/2_7/facebook_react/cache_hope'\n",
    "main_path = '../data/2_7/facebook_react'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_df(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df = pd.read_parquet(os.path.join(path, 'code_df.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(code_df[code_df['label'] == 1].SR_file_path.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Initialized Code File BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 25, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 100, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump', 'psg_len': 350, 'psg_stride': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': args.psg_cnt,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': args.rerank_depth,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "        'psg_len': args.psg_len,\n",
    "        'psg_stride': args.psg_stride\n",
    "    }\n",
    "\n",
    "code_reranker = BERTCodeReranker(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_code_triplets(code_df, code_reranker, cache_file, combined_df, overwrite=False):\n",
    "    print(f'Preparing code triplets from scratch for {len(code_df)} diffs with psg_len: {code_reranker.psg_len}, psg_stride: {code_reranker.psg_stride}, psg_cnt: {code_reranker.psg_cnt}')\n",
    "\n",
    "    if cache_file and os.path.exists(cache_file) and not overwrite:\n",
    "        print(f\"Loading data from cache file: {cache_file}\")\n",
    "        return pd.read_parquet(cache_file)\n",
    "\n",
    "    def prep_line(line):\n",
    "        return line.rstrip().lstrip()\n",
    "\n",
    "    def parse_diff(diff):\n",
    "        return [\n",
    "            line[1:] if line.startswith('+') else line\n",
    "            for line in diff.split('\\n')\n",
    "            if not (line.startswith('-') or len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "            and len(prep_line(line)) > 2\n",
    "        ]\n",
    "\n",
    "    def parse_diff2(diff):\n",
    "        return [\n",
    "            line[1:] if (line.startswith('+') or line.startswith('-')) else line\n",
    "            for line in diff.split('\\n')\n",
    "            if not (len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "        ]\n",
    "\n",
    "    def full_tokenize(s):\n",
    "        return code_reranker.tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()\n",
    "\n",
    "    def count_matching_lines(passage_lines, diff_lines):\n",
    "        # Create a 2D array to store the lengths of the longest common subsequences\n",
    "        dp = [[0] * (len(diff_lines) + 1) for _ in range(len(passage_lines) + 1)]\n",
    "\n",
    "        # Fill the dp array\n",
    "        for i in range(1, len(passage_lines) + 1):\n",
    "            for j in range(1, len(diff_lines) + 1):\n",
    "                if prep_line(passage_lines[i - 1]) == prep_line(diff_lines[j - 1]):\n",
    "                    dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "                else:\n",
    "                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "        return dp[-1][-1]\n",
    "\n",
    "    triplets = []\n",
    "\n",
    "    for _, row in tqdm(code_df.iterrows(), total=len(code_df)):\n",
    "        file_tokens = full_tokenize(row['SR_file_content'])\n",
    "        total_tokens = len(file_tokens)\n",
    "        cur_diff = combined_df[(combined_df['commit_id'] == row['SR_commit_id']) & (combined_df['file_path'] == row['SR_file_path'])]['diff'].values[0]\n",
    "\n",
    "        if pd.isna(cur_diff):\n",
    "            # if diff is NA/NaN, then skip this row\n",
    "            # possible when commit removes or renames this file or maybe god decided to remove the diff\n",
    "            continue\n",
    "\n",
    "        cur_diff_lines = parse_diff(cur_diff)\n",
    "        cur_triplets = []\n",
    "        for cur_start in range(0, total_tokens, code_reranker.psg_stride):\n",
    "            cur_passage = []\n",
    "\n",
    "            cur_passage.extend(file_tokens[cur_start:cur_start+code_reranker.psg_len])\n",
    "\n",
    "            # now convert cur_passage into a string\n",
    "            cur_passage_decoded = code_reranker.tokenizer.decode(cur_passage)\n",
    "\n",
    "            cur_passage_lines = cur_passage_decoded.split('\\n')\n",
    "\n",
    "            # remove lines with less than 2 characters\n",
    "            cur_passage_lines = [line for line in cur_passage_lines if len(prep_line(line)) > 2]\n",
    "\n",
    "            # check if there are lines matching the diff lines\n",
    "            # if there are, then we can add this directly to the triplets\n",
    "            # common_lines = set(cur_passage_lines).intersection(set(cur_diff_lines))\n",
    "            common_line_count = count_matching_lines(cur_passage_lines, cur_diff_lines)\n",
    "\n",
    "            # add the cur_passage to cur_result_passages\n",
    "            cur_triplets.append((common_line_count, (row['train_query'], row['SR_file_path'], cur_passage_decoded, row['label'])))\n",
    "\n",
    "        # sort the cur_triplets by the number of common lines\n",
    "        cur_triplets.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # now we want to filter cur_triplets to have all tuplets with x[0] > 3 to be in order and shuffle the rest\n",
    "\n",
    "        # now add the top code_reranker.psg_cnt to triplets\n",
    "        for triplet in cur_triplets[:code_reranker.psg_cnt]:\n",
    "            # print(f\"Found {triplet[0]} matching lines for diff in cur_passage at index\")\n",
    "            triplets.append(triplet[1])\n",
    "\n",
    "\n",
    "    # convert to pandas dataframe\n",
    "    triplets = pd.DataFrame(triplets, columns=['query', 'file_path', 'passage', 'label'])\n",
    "    if cache_file:\n",
    "        # with open(cache_file, 'wb') as file:\n",
    "        #     pickle.dump(triplets, file)\n",
    "        #     print(f\"Saved data to cache file: {cache_file}\")\n",
    "        print(f\"Saving data to cache file: {cache_file}\")\n",
    "        triplets.to_parquet(cache_file)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triplets_df = prepare_code_triplets(code_df, code_reranker, None, combined_df)\n",
    "triplets_df = pd.read_parquet(os.path.join(path, 'diff_code_triplets.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    42722\n",
       "1    11820\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('../gold/facebook_react/v2_facebook_react_gpt4_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2847\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for arr in train_df.actual_files_modified.tolist():\n",
    "    res.extend(arr)\n",
    "\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1085"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets_df[triplets_df['label'] == 1]['file_path'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function resolveLocksOnRoot(root: FiberRoot, expirationTime: ExpirationTime) {\n",
      "  const firstBatch = root.firstBatch;\n",
      "  if (\n",
      "    firstBatch !== null &&\n",
      "    firstBatch._defer &&\n",
      "    firstBatch._expirationTime >= expirationTime\n",
      "  ) {\n",
      "    scheduleCallback(NormalPriority, () => {\n",
      "      firstBatch._onComplete();\n",
      "      return null;\n",
      "    });\n",
      "    return true;\n",
      "  } else {\n",
      "    return false;\n",
      "  }\n",
      "}\n",
      "****************************************************************************************************\n",
      "function prepareFreshStack(root, expirationTime) {\n",
      "  root.finishedWork = null;\n",
      "  root.finishedExpirationTime = NoWork;\n",
      "\n",
      "  const timeoutHandle = root.timeoutHandle;\n",
      "  if (timeoutHandle !== noTimeout) {\n",
      "    // The root previous suspended and scheduled a timeout to commit a fallback\n",
      "    // state. Now that we have additional work, cancel the timeout.\n",
      "    root.timeoutHandle = noTimeout;\n",
      "    // $FlowFixMe Complains noTimeout is not a TimeoutID, despite the check above\n",
      "    cancelTimeout(timeoutHandle);\n",
      "  }\n",
      "\n",
      "  if (workInProgress !== null) {\n",
      "    let interruptedWork = workInProgress.return;\n",
      "    while (interruptedWork !== null) {\n",
      "      unwindInterruptedWork(interruptedWork);\n",
      "      interruptedWork = interruptedWork.return;\n",
      "    }\n",
      "  }\n",
      "  workInProgressRoot = root;\n",
      "  workInProgress = createWorkInProgress(root.current, null, expirationTime);\n",
      "  renderExpirationTime = expirationTime;\n",
      "  workInProgressRootExitStatus = RootIncomplete;\n",
      "  workInProgressRootMostRecentEventTime = Sync;\n",
      "\n",
      "  if (__DEV__) {\n",
      "    ReactStrictModeWarnings.discardPendingWarnings();\n",
      "    componentsWithSuspendedDiscreteUpdates = null;\n",
      "  }\n",
      "}\n",
      "****************************************************************************************************\n",
      "function computeUniqueAsyncExpiration(): ExpirationTime {\n",
      "  const currentTime = requestCurrentTime();\n",
      "  let result = computeAsyncExpiration(currentTime);\n",
      "  if (result <= lastUniqueAsyncExpiration) {\n",
      "    // Since we assume the current time monotonically increases, we only hit\n",
      "    // this branch when computeUniqueAsyncExpiration is fired multiple times\n",
      "    // within a 200ms window (or whatever the async bucket size is).\n",
      "    result -= 1;\n",
      "  }\n",
      "  lastUniqueAsyncExpiration = result;\n",
      "  return result;\n",
      "}\n",
      "****************************************************************************************************\n",
      "function scheduleUpdateOnFiber(\n",
      "  fiber: Fiber,\n",
      "  expirationTime: ExpirationTime,\n",
      ") {\n",
      "  checkForNestedUpdates();\n",
      "  warnAboutInvalidUpdatesOnClassComponentsInDEV(fiber);\n",
      "\n",
      "  const root = markUpdateTimeFromFiberToRoot(fiber, expirationTime);\n",
      "  if (root === null) {\n",
      "    warnAboutUpdateOnUnmountedFiberInDEV(fiber);\n",
      "    return;\n",
      "  }\n",
      "\n",
      "  root.pingTime = NoWork;\n",
      "\n",
      "  checkForInterruption(fiber, expirationTime);\n",
      "  recordScheduleUpdate();\n",
      "\n",
      "  if (expirationTime === Sync) {\n",
      "    if (workPhase === LegacyUnbatchedPhase) {\n",
      "      // Register pending interactions on the root to avoid losing traced interaction data.\n",
      "      schedulePendingInteraction(root, expirationTime);\n",
      "\n",
      "      // This is a legacy edge case. The initial mount of a ReactDOM.render-ed\n",
      "      // root inside of batchedUpdates should be synchronous, but layout updates\n",
      "      // should be deferred until the end of the batch.\n",
      "      let callback = renderRoot(root, Sync, true);\n",
      "      while (callback !== null) {\n",
      "        callback = callback(true);\n",
      "      }\n",
      "    } else {\n",
      "      scheduleCallbackForRoot(root, ImmediatePriority, Sync);\n",
      "      if (workPhase === NotWorking) {\n",
      "        // Flush the synchronous work now, wnless we're already working or inside\n",
      "        // a batch. This is intentionally inside scheduleUpdateOnFiber instead of\n",
      "        // scheduleCallbackForFiber to preserve the ability to schedule a callback\n",
      "        // without immediately flushing it. We only do this for user-initated\n",
      "        // updates, to preserve historical behavior of sync mode.\n",
      "        flushSyncCallbackQueue();\n",
      "      }\n",
      "    }\n",
      "  } else {\n",
      "    // TODO: computeExpirationForFiber also reads the priority. Pass the\n",
      "    // priority as an argument to that function and this one.\n",
      "    const priorityLevel = getCurrentPriorityLevel();\n",
      "    if (priorityLevel === UserBlockingPriority) {\n",
      "      // This is the result of a discrete event. Track the lowest priority\n",
      "      // discrete update per root so we can flush them early, if needed.\n",
      "      if (rootsWithPendingDiscreteUpdates === null) {\n",
      "        rootsWithPendingDiscreteUpdates = new Map([[root, expirationTime]]);\n",
      "      } else {\n",
      "        const lastDiscreteTime = rootsWithPendingDiscreteUpdates.get(root);\n",
      "        if (\n",
      "          lastDiscreteTime === undefined ||\n",
      "          lastDiscreteTime > expirationTime\n",
      "        ) {\n",
      "          rootsWithPendingDiscreteUpdates.set(root, expirationTime);\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    scheduleCallbackForRoot(root, priorityLevel, expirationTime);\n",
      "  }\n",
      "}\n",
      "****************************************************************************************************\n",
      "function markUpdateTimeFromFiberToRoot(fiber, expirationTime) {\n",
      "  // Update the source fiber's expiration time\n",
      "  if (fiber.expirationTime < expirationTime) {\n",
      "    fiber.expirationTime = expirationTime;\n",
      "  }\n",
      "  let alternate = fiber.alternate;\n",
      "  if (alternate !== null && alternate.expirationTime < expirationTime) {\n",
      "    alternate.expirationTime = expirationTime;\n",
      "  }\n",
      "  // Walk the parent path to the root and update the child expiration time.\n",
      "  let node = fiber.return;\n",
      "  let root = null;\n",
      "  if (node === null && fiber.tag === HostRoot) {\n",
      "    root = fiber.stateNode;\n",
      "  } else {\n",
      "    while (node !== null) {\n",
      "      alternate = node.alternate;\n",
      "      if (node.childExpirationTime < expirationTime) {\n",
      "        node.childExpirationTime = expirationTime;\n",
      "        if (\n",
      "          alternate !== null &&\n",
      "          alternate.childExpirationTime < expirationTime\n",
      "        ) {\n",
      "          alternate.childExpirationTime = expirationTime;\n",
      "        }\n",
      "      } else if (\n",
      "        alternate !== null &&\n",
      "        alternate.childExpirationTime < expirationTime\n",
      "      ) {\n",
      "        alternate.childExpirationTime = expirationTime;\n",
      "      }\n",
      "      if (node.return === null && node.tag === HostRoot) {\n",
      "        root = node.stateNode;\n",
      "        break;\n",
      "      }\n",
      "      node = node.return;\n",
      "    }\n",
      "  }\n",
      "\n",
      "  if (root !== null) {\n",
      "    // Update the first and last pending expiration times in this root\n",
      "    const firstPendingTime = root.firstPendingTime;\n",
      "    if (expirationTime > firstPendingTime) {\n",
      "      root.firstPendingTime = expirationTime;\n",
      "    }\n",
      "    const lastPendingTime = root.lastPendingTime;\n",
      "    if (lastPendingTime === NoWork || expirationTime < lastPendingTime) {\n",
      "      root.lastPendingTime = expirationTime;\n",
      "    }\n",
      "  }\n",
      "\n",
      "  return root;\n",
      "}\n",
      "****************************************************************************************************\n",
      "function scheduleCallbackForRoot(\n",
      "  root: FiberRoot,\n",
      "  priorityLevel: ReactPriorityLevel,\n",
      "  expirationTime: ExpirationTime,\n",
      ") {\n",
      "  const existingCallbackExpirationTime = root.callbackExpirationTime;\n",
      "  if (existingCallbackExpirationTime < expirationTime) {\n",
      "    // New callback has higher priority than the existing one.\n",
      "    const existingCallbackNode = root.callbackNode;\n",
      "    if (existingCallbackNode !== null) {\n",
      "      cancelCallback(existingCallbackNode);\n",
      "    }\n",
      "    root.callbackExpirationTime = expirationTime;\n",
      "\n",
      "    if (expirationTime === Sync) {\n",
      "      // Sync React callbacks are scheduled on a special internal queue\n",
      "      root.callbackNode = scheduleSyncCallback(\n",
      "        runRootCallback.bind(\n",
      "          null,\n",
      "          root,\n",
      "          renderRoot.bind(null, root, expirationTime),\n",
      "        ),\n",
      "      );\n",
      "    } else {\n",
      "      let options = null;\n",
      "      if (expirationTime !== Sync && expirationTime !== Never) {\n",
      "        let timeout = expirationTimeToMs(expirationTime) - now();\n",
      "        if (timeout > 5000) {\n",
      "          // Sanity check. Should never take longer than 5 seconds.\n",
      "          // TODO: Add internal warning?\n",
      "          timeout = 5000;\n",
      "        }\n",
      "        options = {timeout};\n",
      "      }\n",
      "\n",
      "      root.callbackNode = scheduleCallback(\n",
      "        priorityLevel,\n",
      "        runRootCallback.bind(\n",
      "          null,\n",
      "          root,\n",
      "          renderRoot.bind(null, root, expirationTime),\n",
      "        ),\n",
      "        options,\n",
      "      );\n",
      "      if (\n",
      "        enableUserTimingAPI &&\n",
      "        expirationTime !== Sync &&\n",
      "        workPhase !== RenderPhase &&\n",
      "        workPhase !== CommitPhase\n",
      "      ) {\n",
      "        // Scheduled an async callback, and we're not already working. Add an\n",
      "        // entry to the flamegraph that shows we're waiting for a callback\n",
      "        // to fire.\n",
      "        startRequestCallbackTimer();\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  // Add the current set of interactions to the pending set associated with\n",
      "  // this root.\n",
      "  schedulePendingInteraction(root, expirationTime);\n",
      "}\n",
      "****************************************************************************************************\n",
      "function runRootCallback(root, callback, isSync) {\n",
      "  const prevCallbackNode = root.callbackNode;\n",
      "  let continuation = null;\n",
      "  try {\n",
      "    continuation = callback(isSync);\n",
      "    if (continuation !== null) {\n",
      "      return runRootCallback.bind(null, root, continuation);\n",
      "    } else {\n",
      "      return null;\n",
      "    }\n",
      "  } finally {\n",
      "    // If the callback exits without returning a continuation, remove the\n",
      "    // corresponding callback node from the root. Unless the callback node\n",
      "    // has changed, which implies that it was already cancelled by a high\n",
      "    // priority update.\n",
      "    if (continuation === null && prevCallbackNode === root.callbackNode) {\n",
      "      root.callbackNode = null;\n",
      "      root.callbackExpirationTime = NoWork;\n",
      "    }\n",
      "  }\n",
      "}\n",
      "****************************************************************************************************\n",
      "function flushRoot(root: FiberRoot, expirationTime: ExpirationTime) {\n",
      "  if (workPhase === RenderPhase || workPhase === CommitPhase) {\n",
      "    invariant(\n",
      "      false,\n",
      "      'work.commit(): Cannot commit while already rendering. This likely ' +\n",
      "        'means you attempted to commit from inside a lifecycle method.',\n",
      "    );\n",
      "  }\n",
      "  scheduleSyncCallback(renderRoot.bind(null, root, expirationTime));\n",
      "  flushSyncCallbackQueue();\n",
      "}\n",
      "****************************************************************************************************\n",
      "function requestCurrentTime() {\n",
      "  if (workPhase === RenderPhase || workPhase === CommitPhase) {\n",
      "    // We're inside React, so it's fine to read the actual time.\n",
      "    return msToExpirationTime(now());\n",
      "  }\n",
      "  // We're not inside React, so we may be in the middle of a browser event.\n",
      "  if (currentEventTime !== NoWork) {\n",
      "    // Use the same start time for all updates until we enter React again.\n",
      "    return currentEventTime;\n",
      "  }\n",
      "  // This is the first update since React yielded. Compute a new start time.\n",
      "  currentEventTime = msToExpirationTime(now());\n",
      "  return currentEventTime;\n",
      "}\n",
      "****************************************************************************************************\n",
      "function computeExpirationForFiber(\n",
      "  currentTime: ExpirationTime,\n",
      "  fiber: Fiber,\n",
      "): ExpirationTime {\n",
      "  const mode = fiber.mode;\n",
      "  if ((mode & BatchedMode) === NoMode) {\n",
      "    return Sync;\n",
      "  }\n",
      "\n",
      "  const priorityLevel = getCurrentPriorityLevel();\n",
      "  if ((mode & ConcurrentMode) === NoMode) {\n",
      "    return priorityLevel === ImmediatePriority ? Sync : Batched;\n",
      "  }\n",
      "\n",
      "  if (workPhase === RenderPhase) {\n",
      "    // Use whatever time we're already rendering\n",
      "    return renderExpirationTime;\n",
      "  }\n",
      "\n",
      "  // Compute an expiration time based on the Scheduler priority.\n",
      "  let expirationTime;\n",
      "  switch (priorityLevel) {\n",
      "    case ImmediatePriority:\n",
      "      expirationTime = Sync;\n",
      "      break;\n",
      "    case UserBlockingPriority:\n",
      "      // TODO: Rename this to computeUserBlockingExpiration\n",
      "      expirationTime = computeInteractiveExpiration(currentTime);\n",
      "      break;\n",
      "    case NormalPriority:\n",
      "    case LowPriority: // TODO: Handle LowPriority\n",
      "      // TODO: Rename this to... something better.\n",
      "      expirationTime = computeAsyncExpiration(currentTime);\n",
      "      break;\n",
      "    case IdlePriority:\n",
      "      expirationTime = Never;\n",
      "      break;\n",
      "    default:\n",
      "      invariant(false, 'Expected a valid priority level');\n",
      "  }\n",
      "\n",
      "  // If we're in the middle of rendering a tree, do not update at the same\n",
      "  // expiration time that is already rendering.\n",
      "  if (workInProgressRoot !== null && expirationTime === renderExpirationTime) {\n",
      "    // This is a trick to move this update into a separate batch\n",
      "    expirationTime -= 1;\n",
      "  }\n",
      "\n",
      "  return expirationTime;\n",
      "}\n",
      "****************************************************************************************************\n",
      "function flushInteractiveUpdates() {\n",
      "  if (workPhase === RenderPhase || workPhase === CommitPhase) {\n",
      "    // Can't synchronously flush interactive updates if React is already\n",
      "    // working. This is currently a no-op.\n",
      "    // TODO: Should we fire a warning? This happens if you synchronously invoke\n",
      "    // an input event inside an effect, like with `element.click()`.\n",
      "    return;\n",
      "  }\n",
      "  flushPendingDiscreteUpdates();\n",
      "}\n",
      "****************************************************************************************************\n",
      "function warnAboutInvalidUpdatesOnClassComponentsInDEV(fiber) {\n",
      "  if (__DEV__) {\n",
      "    if (fiber.tag === ClassComponent) {\n",
      "      switch (ReactCurrentDebugFiberPhaseInDEV) {\n",
      "        case 'getChildContext':\n",
      "          if (didWarnAboutUpdateInGetChildContext) {\n",
      "            return;\n",
      "          }\n",
      "          warningWithoutStack(\n",
      "            false,\n",
      "            'setState(...): Cannot call setState() inside getChildContext()',\n",
      "          );\n",
      "          didWarnAboutUpdateInGetChildContext = true;\n",
      "          break;\n",
      "        case 'render':\n",
      "          if (didWarnAboutUpdateInRender) {\n",
      "            return;\n",
      "          }\n",
      "          warningWithoutStack(\n",
      "            false,\n",
      "            'Cannot update during an existing state transition (such as ' +\n",
      "              'within `render`). Render methods should be a pure function of ' +\n",
      "              'props and state.',\n",
      "          );\n",
      "          didWarnAboutUpdateInRender = true;\n",
      "          break;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for p in triplets_df[triplets_df['file_path'] == 'packages/react-reconciler/src/ReactFiberScheduler.js'].passage.values:\n",
    "    if len(p) > 0:\n",
    "        print(p)\n",
    "        print('*' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    1750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    225310\n",
       "1     61222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) Facebook, Inc. and its a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c22b94f14a809abb376f07a53f36860a7c6a342e</td>\n",
       "      <td>src/renderers/shared/fiber/ReactChildFiber.js</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright 2013-present, Facebook, Inc....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f74eca9937ad6f19b6291d21edfb8747bae88ca</td>\n",
       "      <td>src/renderers/dom/fiber/__tests__/ReactDOMFibe...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright 2013-present, Facebook, Inc....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberRoot.js</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) Facebook, Inc. and its a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberUnwind...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) 2013-present, Facebook, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_id  \\\n",
       "0  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "1  c22b94f14a809abb376f07a53f36860a7c6a342e   \n",
       "2  1f74eca9937ad6f19b6291d21edfb8747bae88ca   \n",
       "3  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "4  9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1      src/renderers/shared/fiber/ReactChildFiber.js   \n",
       "2  src/renderers/dom/fiber/__tests__/ReactDOMFibe...   \n",
       "3    packages/react-reconciler/src/ReactFiberRoot.js   \n",
       "4  packages/react-reconciler/src/ReactFiberUnwind...   \n",
       "\n",
       "                                               query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                             passage  label  \n",
       "0  /**\\n * Copyright (c) Facebook, Inc. and its a...      0  \n",
       "1  /**\\n * Copyright 2013-present, Facebook, Inc....      0  \n",
       "2  /**\\n * Copyright 2013-present, Facebook, Inc....      0  \n",
       "3  /**\\n * Copyright (c) Facebook, Inc. and its a...      0  \n",
       "4  /**\\n * Copyright (c) 2013-present, Facebook, ...      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6750 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "for i, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if row['label'] == 0:\n",
    "            assert data[(data['query'] == row['query']) & (data['commit_id'] == row['commit_id']) & (data['file_path'] == row['file_path'])]['label'].values[0] == 0\n",
    "        else:\n",
    "            assert data[(data['query'] == row['query']) & (data['commit_id'] == row['commit_id']) & (data['file_path'] == row['file_path'])]['label'].values[0] == 1\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>file_path</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushPassiveEffects();\\n      return null;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Time;\\n      if (childUpdateExpirationTime &gt; n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n          let msUntilTimeout = computeMsUn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>root. Don't need to schedule a ping because\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgress!== null) {\\n      // Ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "2  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "3  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "4  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "\n",
       "                                             passage  label  \n",
       "0      flushPassiveEffects();\\n      return null;...      0  \n",
       "1  Time;\\n      if (childUpdateExpirationTime > n...      0  \n",
       "2   {\\n          let msUntilTimeout = computeMsUn...      0  \n",
       "3   root. Don't need to schedule a ping because\\n...      0  \n",
       "4    if (workInProgress!== null) {\\n      // Ther...      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286532 entries, 0 to 286531\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   query      286532 non-null  object\n",
      " 1   file_path  286532 non-null  object\n",
      " 2   passage    286532 non-null  object\n",
      " 3   label      286532 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    225310\n",
       "1     61222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>file_path</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushPassiveEffects();\\n      return null;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Time;\\n      if (childUpdateExpirationTime &gt; n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n          let msUntilTimeout = computeMsUn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>root. Don't need to schedule a ping because\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgress!== null) {\\n      // Ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>);\\n            return null;\\n         ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>function resolveLocksOnRoot(root: FiberRoot, e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>, try rendering\\n        // at the lower prior...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n    ReactStrictModeWarnings.discardPending...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushRoot(root: FiberRoot, expirationTime: Ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>ity, fn.bind(null, a));\\n  } finally {\\n    wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>pirationTime === expirationTime) {\\n    // The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>pendingPassiveEffectsExpirationTime = expirat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n  // this root.\\n  schedulePendingInteractio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>additional work.\\n    return null;\\n  }\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Root.bind(null, root);\\n    }\\n    case RootSu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.\\n    legacyErrorBoundariesThatAlreadyFailed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>. We just committed the initial mount of\\n    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Priority:\\n      // TODO: Rename this to compu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>;\\n  }\\n\\n  return expirationTime;\\n}\\n\\nlet l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n      // discrete update per root so we can ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>we can mark a fiber with pending\\n// work wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (node.childExpirationTime &lt; expirationT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>node = node.return;\\n    }\\n  }\\n\\n  if (root...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>// should cancel the previous one. It also rel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Callback.bind(\\n          null,\\n          roo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Phase!== FlushSyncPhase) {\\n    // We're not i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.timeoutHandle;\\n  if (timeoutHandle!== noTime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.\\n      // Instead the first renderer will la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n        // single batch.\\n        const curr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgressRootExitStatus === RootInco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>ate;\\n    const returnFiber = workInProgress.r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>}\\n      stopWorkTimer(workInProgress);\\n ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>}\\n      }\\n    } else {\\n      // This ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>next.effectTag &amp;= HostEffectMask;\\n      ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>the root.\\n  if (workInProgressRootExitStatus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>finishes synchronously.\\n  // So we can clear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n        nextEffect.effectTag &amp;= ~Placement;\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>function commitLayoutEffects(\\n  root: FiberRo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Malformed data types (`commitDetails`, `intera...   \n",
       "1   Malformed data types (`commitDetails`, `intera...   \n",
       "2   Malformed data types (`commitDetails`, `intera...   \n",
       "3   Malformed data types (`commitDetails`, `intera...   \n",
       "4   Malformed data types (`commitDetails`, `intera...   \n",
       "5   Malformed data types (`commitDetails`, `intera...   \n",
       "6   Malformed data types (`commitDetails`, `intera...   \n",
       "7   Malformed data types (`commitDetails`, `intera...   \n",
       "8   Malformed data types (`commitDetails`, `intera...   \n",
       "9   Malformed data types (`commitDetails`, `intera...   \n",
       "10  Malformed data types (`commitDetails`, `intera...   \n",
       "11  Malformed data types (`commitDetails`, `intera...   \n",
       "12  Malformed data types (`commitDetails`, `intera...   \n",
       "13  Malformed data types (`commitDetails`, `intera...   \n",
       "14  Malformed data types (`commitDetails`, `intera...   \n",
       "15  Malformed data types (`commitDetails`, `intera...   \n",
       "16  Malformed data types (`commitDetails`, `intera...   \n",
       "17  Malformed data types (`commitDetails`, `intera...   \n",
       "18  Malformed data types (`commitDetails`, `intera...   \n",
       "19  Malformed data types (`commitDetails`, `intera...   \n",
       "20  Malformed data types (`commitDetails`, `intera...   \n",
       "21  Malformed data types (`commitDetails`, `intera...   \n",
       "22  Malformed data types (`commitDetails`, `intera...   \n",
       "23  Malformed data types (`commitDetails`, `intera...   \n",
       "24  Malformed data types (`commitDetails`, `intera...   \n",
       "25  Malformed data types (`commitDetails`, `intera...   \n",
       "26  Malformed data types (`commitDetails`, `intera...   \n",
       "27  Malformed data types (`commitDetails`, `intera...   \n",
       "28  Malformed data types (`commitDetails`, `intera...   \n",
       "29  Malformed data types (`commitDetails`, `intera...   \n",
       "30  Malformed data types (`commitDetails`, `intera...   \n",
       "31  Malformed data types (`commitDetails`, `intera...   \n",
       "32  Malformed data types (`commitDetails`, `intera...   \n",
       "33  Malformed data types (`commitDetails`, `intera...   \n",
       "34  Malformed data types (`commitDetails`, `intera...   \n",
       "35  Malformed data types (`commitDetails`, `intera...   \n",
       "36  Malformed data types (`commitDetails`, `intera...   \n",
       "37  Malformed data types (`commitDetails`, `intera...   \n",
       "38  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                            file_path  \\\n",
       "0   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "2   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "3   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "4   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "5   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "6   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "7   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "8   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "9   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "10  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "11  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "12  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "13  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "14  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "15  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "16  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "17  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "18  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "19  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "20  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "21  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "22  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "23  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "24  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "25  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "26  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "27  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "28  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "29  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "30  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "31  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "32  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "33  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "34  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "35  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "36  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "37  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "38  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "\n",
       "                                              passage  label  \n",
       "0       flushPassiveEffects();\\n      return null;...      0  \n",
       "1   Time;\\n      if (childUpdateExpirationTime > n...      0  \n",
       "2    {\\n          let msUntilTimeout = computeMsUn...      0  \n",
       "3    root. Don't need to schedule a ping because\\n...      0  \n",
       "4     if (workInProgress!== null) {\\n      // Ther...      0  \n",
       "5          );\\n            return null;\\n         ...      0  \n",
       "6   function resolveLocksOnRoot(root: FiberRoot, e...      0  \n",
       "7   , try rendering\\n        // at the lower prior...      0  \n",
       "8    {\\n    ReactStrictModeWarnings.discardPending...      0  \n",
       "9    flushRoot(root: FiberRoot, expirationTime: Ex...      0  \n",
       "10  ity, fn.bind(null, a));\\n  } finally {\\n    wo...      0  \n",
       "11  pirationTime === expirationTime) {\\n    // The...      0  \n",
       "12   pendingPassiveEffectsExpirationTime = expirat...      0  \n",
       "13  \\n  // this root.\\n  schedulePendingInteractio...      0  \n",
       "14   additional work.\\n    return null;\\n  }\\n\\n  ...      0  \n",
       "15  Root.bind(null, root);\\n    }\\n    case RootSu...      0  \n",
       "16  .\\n    legacyErrorBoundariesThatAlreadyFailed ...      0  \n",
       "17  . We just committed the initial mount of\\n    ...      0  \n",
       "18  Priority:\\n      // TODO: Rename this to compu...      0  \n",
       "19  ;\\n  }\\n\\n  return expirationTime;\\n}\\n\\nlet l...      0  \n",
       "20  \\n      // discrete update per root so we can ...      0  \n",
       "21   we can mark a fiber with pending\\n// work wit...      0  \n",
       "22      if (node.childExpirationTime < expirationT...      0  \n",
       "23   node = node.return;\\n    }\\n  }\\n\\n  if (root...      0  \n",
       "24  // should cancel the previous one. It also rel...      0  \n",
       "25  Callback.bind(\\n          null,\\n          roo...      0  \n",
       "26  Phase!== FlushSyncPhase) {\\n    // We're not i...      0  \n",
       "27  .timeoutHandle;\\n  if (timeoutHandle!== noTime...      0  \n",
       "28  .\\n      // Instead the first renderer will la...      0  \n",
       "29  \\n        // single batch.\\n        const curr...      0  \n",
       "30   if (workInProgressRootExitStatus === RootInco...      0  \n",
       "31  ate;\\n    const returnFiber = workInProgress.r...      0  \n",
       "32      }\\n      stopWorkTimer(workInProgress);\\n ...      0  \n",
       "33        }\\n      }\\n    } else {\\n      // This ...      0  \n",
       "34       next.effectTag &= HostEffectMask;\\n      ...      0  \n",
       "35   the root.\\n  if (workInProgressRootExitStatus...      0  \n",
       "36   finishes synchronously.\\n  // So we can clear...      0  \n",
       "37  \\n        nextEffect.effectTag &= ~Placement;\\...      0  \n",
       "38  function commitLayoutEffects(\\n  root: FiberRo...      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    1750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of label column\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCodeReranker:\n",
    "    def __init__(self, parameters):\n",
    "        self.parameters = parameters\n",
    "        self.model_name = parameters['model_name']\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=1, problem_type='regression')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and parameters['use_gpu'] else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(f'Using device: {self.device}')\n",
    "\n",
    "        # print GPU info\n",
    "        if torch.cuda.is_available() and parameters['use_gpu']:\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f'GPU Device Count: {torch.cuda.device_count()}')\n",
    "            print(f\"GPU Memory Usage: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "\n",
    "        self.psg_len = parameters['psg_len']\n",
    "        self.psg_cnt = parameters['psg_cnt'] # how many contributing_results to use per file for reranking\n",
    "        self.psg_stride = parameters.get('psg_stride', self.psg_len)\n",
    "        self.aggregation_strategy = parameters['aggregation_strategy'] # how to aggregate the scores of the psg_cnt contributing_results\n",
    "        self.batch_size = parameters['batch_size'] # batch size for reranking efficiently\n",
    "        self.rerank_depth = parameters['rerank_depth']\n",
    "        self.max_seq_length = self.tokenizer.model_max_length # max sequence length for the model\n",
    "\n",
    "        print(f\"Initialized Code File BERT reranker with parameters: {parameters}\")\n",
    "\n",
    "\n",
    "    def rerank(self, query, aggregated_results):\n",
    "        \"\"\"\n",
    "        Rerank the BM25 aggregated search results using BERT model scores.\n",
    "\n",
    "        query: The issue query string.\n",
    "        aggregated_results: A list of AggregatedSearchResult objects from BM25 search.\n",
    "        \"\"\"\n",
    "        # aggregated_results = aggregated_results[:self.rerank_depth] # already done in the pipeline\n",
    "        # print(f'Reranking {len(aggregated_results)} results')\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        query_passage_pairs, per_result_contribution = self.split_into_query_passage_pairs(query, aggregated_results)\n",
    "\n",
    "\n",
    "        # for agg_result in aggregated_results:\n",
    "        #     query_passage_pairs.extend(\n",
    "        #         (query, result.commit_message)\n",
    "        #         for result in agg_result.contributing_results[: self.psg_cnt]\n",
    "        #     )\n",
    "\n",
    "        if not query_passage_pairs:\n",
    "            print('WARNING: No query passage pairs to rerank, returning original results from previous stage')\n",
    "            print(query, aggregated_results, self.psg_cnt)\n",
    "            return aggregated_results\n",
    "\n",
    "        # tokenize the query passage pairs\n",
    "        encoded_pairs = [self.tokenizer.encode_plus([query, passage], max_length=self.max_seq_length, truncation=True, padding='max_length', return_tensors='pt', add_special_tokens=True) for query, passage in query_passage_pairs]\n",
    "\n",
    "        # create tensors for the input ids, attention masks\n",
    "        input_ids = torch.stack([encoded_pair['input_ids'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "        attention_masks = torch.stack([encoded_pair['attention_mask'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "\n",
    "        # Create a dataloader for feeding the data to the model\n",
    "        dataset = TensorDataset(input_ids, attention_masks)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False) # shuffle=False very important for reconstructing the results back into the original order\n",
    "\n",
    "        scores = self.get_scores(dataloader, self.model)\n",
    "\n",
    "        score_index = 0\n",
    "        # Now assign the scores to the aggregated results by mapping the scores to the contributing results\n",
    "        for i, agg_result in enumerate(aggregated_results):\n",
    "            # Each aggregated result gets a slice of the scores equal to the number of contributing results it has which should be min(psg_cnt, len(contributing_results))\n",
    "            assert score_index < len(scores), f'score_index {score_index} is greater than or equal to scores length {len(scores)}'\n",
    "            end_index = score_index + per_result_contribution[i] # only use psg_cnt contributing_results\n",
    "            cur_passage_scores = scores[score_index:end_index]\n",
    "            score_index = end_index\n",
    "\n",
    "\n",
    "            # Aggregate the scores for the current aggregated result\n",
    "            agg_score = self.aggregate_scores(cur_passage_scores)\n",
    "            agg_result.score = agg_score  # Assign the aggregated score\n",
    "\n",
    "        assert score_index == len(scores), f'score_index {score_index} does not equal scores length {len(scores)}, indices probably not working correctly'\n",
    "\n",
    "        # Sort by the new aggregated score\n",
    "        aggregated_results.sort(key=lambda res: res.score, reverse=True)\n",
    "\n",
    "        return aggregated_results\n",
    "\n",
    "    def get_scores(self, dataloader, model):\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Unpack the batch and move it to GPU\n",
    "                b_input_ids, b_attention_mask = batch\n",
    "                b_input_ids = b_input_ids.to(self.device)\n",
    "                b_attention_mask = b_attention_mask.to(self.device)\n",
    "\n",
    "                # Get scores from the model\n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_mask)\n",
    "                scores.extend(outputs.logits.detach().cpu().numpy().squeeze(-1))\n",
    "        return scores\n",
    "\n",
    "    def aggregate_scores(self, passage_scores):\n",
    "        \"\"\"\n",
    "        Aggregate passage scores based on the specified strategy.\n",
    "        \"\"\"\n",
    "        if len(passage_scores) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        if self.aggregation_strategy == 'firstp':\n",
    "            return passage_scores[0]\n",
    "        if self.aggregation_strategy == 'maxp':\n",
    "            return max(passage_scores)\n",
    "        if self.aggregation_strategy == 'avgp':\n",
    "            return sum(passage_scores) / len(passage_scores)\n",
    "        if self.aggregation_strategy == 'sump':\n",
    "            return sum(passage_scores)\n",
    "        # else:\n",
    "        raise ValueError(f\"Invalid score aggregation method: {self.aggregation_strategy}\")\n",
    "\n",
    "\n",
    "    def split_into_query_passage_pairs(self, query, aggregated_results):\n",
    "        # Flatten the list of results into a list of (query, passage) pairs but only keep max psg_cnt passages per file\n",
    "        def full_tokenize(s):\n",
    "            return self.tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()\n",
    "        query_passage_pairs = []\n",
    "        per_result_contribution = []\n",
    "        for agg_result in aggregated_results:\n",
    "            agg_result.contributing_results.sort(key=lambda res: res.commit_date, reverse=True)\n",
    "            # get most recent file version\n",
    "            most_recent_search_result = agg_result.contributing_results[0]\n",
    "            # get the file_path and commit_id\n",
    "            file_path = most_recent_search_result.file_path\n",
    "            commit_id = most_recent_search_result.commit_id\n",
    "            # get the file content from combined_df\n",
    "            file_content = combined_df[(combined_df['commit_id'] == commit_id) & (combined_df['file_path'] == file_path)]['cur_file_content'].values[0]\n",
    "\n",
    "            # now need to split this file content into psg_cnt passages\n",
    "            # first tokenize the file content\n",
    "\n",
    "            # warning these asserts are useless since we are using NaNs\n",
    "            assert file_content is not None, f'file_content is None for commit_id: {commit_id}, file_path: {file_path}'\n",
    "            assert file_path is not None, f'file_path is None for commit_id: {commit_id}'\n",
    "            assert query is not None, f'query is None'\n",
    "\n",
    "            query_tokens = full_tokenize(query)\n",
    "            path_tokens = full_tokenize(file_path)\n",
    "\n",
    "            if pd.isna(file_content):\n",
    "                # if file_content is NaN, then we can just set file_content to empty string\n",
    "                print(f'WARNING: file_content is NaN for commit_id: {commit_id}, file_path: {file_path}, setting file_content to empty string')\n",
    "                file_content = ''\n",
    "\n",
    "            file_tokens = full_tokenize(file_content)\n",
    "\n",
    "\n",
    "            # now split the file content into psg_cnt passages\n",
    "            cur_result_passages = []\n",
    "            # get the input ids\n",
    "            # input_ids = file_content['input_ids'].squeeze()\n",
    "            # get the number of tokens in the file content\n",
    "            total_tokens = len(file_tokens)\n",
    "\n",
    "            for cur_start in range(0, total_tokens, self.psg_stride):\n",
    "                cur_passage = []\n",
    "                # add query tokens and path tokens\n",
    "                # cur_passage.extend(query_tokens) # ??????????????\n",
    "                cur_passage.extend(path_tokens)\n",
    "\n",
    "                # add the file tokens\n",
    "                cur_passage.extend(file_tokens[cur_start:cur_start+self.psg_len])\n",
    "\n",
    "                # now convert cur_passage into a string\n",
    "                cur_passage_decoded = self.tokenizer.decode(cur_passage)\n",
    "\n",
    "                # add the cur_passage to cur_result_passages\n",
    "                cur_result_passages.append(cur_passage_decoded)\n",
    "\n",
    "                if len(cur_result_passages) == self.psg_cnt:\n",
    "                    break\n",
    "\n",
    "            # now add the query, passage pairs to query_passage_pairs\n",
    "            per_result_contribution.append(len(cur_result_passages))\n",
    "            query_passage_pairs.extend((query, passage) for passage in cur_result_passages)\n",
    "        return query_passage_pairs, per_result_contribution\n",
    "\n",
    "    def rerank_pipeline(self, query, aggregated_results):\n",
    "        if len(aggregated_results) == 0:\n",
    "            return aggregated_results\n",
    "        top_results = aggregated_results[:self.rerank_depth]\n",
    "        bottom_results = aggregated_results[self.rerank_depth:]\n",
    "        reranked_results = self.rerank(query, top_results)\n",
    "        min_top_score = reranked_results[-1].score\n",
    "        # now adjust the scores of bottom_results\n",
    "        for i, result in enumerate(bottom_results):\n",
    "            result.score = min_top_score - i - 1\n",
    "        # combine the results\n",
    "        reranked_results.extend(bottom_results)\n",
    "        assert(len(reranked_results) == len(aggregated_results))\n",
    "        return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='../smalldata/ftr/index_commit_tokenized', repo_path='../smalldata/ftr', k=1000, n=100, model_path='microsoft/codebert-base', overwrite_cache=False, batch_size=32, num_epochs=10, learning_rate=5e-05, num_positives=10, num_negatives=10, train_depth=1000, num_workers=8, train_commits=1000, psg_cnt=25, aggregation_strategy='sump', use_gpu=True, rerank_depth=100, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4', overwrite_eval=False, sanity_check=True, debug=False, best_model_path=None, bert_best_model='../data/combined_commit_train/best_model', psg_len=350, psg_stride=300, ignore_gold_in_training=False, eval_folder='code_rerank', use_gpt_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../smalldata/ftr/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['MAP', 'P@10', 'P@100', 'P@1000', 'MRR', 'Recall@100', 'Recall@1000']\n",
    "repo_path = args.repo_path\n",
    "repo_name = repo_path.split('/')[-1]\n",
    "index_path = args.index_path\n",
    "K = args.k\n",
    "n = args.n\n",
    "combined_df = get_combined_df(repo_path)\n",
    "BM25_AGGR_STRAT = 'sump'\n",
    "eval_path = os.path.join(repo_path, 'eval')\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "bm25_searcher = BM25Searcher(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "\n",
    "test_path = os.path.join('..', 'gold', 'facebook_react', 'v2_facebook_react_gpt4_gold.parquet')\n",
    "gold_df = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:23<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Baseline Evaluation\n",
      "{'MAP': 0.1542, 'P@10': 0.087, 'P@100': 0.0267, 'P@1000': 0.0041, 'MRR': 0.2133, 'Recall@100': 0.5077, 'Recall@1000': 0.6845}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bm25_baseline_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=BM25_AGGR_STRAT)\n",
    "\n",
    "print(\"BM25 Baseline Evaluation\")\n",
    "print(bm25_baseline_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': 5,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': 250,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 476.73 MB\n",
      "Initialized BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 5, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 250, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_path = os.path.join('data', 'combined_commit_train', 'best_model')\n",
    "bert_reranker = BERTReranker(bert_params)\n",
    "bert_reranker.model = AutoModelForSequenceClassification.from_pretrained(args.bert_best_model, num_labels=1, problem_type='regression')\n",
    "bert_reranker.model.to(bert_reranker.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 953.46 MB\n",
      "Initialized Code File BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 25, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 100, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump', 'psg_len': 350, 'psg_stride': 250}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerankers = [bert_reranker, code_reranker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n",
      "Found gold_df, evaluating on 1 commits\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 1 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   commit_id                 1 non-null      string\n",
      " 1   commit_date               1 non-null      int64 \n",
      " 2   commit_message            1 non-null      string\n",
      " 3   actual_files_modified     1 non-null      object\n",
      " 4   transformed_message_gpt4  1 non-null      object\n",
      "dtypes: int64(1), object(2), string(2)\n",
      "memory usage: 172.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "bert_gold_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=params['aggregation_strategy'], rerankers=rerankers, gold_df=gold_df.iloc[1:2])\n",
    "\n",
    "print(\"BERT Gold Evaluation\")\n",
    "print(bert_gold_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>file_path</th>\n",
       "      <th>previous_commit_id</th>\n",
       "      <th>previous_file_content</th>\n",
       "      <th>cur_file_content</th>\n",
       "      <th>diff</th>\n",
       "      <th>status</th>\n",
       "      <th>is_merge_request</th>\n",
       "      <th>file_extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696522497</td>\n",
       "      <td>dddfe688206dafa5646550d351eb9a8e9c53654a</td>\n",
       "      <td>pull implementations from the right react-dom ...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696521194</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>`react-dom/server-rendering-stub`: restore exp...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>16619f106ab5ba8e6aca19d55be46cce22e4a7ff</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-dom/src/__tests__/ReactDOMFizzS...</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-server/src/ReactFizzServer.js</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -1110,7 +1110,6 @@ function replaySuspenseB...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696450581</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>Move ReactCurrentDispatcher back to shared int...</td>\n",
       "      <td>packages/react-server/src/ReactFlightServer.js</td>\n",
       "      <td>ca237d6f0ab986e799f192224d3066f76d66b73b</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      owner repo_name  commit_date                                 commit_id  \\\n",
       "0  facebook     react   1696522497  dddfe688206dafa5646550d351eb9a8e9c53654a   \n",
       "1  facebook     react   1696521194  546178f9109424f6a0176ea8702a7620c4417569   \n",
       "2  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "3  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "4  facebook     react   1696450581  6f132439578ee11e04b41a278df51c52b0dc8563   \n",
       "\n",
       "                                      commit_message  \\\n",
       "0  pull implementations from the right react-dom ...   \n",
       "1  `react-dom/server-rendering-stub`: restore exp...   \n",
       "2  [Fizz] Reset error component stack and fix err...   \n",
       "3  [Fizz] Reset error component stack and fix err...   \n",
       "4  Move ReactCurrentDispatcher back to shared int...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0        packages/react-dom/server-rendering-stub.js   \n",
       "1        packages/react-dom/server-rendering-stub.js   \n",
       "2  packages/react-dom/src/__tests__/ReactDOMFizzS...   \n",
       "3       packages/react-server/src/ReactFizzServer.js   \n",
       "4     packages/react-server/src/ReactFlightServer.js   \n",
       "\n",
       "                          previous_commit_id  \\\n",
       "0  546178f9109424f6a0176ea8702a7620c4417569\n",
       "   \n",
       "1  16619f106ab5ba8e6aca19d55be46cce22e4a7ff\n",
       "   \n",
       "2  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "3  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "4  ca237d6f0ab986e799f192224d3066f76d66b73b\n",
       "   \n",
       "\n",
       "                               previous_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                    cur_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                                diff    status  \\\n",
       "0  @@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...  modified   \n",
       "1  @@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...  modified   \n",
       "2  @@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...  modified   \n",
       "3  @@ -1110,7 +1110,6 @@ function replaySuspenseB...  modified   \n",
       "4  @@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...  modified   \n",
       "\n",
       "   is_merge_request file_extension  \n",
       "0             False             js  \n",
       "1             False             js  \n",
       "2             False             js  \n",
       "3             False             js  \n",
       "4             False             js  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first row\n",
    "code = subdf.iloc[0].cur_file_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
