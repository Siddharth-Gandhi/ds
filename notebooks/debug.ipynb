{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/2_7/facebook_react/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df = pd.read_parquet(os.path.join(path, 'code_data.parquet'))\n",
    "sub_df = pd.read_parquet(os.path.join(path, 'diff_code_triplets.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    1750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    225310\n",
       "1     61222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>file_path</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) Facebook, Inc. and its a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c22b94f14a809abb376f07a53f36860a7c6a342e</td>\n",
       "      <td>src/renderers/shared/fiber/ReactChildFiber.js</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright 2013-present, Facebook, Inc....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f74eca9937ad6f19b6291d21edfb8747bae88ca</td>\n",
       "      <td>src/renderers/dom/fiber/__tests__/ReactDOMFibe...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright 2013-present, Facebook, Inc....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc24d0ea56b0538d1ac61dc09faedd70ced5bb47</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberRoot.js</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) Facebook, Inc. and its a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberUnwind...</td>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>/**\\n * Copyright (c) 2013-present, Facebook, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  commit_id  \\\n",
       "0  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "1  c22b94f14a809abb376f07a53f36860a7c6a342e   \n",
       "2  1f74eca9937ad6f19b6291d21edfb8747bae88ca   \n",
       "3  cc24d0ea56b0538d1ac61dc09faedd70ced5bb47   \n",
       "4  9bd4d1fae21a6521c185cb114a15ca5dc74d6d9b   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1      src/renderers/shared/fiber/ReactChildFiber.js   \n",
       "2  src/renderers/dom/fiber/__tests__/ReactDOMFibe...   \n",
       "3    packages/react-reconciler/src/ReactFiberRoot.js   \n",
       "4  packages/react-reconciler/src/ReactFiberUnwind...   \n",
       "\n",
       "                                               query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                             passage  label  \n",
       "0  /**\\n * Copyright (c) Facebook, Inc. and its a...      0  \n",
       "1  /**\\n * Copyright 2013-present, Facebook, Inc....      0  \n",
       "2  /**\\n * Copyright 2013-present, Facebook, Inc....      0  \n",
       "3  /**\\n * Copyright (c) Facebook, Inc. and its a...      0  \n",
       "4  /**\\n * Copyright (c) 2013-present, Facebook, ...      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6750 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "for i, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if row['label'] == 0:\n",
    "            assert data[(data['query'] == row['query']) & (data['commit_id'] == row['commit_id']) & (data['file_path'] == row['file_path'])]['label'].values[0] == 0\n",
    "        else:\n",
    "            assert data[(data['query'] == row['query']) & (data['commit_id'] == row['commit_id']) & (data['file_path'] == row['file_path'])]['label'].values[0] == 1\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>file_path</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushPassiveEffects();\\n      return null;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Time;\\n      if (childUpdateExpirationTime &gt; n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n          let msUntilTimeout = computeMsUn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>root. Don't need to schedule a ping because\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgress!== null) {\\n      // Ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Malformed data types (`commitDetails`, `intera...   \n",
       "1  Malformed data types (`commitDetails`, `intera...   \n",
       "2  Malformed data types (`commitDetails`, `intera...   \n",
       "3  Malformed data types (`commitDetails`, `intera...   \n",
       "4  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "2  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "3  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "4  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "\n",
       "                                             passage  label  \n",
       "0      flushPassiveEffects();\\n      return null;...      0  \n",
       "1  Time;\\n      if (childUpdateExpirationTime > n...      0  \n",
       "2   {\\n          let msUntilTimeout = computeMsUn...      0  \n",
       "3   root. Don't need to schedule a ping because\\n...      0  \n",
       "4    if (workInProgress!== null) {\\n      // Ther...      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286532 entries, 0 to 286531\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   query      286532 non-null  object\n",
      " 1   file_path  286532 non-null  object\n",
      " 2   passage    286532 non-null  object\n",
      " 3   label      286532 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    225310\n",
       "1     61222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>file_path</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushPassiveEffects();\\n      return null;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Time;\\n      if (childUpdateExpirationTime &gt; n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n          let msUntilTimeout = computeMsUn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>root. Don't need to schedule a ping because\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgress!== null) {\\n      // Ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>);\\n            return null;\\n         ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>function resolveLocksOnRoot(root: FiberRoot, e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>, try rendering\\n        // at the lower prior...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>{\\n    ReactStrictModeWarnings.discardPending...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>flushRoot(root: FiberRoot, expirationTime: Ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>ity, fn.bind(null, a));\\n  } finally {\\n    wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>pirationTime === expirationTime) {\\n    // The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>pendingPassiveEffectsExpirationTime = expirat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n  // this root.\\n  schedulePendingInteractio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>additional work.\\n    return null;\\n  }\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Root.bind(null, root);\\n    }\\n    case RootSu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.\\n    legacyErrorBoundariesThatAlreadyFailed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>. We just committed the initial mount of\\n    ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Priority:\\n      // TODO: Rename this to compu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>;\\n  }\\n\\n  return expirationTime;\\n}\\n\\nlet l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n      // discrete update per root so we can ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>we can mark a fiber with pending\\n// work wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (node.childExpirationTime &lt; expirationT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>node = node.return;\\n    }\\n  }\\n\\n  if (root...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>// should cancel the previous one. It also rel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Callback.bind(\\n          null,\\n          roo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>Phase!== FlushSyncPhase) {\\n    // We're not i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.timeoutHandle;\\n  if (timeoutHandle!== noTime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>.\\n      // Instead the first renderer will la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n        // single batch.\\n        const curr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>if (workInProgressRootExitStatus === RootInco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>ate;\\n    const returnFiber = workInProgress.r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>}\\n      stopWorkTimer(workInProgress);\\n ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>}\\n      }\\n    } else {\\n      // This ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>next.effectTag &amp;= HostEffectMask;\\n      ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>the root.\\n  if (workInProgressRootExitStatus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>finishes synchronously.\\n  // So we can clear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>\\n        nextEffect.effectTag &amp;= ~Placement;\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Malformed data types (`commitDetails`, `intera...</td>\n",
       "      <td>packages/react-reconciler/src/ReactFiberSchedu...</td>\n",
       "      <td>function commitLayoutEffects(\\n  root: FiberRo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Malformed data types (`commitDetails`, `intera...   \n",
       "1   Malformed data types (`commitDetails`, `intera...   \n",
       "2   Malformed data types (`commitDetails`, `intera...   \n",
       "3   Malformed data types (`commitDetails`, `intera...   \n",
       "4   Malformed data types (`commitDetails`, `intera...   \n",
       "5   Malformed data types (`commitDetails`, `intera...   \n",
       "6   Malformed data types (`commitDetails`, `intera...   \n",
       "7   Malformed data types (`commitDetails`, `intera...   \n",
       "8   Malformed data types (`commitDetails`, `intera...   \n",
       "9   Malformed data types (`commitDetails`, `intera...   \n",
       "10  Malformed data types (`commitDetails`, `intera...   \n",
       "11  Malformed data types (`commitDetails`, `intera...   \n",
       "12  Malformed data types (`commitDetails`, `intera...   \n",
       "13  Malformed data types (`commitDetails`, `intera...   \n",
       "14  Malformed data types (`commitDetails`, `intera...   \n",
       "15  Malformed data types (`commitDetails`, `intera...   \n",
       "16  Malformed data types (`commitDetails`, `intera...   \n",
       "17  Malformed data types (`commitDetails`, `intera...   \n",
       "18  Malformed data types (`commitDetails`, `intera...   \n",
       "19  Malformed data types (`commitDetails`, `intera...   \n",
       "20  Malformed data types (`commitDetails`, `intera...   \n",
       "21  Malformed data types (`commitDetails`, `intera...   \n",
       "22  Malformed data types (`commitDetails`, `intera...   \n",
       "23  Malformed data types (`commitDetails`, `intera...   \n",
       "24  Malformed data types (`commitDetails`, `intera...   \n",
       "25  Malformed data types (`commitDetails`, `intera...   \n",
       "26  Malformed data types (`commitDetails`, `intera...   \n",
       "27  Malformed data types (`commitDetails`, `intera...   \n",
       "28  Malformed data types (`commitDetails`, `intera...   \n",
       "29  Malformed data types (`commitDetails`, `intera...   \n",
       "30  Malformed data types (`commitDetails`, `intera...   \n",
       "31  Malformed data types (`commitDetails`, `intera...   \n",
       "32  Malformed data types (`commitDetails`, `intera...   \n",
       "33  Malformed data types (`commitDetails`, `intera...   \n",
       "34  Malformed data types (`commitDetails`, `intera...   \n",
       "35  Malformed data types (`commitDetails`, `intera...   \n",
       "36  Malformed data types (`commitDetails`, `intera...   \n",
       "37  Malformed data types (`commitDetails`, `intera...   \n",
       "38  Malformed data types (`commitDetails`, `intera...   \n",
       "\n",
       "                                            file_path  \\\n",
       "0   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "1   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "2   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "3   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "4   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "5   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "6   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "7   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "8   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "9   packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "10  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "11  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "12  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "13  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "14  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "15  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "16  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "17  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "18  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "19  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "20  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "21  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "22  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "23  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "24  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "25  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "26  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "27  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "28  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "29  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "30  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "31  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "32  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "33  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "34  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "35  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "36  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "37  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "38  packages/react-reconciler/src/ReactFiberSchedu...   \n",
       "\n",
       "                                              passage  label  \n",
       "0       flushPassiveEffects();\\n      return null;...      0  \n",
       "1   Time;\\n      if (childUpdateExpirationTime > n...      0  \n",
       "2    {\\n          let msUntilTimeout = computeMsUn...      0  \n",
       "3    root. Don't need to schedule a ping because\\n...      0  \n",
       "4     if (workInProgress!== null) {\\n      // Ther...      0  \n",
       "5          );\\n            return null;\\n         ...      0  \n",
       "6   function resolveLocksOnRoot(root: FiberRoot, e...      0  \n",
       "7   , try rendering\\n        // at the lower prior...      0  \n",
       "8    {\\n    ReactStrictModeWarnings.discardPending...      0  \n",
       "9    flushRoot(root: FiberRoot, expirationTime: Ex...      0  \n",
       "10  ity, fn.bind(null, a));\\n  } finally {\\n    wo...      0  \n",
       "11  pirationTime === expirationTime) {\\n    // The...      0  \n",
       "12   pendingPassiveEffectsExpirationTime = expirat...      0  \n",
       "13  \\n  // this root.\\n  schedulePendingInteractio...      0  \n",
       "14   additional work.\\n    return null;\\n  }\\n\\n  ...      0  \n",
       "15  Root.bind(null, root);\\n    }\\n    case RootSu...      0  \n",
       "16  .\\n    legacyErrorBoundariesThatAlreadyFailed ...      0  \n",
       "17  . We just committed the initial mount of\\n    ...      0  \n",
       "18  Priority:\\n      // TODO: Rename this to compu...      0  \n",
       "19  ;\\n  }\\n\\n  return expirationTime;\\n}\\n\\nlet l...      0  \n",
       "20  \\n      // discrete update per root so we can ...      0  \n",
       "21   we can mark a fiber with pending\\n// work wit...      0  \n",
       "22      if (node.childExpirationTime < expirationT...      0  \n",
       "23   node = node.return;\\n    }\\n  }\\n\\n  if (root...      0  \n",
       "24  // should cancel the previous one. It also rel...      0  \n",
       "25  Callback.bind(\\n          null,\\n          roo...      0  \n",
       "26  Phase!== FlushSyncPhase) {\\n    // We're not i...      0  \n",
       "27  .timeoutHandle;\\n  if (timeoutHandle!== noTime...      0  \n",
       "28  .\\n      // Instead the first renderer will la...      0  \n",
       "29  \\n        // single batch.\\n        const curr...      0  \n",
       "30   if (workInProgressRootExitStatus === RootInco...      0  \n",
       "31  ate;\\n    const returnFiber = workInProgress.r...      0  \n",
       "32      }\\n      stopWorkTimer(workInProgress);\\n ...      0  \n",
       "33        }\\n      }\\n    } else {\\n      // This ...      0  \n",
       "34       next.effectTag &= HostEffectMask;\\n      ...      0  \n",
       "35   the root.\\n  if (workInProgressRootExitStatus...      0  \n",
       "36   finishes synchronously.\\n  // So we can clear...      0  \n",
       "37  \\n        nextEffect.effectTag &= ~Placement;\\...      0  \n",
       "38  function commitLayoutEffects(\\n  root: FiberRo...      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    1750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of label column\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTCodeReranker:\n",
    "    def __init__(self, parameters):\n",
    "        self.parameters = parameters\n",
    "        self.model_name = parameters['model_name']\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=1, problem_type='regression')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and parameters['use_gpu'] else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(f'Using device: {self.device}')\n",
    "\n",
    "        # print GPU info\n",
    "        if torch.cuda.is_available() and parameters['use_gpu']:\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f'GPU Device Count: {torch.cuda.device_count()}')\n",
    "            print(f\"GPU Memory Usage: {torch.cuda.memory_allocated(0) / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "\n",
    "        self.psg_len = parameters['psg_len']\n",
    "        self.psg_cnt = parameters['psg_cnt'] # how many contributing_results to use per file for reranking\n",
    "        self.psg_stride = parameters.get('psg_stride', self.psg_len)\n",
    "        self.aggregation_strategy = parameters['aggregation_strategy'] # how to aggregate the scores of the psg_cnt contributing_results\n",
    "        self.batch_size = parameters['batch_size'] # batch size for reranking efficiently\n",
    "        self.rerank_depth = parameters['rerank_depth']\n",
    "        self.max_seq_length = self.tokenizer.model_max_length # max sequence length for the model\n",
    "\n",
    "        print(f\"Initialized Code File BERT reranker with parameters: {parameters}\")\n",
    "\n",
    "\n",
    "    def rerank(self, query, aggregated_results: List[AggregatedSearchResult]):\n",
    "        \"\"\"\n",
    "        Rerank the BM25 aggregated search results using BERT model scores.\n",
    "\n",
    "        query: The issue query string.\n",
    "        aggregated_results: A list of AggregatedSearchResult objects from BM25 search.\n",
    "        \"\"\"\n",
    "        # aggregated_results = aggregated_results[:self.rerank_depth] # already done in the pipeline\n",
    "        # print(f'Reranking {len(aggregated_results)} results')\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        query_passage_pairs, per_result_contribution = self.split_into_query_passage_pairs(query, aggregated_results)\n",
    "\n",
    "\n",
    "        # for agg_result in aggregated_results:\n",
    "        #     query_passage_pairs.extend(\n",
    "        #         (query, result.commit_message)\n",
    "        #         for result in agg_result.contributing_results[: self.psg_cnt]\n",
    "        #     )\n",
    "\n",
    "        if not query_passage_pairs:\n",
    "            print('WARNING: No query passage pairs to rerank, returning original results from previous stage')\n",
    "            print(query, aggregated_results, self.psg_cnt)\n",
    "            return aggregated_results\n",
    "\n",
    "        # tokenize the query passage pairs\n",
    "        encoded_pairs = [self.tokenizer.encode_plus([query, passage], max_length=self.max_seq_length, truncation=True, padding='max_length', return_tensors='pt', add_special_tokens=True) for query, passage in query_passage_pairs]\n",
    "\n",
    "        # create tensors for the input ids, attention masks\n",
    "        input_ids = torch.stack([encoded_pair['input_ids'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "        attention_masks = torch.stack([encoded_pair['attention_mask'].squeeze() for encoded_pair in encoded_pairs], dim=0) # type: ignore\n",
    "\n",
    "        # Create a dataloader for feeding the data to the model\n",
    "        dataset = TensorDataset(input_ids, attention_masks)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False) # shuffle=False very important for reconstructing the results back into the original order\n",
    "\n",
    "        scores = self.get_scores(dataloader, self.model)\n",
    "\n",
    "        score_index = 0\n",
    "        # Now assign the scores to the aggregated results by mapping the scores to the contributing results\n",
    "        for i, agg_result in enumerate(aggregated_results):\n",
    "            # Each aggregated result gets a slice of the scores equal to the number of contributing results it has which should be min(psg_cnt, len(contributing_results))\n",
    "            assert score_index < len(scores), f'score_index {score_index} is greater than or equal to scores length {len(scores)}'\n",
    "            end_index = score_index + per_result_contribution[i] # only use psg_cnt contributing_results\n",
    "            cur_passage_scores = scores[score_index:end_index]\n",
    "            score_index = end_index\n",
    "\n",
    "\n",
    "            # Aggregate the scores for the current aggregated result\n",
    "            agg_score = self.aggregate_scores(cur_passage_scores)\n",
    "            agg_result.score = agg_score  # Assign the aggregated score\n",
    "\n",
    "        assert score_index == len(scores), f'score_index {score_index} does not equal scores length {len(scores)}, indices probably not working correctly'\n",
    "\n",
    "        # Sort by the new aggregated score\n",
    "        aggregated_results.sort(key=lambda res: res.score, reverse=True)\n",
    "\n",
    "        return aggregated_results\n",
    "\n",
    "    def get_scores(self, dataloader, model):\n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                # Unpack the batch and move it to GPU\n",
    "                b_input_ids, b_attention_mask = batch\n",
    "                b_input_ids = b_input_ids.to(self.device)\n",
    "                b_attention_mask = b_attention_mask.to(self.device)\n",
    "\n",
    "                # Get scores from the model\n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_mask)\n",
    "                scores.extend(outputs.logits.detach().cpu().numpy().squeeze(-1))\n",
    "        return scores\n",
    "\n",
    "    def aggregate_scores(self, passage_scores):\n",
    "        \"\"\"\n",
    "        Aggregate passage scores based on the specified strategy.\n",
    "        \"\"\"\n",
    "        if len(passage_scores) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        if self.aggregation_strategy == 'firstp':\n",
    "            return passage_scores[0]\n",
    "        if self.aggregation_strategy == 'maxp':\n",
    "            return max(passage_scores)\n",
    "        if self.aggregation_strategy == 'avgp':\n",
    "            return sum(passage_scores) / len(passage_scores)\n",
    "        if self.aggregation_strategy == 'sump':\n",
    "            return sum(passage_scores)\n",
    "        # else:\n",
    "        raise ValueError(f\"Invalid score aggregation method: {self.aggregation_strategy}\")\n",
    "\n",
    "\n",
    "    def split_into_query_passage_pairs(self, query, aggregated_results):\n",
    "        # Flatten the list of results into a list of (query, passage) pairs but only keep max psg_cnt passages per file\n",
    "        def full_tokenize(s):\n",
    "            return self.tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=True, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()\n",
    "        query_passage_pairs = []\n",
    "        per_result_contribution = []\n",
    "        for agg_result in aggregated_results:\n",
    "            agg_result.contributing_results.sort(key=lambda res: res.commit_date, reverse=True)\n",
    "            # get most recent file version\n",
    "            most_recent_search_result = agg_result.contributing_results[0]\n",
    "            # get the file_path and commit_id\n",
    "            file_path = most_recent_search_result.file_path\n",
    "            commit_id = most_recent_search_result.commit_id\n",
    "            # get the file content from combined_df\n",
    "            file_content = combined_df[(combined_df['commit_id'] == commit_id) & (combined_df['file_path'] == file_path)]['cur_file_content'].values[0]\n",
    "\n",
    "            # now need to split this file content into psg_cnt passages\n",
    "            # first tokenize the file content\n",
    "\n",
    "            # warning these asserts are useless since we are using NaNs\n",
    "            assert file_content is not None, f'file_content is None for commit_id: {commit_id}, file_path: {file_path}'\n",
    "            assert file_path is not None, f'file_path is None for commit_id: {commit_id}'\n",
    "            assert query is not None, f'query is None'\n",
    "\n",
    "            query_tokens = full_tokenize(query)\n",
    "            path_tokens = full_tokenize(file_path)\n",
    "\n",
    "            if pd.isna(file_content):\n",
    "                # if file_content is NaN, then we can just set file_content to empty string\n",
    "                print(f'WARNING: file_content is NaN for commit_id: {commit_id}, file_path: {file_path}, setting file_content to empty string')\n",
    "                file_content = ''\n",
    "\n",
    "            file_tokens = full_tokenize(file_content)\n",
    "\n",
    "\n",
    "            # now split the file content into psg_cnt passages\n",
    "            cur_result_passages = []\n",
    "            # get the input ids\n",
    "            # input_ids = file_content['input_ids'].squeeze()\n",
    "            # get the number of tokens in the file content\n",
    "            total_tokens = len(file_tokens)\n",
    "\n",
    "            for cur_start in range(0, total_tokens, self.psg_stride):\n",
    "                cur_passage = []\n",
    "                # add query tokens and path tokens\n",
    "                # cur_passage.extend(query_tokens) # ??????????????\n",
    "                cur_passage.extend(path_tokens)\n",
    "\n",
    "                # add the file tokens\n",
    "                cur_passage.extend(file_tokens[cur_start:cur_start+self.psg_len])\n",
    "\n",
    "                # now convert cur_passage into a string\n",
    "                cur_passage_decoded = self.tokenizer.decode(cur_passage)\n",
    "\n",
    "                # add the cur_passage to cur_result_passages\n",
    "                cur_result_passages.append(cur_passage_decoded)\n",
    "\n",
    "                if len(cur_result_passages) == self.psg_cnt:\n",
    "                    break\n",
    "\n",
    "            # now add the query, passage pairs to query_passage_pairs\n",
    "            per_result_contribution.append(len(cur_result_passages))\n",
    "            query_passage_pairs.extend((query, passage) for passage in cur_result_passages)\n",
    "        return query_passage_pairs, per_result_contribution\n",
    "\n",
    "    def rerank_pipeline(self, query, aggregated_results):\n",
    "        if len(aggregated_results) == 0:\n",
    "            return aggregated_results\n",
    "        top_results = aggregated_results[:self.rerank_depth]\n",
    "        bottom_results = aggregated_results[self.rerank_depth:]\n",
    "        reranked_results = self.rerank(query, top_results)\n",
    "        min_top_score = reranked_results[-1].score\n",
    "        # now adjust the scores of bottom_results\n",
    "        for i, result in enumerate(bottom_results):\n",
    "            result.score = min_top_score - i - 1\n",
    "        # combine the results\n",
    "        reranked_results.extend(bottom_results)\n",
    "        assert(len(reranked_results) == len(aggregated_results))\n",
    "        return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='../smalldata/ftr/index_commit_tokenized', repo_path='../smalldata/ftr', k=1000, n=100, model_path='microsoft/codebert-base', overwrite_cache=False, batch_size=32, num_epochs=10, learning_rate=5e-05, num_positives=10, num_negatives=10, train_depth=1000, num_workers=8, train_commits=1000, psg_cnt=25, aggregation_strategy='sump', use_gpu=True, rerank_depth=100, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4', overwrite_eval=False, sanity_check=True, debug=False, best_model_path=None, bert_best_model='../data/combined_commit_train/best_model', psg_len=350, psg_stride=250, ignore_gold_in_training=False, eval_folder='code_rerank', use_gpt_train=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../smalldata/ftr/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "metrics = ['MAP', 'P@10', 'P@100', 'P@1000', 'MRR', 'Recall@100', 'Recall@1000']\n",
    "repo_path = args.repo_path\n",
    "repo_name = repo_path.split('/')[-1]\n",
    "index_path = args.index_path\n",
    "K = args.k\n",
    "n = args.n\n",
    "combined_df = get_combined_df(repo_path)\n",
    "BM25_AGGR_STRAT = 'sump'\n",
    "eval_path = os.path.join(repo_path, 'eval')\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "bm25_searcher = BM25Searcher(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "\n",
    "test_path = os.path.join('..', 'gold', 'facebook_react', 'v2_facebook_react_gpt4_gold.parquet')\n",
    "gold_df = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:23<00:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Baseline Evaluation\n",
      "{'MAP': 0.1542, 'P@10': 0.087, 'P@100': 0.0267, 'P@1000': 0.0041, 'MRR': 0.2133, 'Recall@100': 0.5077, 'Recall@1000': 0.6845}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bm25_baseline_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=BM25_AGGR_STRAT)\n",
    "\n",
    "print(\"BM25 Baseline Evaluation\")\n",
    "print(bm25_baseline_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': 5,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': 250,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 476.73 MB\n",
      "Initialized BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 5, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 250, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_path = os.path.join('data', 'combined_commit_train', 'best_model')\n",
    "bert_reranker = BERTReranker(bert_params)\n",
    "bert_reranker.model = AutoModelForSequenceClassification.from_pretrained(args.bert_best_model, num_labels=1, problem_type='regression')\n",
    "bert_reranker.model.to(bert_reranker.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: Quadro RTX 6000\n",
      "GPU Device Count: 1\n",
      "GPU Memory Usage: 953.46 MB\n",
      "Initialized Code File BERT reranker with parameters: {'model_name': 'microsoft/codebert-base', 'psg_cnt': 25, 'aggregation_strategy': 'sump', 'batch_size': 32, 'use_gpu': True, 'rerank_depth': 100, 'num_epochs': 10, 'lr': 5e-05, 'num_positives': 10, 'num_negatives': 10, 'train_depth': 1000, 'num_workers': 8, 'train_commits': 1000, 'bm25_aggr_strategy': 'sump', 'psg_len': 350, 'psg_stride': 250}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'model_name': args.model_path,\n",
    "        'psg_cnt': args.psg_cnt,\n",
    "        'aggregation_strategy': args.aggregation_strategy,\n",
    "        'batch_size': args.batch_size,\n",
    "        'use_gpu': args.use_gpu,\n",
    "        'rerank_depth': args.rerank_depth,\n",
    "        'num_epochs': args.num_epochs,\n",
    "        'lr': args.learning_rate,\n",
    "        'num_positives': args.num_positives,\n",
    "        'num_negatives': args.num_negatives,\n",
    "        'train_depth': args.train_depth,\n",
    "        'num_workers': args.num_workers,\n",
    "        'train_commits': args.train_commits,\n",
    "        'bm25_aggr_strategy': 'sump',\n",
    "        'psg_len': args.psg_len,\n",
    "        'psg_stride': args.psg_stride\n",
    "    }\n",
    "\n",
    "code_reranker = BERTCodeReranker(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerankers = [bert_reranker, code_reranker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output file path not provided, not writing results to file\n",
      "Found gold_df, evaluating on 1 commits\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 1 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   commit_id                 1 non-null      string\n",
      " 1   commit_date               1 non-null      int64 \n",
      " 2   commit_message            1 non-null      string\n",
      " 3   actual_files_modified     1 non-null      object\n",
      " 4   transformed_message_gpt4  1 non-null      object\n",
      "dtypes: int64(1), object(2), string(2)\n",
      "memory usage: 172.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "bert_gold_eval = model_evaluator.evaluate_sampling(n=n, k=K, output_file_path=None, aggregation_strategy=params['aggregation_strategy'], rerankers=rerankers, gold_df=gold_df.iloc[1:2])\n",
    "\n",
    "print(\"BERT Gold Evaluation\")\n",
    "print(bert_gold_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_id</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>file_path</th>\n",
       "      <th>previous_commit_id</th>\n",
       "      <th>previous_file_content</th>\n",
       "      <th>cur_file_content</th>\n",
       "      <th>diff</th>\n",
       "      <th>status</th>\n",
       "      <th>is_merge_request</th>\n",
       "      <th>file_extension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696522497</td>\n",
       "      <td>dddfe688206dafa5646550d351eb9a8e9c53654a</td>\n",
       "      <td>pull implementations from the right react-dom ...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696521194</td>\n",
       "      <td>546178f9109424f6a0176ea8702a7620c4417569</td>\n",
       "      <td>`react-dom/server-rendering-stub`: restore exp...</td>\n",
       "      <td>packages/react-dom/server-rendering-stub.js</td>\n",
       "      <td>16619f106ab5ba8e6aca19d55be46cce22e4a7ff</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-dom/src/__tests__/ReactDOMFizzS...</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696452492</td>\n",
       "      <td>0fba3ecf73900a1b54ed6d3b0617462ac92d2fef</td>\n",
       "      <td>[Fizz] Reset error component stack and fix err...</td>\n",
       "      <td>packages/react-server/src/ReactFizzServer.js</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -1110,7 +1110,6 @@ function replaySuspenseB...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>1696450581</td>\n",
       "      <td>6f132439578ee11e04b41a278df51c52b0dc8563</td>\n",
       "      <td>Move ReactCurrentDispatcher back to shared int...</td>\n",
       "      <td>packages/react-server/src/ReactFlightServer.js</td>\n",
       "      <td>ca237d6f0ab986e799f192224d3066f76d66b73b</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>/**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...</td>\n",
       "      <td>@@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...</td>\n",
       "      <td>modified</td>\n",
       "      <td>False</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      owner repo_name  commit_date                                 commit_id  \\\n",
       "0  facebook     react   1696522497  dddfe688206dafa5646550d351eb9a8e9c53654a   \n",
       "1  facebook     react   1696521194  546178f9109424f6a0176ea8702a7620c4417569   \n",
       "2  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "3  facebook     react   1696452492  0fba3ecf73900a1b54ed6d3b0617462ac92d2fef   \n",
       "4  facebook     react   1696450581  6f132439578ee11e04b41a278df51c52b0dc8563   \n",
       "\n",
       "                                      commit_message  \\\n",
       "0  pull implementations from the right react-dom ...   \n",
       "1  `react-dom/server-rendering-stub`: restore exp...   \n",
       "2  [Fizz] Reset error component stack and fix err...   \n",
       "3  [Fizz] Reset error component stack and fix err...   \n",
       "4  Move ReactCurrentDispatcher back to shared int...   \n",
       "\n",
       "                                           file_path  \\\n",
       "0        packages/react-dom/server-rendering-stub.js   \n",
       "1        packages/react-dom/server-rendering-stub.js   \n",
       "2  packages/react-dom/src/__tests__/ReactDOMFizzS...   \n",
       "3       packages/react-server/src/ReactFizzServer.js   \n",
       "4     packages/react-server/src/ReactFlightServer.js   \n",
       "\n",
       "                          previous_commit_id  \\\n",
       "0  546178f9109424f6a0176ea8702a7620c4417569\n",
       "   \n",
       "1  16619f106ab5ba8e6aca19d55be46cce22e4a7ff\n",
       "   \n",
       "2  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "3  6f132439578ee11e04b41a278df51c52b0dc8563\n",
       "   \n",
       "4  ca237d6f0ab986e799f192224d3066f76d66b73b\n",
       "   \n",
       "\n",
       "                               previous_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                    cur_file_content  \\\n",
       "0  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "1  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "2  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "3  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "4  /**\n",
       " * Copyright (c) Meta Platforms, Inc. and ...   \n",
       "\n",
       "                                                diff    status  \\\n",
       "0  @@ -30,7 +30,10 @@ export {\n",
       " } from './src/ser...  modified   \n",
       "1  @@ -28,3 +28,30 @@ export {\n",
       "   useFormState,\n",
       " ...  modified   \n",
       "2  @@ -981,4 +981,149 @@ describe('ReactDOMFizzSt...  modified   \n",
       "3  @@ -1110,7 +1110,6 @@ function replaySuspenseB...  modified   \n",
       "4  @@ -108,6 +108,7 @@ import {\n",
       " } from 'shared/R...  modified   \n",
       "\n",
       "   is_merge_request file_extension  \n",
       "0             False             js  \n",
       "1             False             js  \n",
       "2             False             js  \n",
       "3             False             js  \n",
       "4             False             js  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first row\n",
    "code = subdf.iloc[0].cur_file_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
