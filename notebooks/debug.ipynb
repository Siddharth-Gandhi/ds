{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils import get_combined_df\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bm25_v2 import BM25Searcher\n",
    "from eval import ModelEvaluator, SearchEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../data/2_7/facebook_react/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 7587973, 'documents': 73765, 'non_empty_documents': 73765, 'unique_terms': 14602}\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Args(\n",
    "    index_path='../data/2_7/facebook_react/index_commit_tokenized', repo_path='../data/2_7/facebook_react', k=1000, n=100, model_path='microsoft/codebert-base', overwrite_cache=False, batch_size=32, num_epochs=10, learning_rate=5e-05, run_name='repr_0.1663', notes='reproducing current best 0.1663 MAP result for CodeReranker', num_positives=10, num_negatives=10, train_depth=1000, num_workers=8, train_commits=1000, psg_cnt=25, aggregation_strategy='sump', use_gpu=True, rerank_depth=100, do_train=True, do_eval=True, eval_gold=True, openai_model='gpt4', overwrite_eval=False, sanity_check=True, debug=False, best_model_path=None, bert_best_model='data/combined_commit_train/best_model', psg_len=350, psg_stride=250, ignore_gold_in_training=False, eval_folder='repr_0.1663', use_gpt_train=True\n",
    ")\n",
    "\n",
    "metrics =['MAP', 'P@1', 'P@10', 'P@20', 'P@30', 'MRR', 'R@1', 'R@10', 'R@100', 'R@1000']\n",
    "repo_path = args.repo_path\n",
    "repo_name = repo_path.split('/')[-1]\n",
    "index_path = args.index_path\n",
    "K = args.k\n",
    "n = args.n\n",
    "combined_df = get_combined_df(repo_path)\n",
    "BM25_AGGR_STRAT = 'sump'\n",
    "eval_path = os.path.join(repo_path, 'eval')\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "bm25_searcher = BM25Searcher(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "\n",
    "test_path = os.path.join('..', 'gold', 'facebook_react', 'v2_facebook_react_gpt4_gold.parquet')\n",
    "gold_df = pd.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = os.path.join(args.repo_path, 'cache', '4X_random_split')\n",
    "code_df = pd.read_parquet(os.path.join(cache_path, 'code_df.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_line(line):\n",
    "        return line.rstrip().lstrip()\n",
    "\n",
    "def parse_diff_remove_minus(diff):\n",
    "    return [\n",
    "        line[1:] if line.startswith('+') else line\n",
    "        for line in diff.split('\\n')\n",
    "        if not (line.startswith('-') or len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "        and len(prep_line(line)) > 2\n",
    "    ]\n",
    "\n",
    "def full_parse_diffs(diff):\n",
    "       # keep both insertions and deletions to be passed to the model\n",
    "        return [\n",
    "            line[1:] if (line.startswith('+') or line.startswith('-')) else line\n",
    "            for line in diff.split('\\n')\n",
    "            if not (len(line) == 0 or (line.startswith('@@') and line.count('@@') > 1))\n",
    "        ]\n",
    "\n",
    "def full_tokenize(s, tokenizer):\n",
    "        return tokenizer.encode_plus(s, max_length=None, truncation=False, return_tensors='pt', add_special_tokens=False, return_attention_mask=False, return_token_type_ids=False)['input_ids'].squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = code_df.iloc[0].SR_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@@ -569,8 +569,6 @@ function resolveLocksOnRoot(root: FiberRoot, expirationTime: ExpirationTime) {\\n     firstBatch._defer &&\\n     firstBatch._expirationTime >= expirationTime\\n   ) {\\n-    root.finishedWork = root.current.alternate;\\n-    root.pendingCommitExpirationTime = expirationTime;\\n     scheduleCallback(NormalPriority, () => {\\n       firstBatch._onComplete();\\n       return null;\\n@@ -689,7 +687,8 @@ export function flushControlled(fn: () => mixed): void {\\n }\\n \\n function prepareFreshStack(root, expirationTime) {\\n-  root.pendingCommitExpirationTime = NoWork;\\n+  root.finishedWork = null;\\n+  root.finishedExpirationTime = NoWork;\\n \\n   const timeoutHandle = root.timeoutHandle;\\n   if (timeoutHandle!== noTimeout) {\\n@@ -741,10 +740,9 @@ function renderRoot(\\n     return null;\\n   }\\n \\n-  if (root.pendingCommitExpirationTime === expirationTime) {\\n+  if (root.finishedExpirationTime === expirationTime) {\\n     // There's already a pending commit at this expiration time.\\n-    root.pendingCommitExpirationTime = NoWork;\\n-    return commitRoot.bind(null, root, expirationTime);\\n+    return commitRoot.bind(null, root);\\n   }\\n \\n   flushPassiveEffects();\\n@@ -867,6 +865,9 @@ function renderRoot(\\n   // something suspended, wait to commit it after a timeout.\\n   stopFinishedWorkLoopTimer();\\n \\n+  root.finishedWork = root.current.alternate;\\n+  root.finishedExpirationTime = expirationTime;\\n+\\n   const isLocked = resolveLocksOnRoot(root, expirationTime);\\n   if (isLocked) {\\n     // This root has a lock that prevents it from committing. Exit. If we begin\\n@@ -905,7 +906,7 @@ function renderRoot(\\n       }\\n       // If we're already rendering synchronously, commit the root in its\\n       // errored state.\\n-      return commitRoot.bind(null, root, expirationTime);\\n+      return commitRoot.bind(null, root);\\n     }\\n     case RootSuspended: {\\n       if (!isSync) {\\n@@ -929,7 +930,7 @@ function renderRoot(\\n             // priority work to do. Instead of committing the fallback\\n             // immediately, wait for more data to arrive.\\n             root.timeoutHandle = scheduleTimeout(\\n-              commitRoot.bind(null, root, expirationTime),\\n+              commitRoot.bind(null, root),\\n               msUntilTimeout,\\n             );\\n             return null;\\n@@ -937,11 +938,11 @@ function renderRoot(\\n         }\\n       }\\n       // The work expired. Commit immediately.\\n-      return commitRoot.bind(null, root, expirationTime);\\n+      return commitRoot.bind(null, root);\\n     }\\n     case RootCompleted: {\\n       // The work completed. Ready to commit.\\n-      return commitRoot.bind(null, root, expirationTime);\\n+      return commitRoot.bind(null, root);\\n     }\\n     default: {\\n       invariant(false, 'Unknown root exit status.');\\n@@ -1223,11 +1224,8 @@ function resetChildExpirationTime(completedWork: Fiber) {\\n   completedWork.childExpirationTime = newChildExpirationTime;\\n }\\n \\n-function commitRoot(root, expirationTime) {\\n-  runWithPriority(\\n-    ImmediatePriority,\\n-    commitRootImpl.bind(null, root, expirationTime),\\n-  );\\n+function commitRoot(root) {\\n+  runWithPriority(ImmediatePriority, commitRootImpl.bind(null, root));\\n   // If there are passive effects, schedule a callback to flush them. This goes\\n   // outside commitRootImpl so that it inherits the priority of the render.\\n   if (rootWithPendingPassiveEffects!== null) {\\n@@ -1240,7 +1238,7 @@ function commitRoot(root, expirationTime) {\\n   return null;\\n }\\n \\n-function commitRootImpl(root, expirationTime) {\\n+function commitRootImpl(root) {\\n   flushPassiveEffects();\\n   flushRenderPhaseStrictModeWarningsInDEV();\\n   flushSuspensePriorityWarningInDEV();\\n@@ -1249,8 +1247,20 @@ function commitRootImpl(root, expirationTime) {\\n     workPhase!== RenderPhase && workPhase!== CommitPhase,\\n     'Should not already be working.',\\n   );\\n-  const finishedWork = root.current.alternate;\\n-  invariant(finishedWork!== null, 'Should have a work-in-progress root.');\\n+\\n+  const finishedWork = root.finishedWork;\\n+  const expirationTime = root.finishedExpirationTime;\\n+  if (finishedWork === null) {\\n+    return null;\\n+  }\\n+  root.finishedWork = null;\\n+  root.finishedExpirationTime = NoWork;\\n+\\n+  invariant(\\n+    finishedWork!== root.current,\\n+    'Cannot commit the same tree as before. This error is likely caused by'+\\n+      'a bug in React. Please file an issue.',\\n+  );\\n \\n   // commitRoot never returns a continuation; it always finishes synchronously.\\n   // So we can clear these now to allow a new callback to be scheduled.\\n@@ -1794,6 +1804,12 @@ export function pingSuspendedRoot(\\n   // Mark the time at which this ping was scheduled.\\n   root.pingTime = suspendedTime;\\n \\n+  if (root.finishedExpirationTime === suspendedTime) {\\n+    // If there's a pending fallback waiting to commit, throw it away.\\n+    root.finishedExpirationTime = NoWork;\\n+    root.finishedWork = null;\\n+  }\\n+\\n   const currentTime = requestCurrentTime();\\n   const priorityLevel = inferPriorityFromExpirationTime(\\n     currentTime,\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(full_tokenize(diff, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_diff_stats(diff):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.train_commit_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    18114\n",
       "1     5862\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_df = pd.read_parquet(os.path.join(cache_path, 'diff_code_triplets.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421828 entries, 0 to 421827\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   query      421828 non-null  object\n",
      " 1   file_path  421828 non-null  object\n",
      " 2   passage    421828 non-null  object\n",
      " 3   label      421828 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "triplets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    328390\n",
       "1     93438\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_paths = [\n",
    "    \"../data/2_7/apache_spark\",\n",
    "    \"../data/2_7/apache_kafka\",\n",
    "    \"../data/2_8/angular_angular\",\n",
    "    \"../data/2_8/django_django\",\n",
    "    \"../data/2_8/pytorch_pytorch\",\n",
    "    \"../data/2_7/julialang_julia\",\n",
    "    \"../data/2_7/ruby_ruby\",\n",
    "    \"../data/2_9/huggingface_transformers\",\n",
    "    \"../data/2_9/redis_redis\",\n",
    "    \"../data/2_7/facebook_react\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for repo in repo_paths:\n",
    "    gold_df_path = os.path.join('..', 'gold', repo, f'v2_{repo}_gpt4_train.parquet')\n",
    "    gold_df = pd.read_parquet(gold_df_path)\n",
    "    dfs.append(gold_df)\n",
    "\n",
    "print(len(dfs))\n",
    "big_gold_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   commit_id                 5000 non-null   string\n",
      " 1   commit_date               5000 non-null   int64 \n",
      " 2   commit_message            5000 non-null   string\n",
      " 3   actual_files_modified     5000 non-null   object\n",
      " 4   transformed_message_gpt4  5000 non-null   object\n",
      "dtypes: int64(1), object(2), string(2)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "big_gold_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_gold_df.to_parquet('merged_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# code_df_list = []\n",
    "# print(repo_paths)\n",
    "# for repo_path in repo_paths:\n",
    "#     repo_name = repo_path.split('/')[-1]\n",
    "#     print(f'processing {repo_name}')\n",
    "#     index_path = os.path.join(repo_path, 'index_commit_tokenized')\n",
    "#     K = args.k\n",
    "#     n = args.n\n",
    "#     combined_df = get_combined_df(repo_path)\n",
    "#     BM25_AGGR_STRAT = 'sump'\n",
    "#     eval_path = os.path.join(repo_path, 'eval')\n",
    "#     if not os.path.exists(eval_path):\n",
    "#         os.makedirs(eval_path)\n",
    "    \n",
    "#     bm25_searcher = BM25Searcher(index_path)\n",
    "#     evaluator = SearchEvaluator(metrics)\n",
    "#     model_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)\n",
    "    \n",
    "#     gold_df_path = os.path.join('..', 'gold', repo_name, f'v2_{repo_name}_gpt4_train.parquet')\n",
    "\n",
    "#     recent_df = pd.read_parquet(gold_df_path)\n",
    "#     recent_df = recent_df.rename(columns={'commit_message': 'original_message', f'transformed_message_{args.openai_model}': 'commit_message'})\n",
    "#     cache_path = f'{repo_name}_code_df.parquet'\n",
    "#     code_df = get_code_df(recent_df, bm25_searcher, args.train_depth, args.num_positives, args.num_negatives, combined_df, cache_path, False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
