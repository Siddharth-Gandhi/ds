{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from pyserini.index.lucene import IndexReader\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "\n",
    "from utils import count_commits, get_combined_df, tokenize, reverse_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult:\n",
    "    def __init__(self, commit_id, file_path, score, commit_date, commit_msg):\n",
    "        self.commit_id = commit_id\n",
    "        self.file_path = file_path\n",
    "        self.score = score\n",
    "        self.commit_date = commit_date\n",
    "        self.commit_msg = commit_msg\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        # return f\"{self.file_path} {self.score:.5f} {self.commit_date}\"\n",
    "        # return f\"{class_name}(score: {self.score:.5f}, file_path: {self.file_path!r}, commit_id: {self.commit_id!r}, commit_date: {self.commit_date})\"\n",
    "        return f\"{class_name}(score={self.score:.5f}, file_path={self.file_path!r}, commit_id={self.commit_id!r}, commit_date={self.commit_date})\"\n",
    "\n",
    "    def is_actual_modified(self, actual_modified_files):\n",
    "        return self.file_path in actual_modified_files\n",
    "\n",
    "    @staticmethod\n",
    "    def print_results(query, search_results, show_only_actual_modified=False):\n",
    "        actual_modified_files = query['actual_files_modified']\n",
    "        for i, result in enumerate(search_results):\n",
    "            if show_only_actual_modified and not result.is_actual_modified(actual_modified_files):\n",
    "                continue\n",
    "            print(f\"{i+1:2} {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatedSearchResult:\n",
    "    def __init__(self, file_path, aggregated_score, contributing_results):\n",
    "        self.file_path = file_path\n",
    "        self.score = aggregated_score\n",
    "        self.contributing_results = contributing_results\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        return f\"{class_name}(file_path={self.file_path!r}, score={self.score}, \" \\\n",
    "               f\"contributing_results={self.contributing_results})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Search:\n",
    "    def __init__(self, index_path):\n",
    "        if not os.path.exists(index_path):\n",
    "            raise FileNotFoundError(f\"Index at {index_path} does not exist!\")\n",
    "        self.searcher = LuceneSearcher(index_path)\n",
    "        print(f\"Loaded index at {index_path}\")\n",
    "        print(f'Index Stats: {IndexReader(index_path).stats()}')\n",
    "        # self.ranking_depth = ranking_depth\n",
    "\n",
    "    def search(self, query, query_date, ranking_depth):\n",
    "        # TODO maybe change this to mean returning reranking_depths total results instead of being pruned by the query date\n",
    "        hits = self.searcher.search(tokenize(query), ranking_depth)\n",
    "        unix_date = query_date\n",
    "        filtered_hits = [\n",
    "            SearchResult(hit.docid, json.loads(hit.raw)['file_path'], hit.score, int(json.loads(hit.raw)[\"commit_date\"]), reverse_tokenize(json.loads(hit.raw)['contents']))\n",
    "            for hit in hits if int(json.loads(hit.raw)[\"commit_date\"]) < unix_date\n",
    "        ]\n",
    "        return filtered_hits\n",
    "\n",
    "    def search_full(self, query, query_date, ranking_depth):\n",
    "        filtered_hits = []\n",
    "        step_size = ranking_depth  # Initial search window\n",
    "        total_hits_retrieved = 0\n",
    "\n",
    "        while len(filtered_hits) < ranking_depth and step_size > 0:\n",
    "            current_hits = self.searcher.search(tokenize(query), total_hits_retrieved + step_size)\n",
    "            if not current_hits:\n",
    "                break  # No more results to retrieve\n",
    "\n",
    "            # Filter hits by query date\n",
    "            for hit in current_hits:\n",
    "                if int(json.loads(hit.raw)[\"commit_date\"]) < query_date:\n",
    "                    filtered_hits.append(\n",
    "                        SearchResult(hit.docid, json.loads(hit.raw)['file_path'], hit.score,\n",
    "                                     int(json.loads(hit.raw)[\"commit_date\"]),\n",
    "                                     reverse_tokenize(json.loads(hit.raw)['contents']))\n",
    "                    )\n",
    "                if len(filtered_hits) == ranking_depth:\n",
    "                    break  # We have enough results\n",
    "\n",
    "            total_hits_retrieved += step_size\n",
    "            step_size = ranking_depth - len(filtered_hits)  # Decrease step size to only get as many as needed\n",
    "\n",
    "        return filtered_hits[:ranking_depth]  # Return up to ranking_depth results\n",
    "\n",
    "    def aggregate_file_scores(self, search_results, aggregation_method='sump'):\n",
    "        # TODO maybe have different aggregation methods\n",
    "        file_to_results = defaultdict(list)\n",
    "        for result in search_results:\n",
    "            file_to_results[result.file_path].append(result)\n",
    "\n",
    "        aggregated_results = []\n",
    "        for file_path, results in file_to_results.items():\n",
    "            # aggregated_score = sum(result.score for result in results)\n",
    "            if aggregation_method == 'sump':\n",
    "                aggregated_score = sum(result.score for result in results)\n",
    "            elif aggregation_method == 'maxp':\n",
    "                aggregated_score = max(result.score for result in results)\n",
    "            # elif aggregation_method == 'firstp':\n",
    "            #     aggregated_score = results[0].score\n",
    "            elif aggregation_method == 'avgp':\n",
    "                aggregated_score = np.mean([result.score for result in results])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown aggregation method {aggregation_method}\")\n",
    "\n",
    "            aggregated_results.append(AggregatedSearchResult(file_path, aggregated_score, results))\n",
    "\n",
    "        aggregated_results.sort(key=lambda result: result.score, reverse=True)\n",
    "        return aggregated_results\n",
    "\n",
    "    def pipeline(self, query, query_date, ranking_depth, aggregation_method='sump'):\n",
    "        search_results = self.search(query, query_date, ranking_depth)\n",
    "        aggregated_results = self.aggregate_file_scores(search_results, aggregation_method)\n",
    "        return aggregated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEvaluator:\n",
    "    def __init__(self, metrics):\n",
    "        self.metrics = metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def precision_at_k(relevant, k):\n",
    "        return sum(relevant[:k]) / k\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_reciprocal_rank(relevant):\n",
    "        for idx, value in enumerate(relevant):\n",
    "            if value == 1:\n",
    "                return 1 / (idx + 1)\n",
    "        return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_average_precision(relevant):\n",
    "        pred_rel = [1] * len(relevant)\n",
    "        relevant_documents_count = 0\n",
    "        cumulative_precision = 0.0\n",
    "\n",
    "        # We iterate through the predicted relevance scores\n",
    "        for i in range(len(pred_rel)):\n",
    "            # Check if the prediction at this rank is correct (i.e., if it is a relevant document)\n",
    "            if pred_rel[i] == 1 and relevant[i] == 1:\n",
    "                relevant_documents_count += 1\n",
    "                precision_at_i = relevant_documents_count / (i + 1)\n",
    "                cumulative_precision += precision_at_i\n",
    "\n",
    "        # The average precision is the cumulative precision divided by the number of relevant documents\n",
    "        average_precision = cumulative_precision / sum(relevant) if sum(relevant) > 0 else 0\n",
    "        return average_precision\n",
    "\n",
    "    # @staticmethod\n",
    "    # def calculate_recall(relevant, total_modified_files, k):\n",
    "    #   # Does not work for commit based approach as it can have multiple mentions of the same file across commits leading to a higher than 1 recall\n",
    "    #     print(total_modified_files)\n",
    "    #     print(relevant)\n",
    "    #     return sum(relevant[:k]) / total_modified_files\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_recall(retrieved_files, actual_modified_files, relevant, k):\n",
    "\n",
    "        return len(list({\n",
    "                        file\n",
    "                        for idx, file in enumerate(retrieved_files)\n",
    "                        if relevant[idx] == 1\n",
    "                    })[:k]) / len(actual_modified_files) if len(actual_modified_files) > 0 else 0\n",
    "\n",
    "\n",
    "    def evaluate(self, search_results, actual_modified_files):\n",
    "        retrieved_files = [result.file_path for result in search_results]\n",
    "        relevant = [1 if file in actual_modified_files else 0 for file in retrieved_files]\n",
    "\n",
    "\n",
    "        evaluations = {}\n",
    "        for metric in self.metrics:\n",
    "            if metric == 'MAP':\n",
    "                evaluations[metric] = self.calculate_average_precision(relevant)\n",
    "            elif metric == 'MRR':\n",
    "                evaluations[metric] = self.mean_reciprocal_rank(relevant)\n",
    "            elif metric.startswith('P@'):\n",
    "                k = int(metric.split('@')[1])\n",
    "                evaluations[metric] = self.precision_at_k(relevant, k)\n",
    "            elif metric.startswith('Recall@'):\n",
    "                k = int(metric.split('@')[1])\n",
    "\n",
    "                # evaluations[metric] = len(list({\n",
    "                #         file\n",
    "                #         for idx, file in enumerate(retrieved_files)\n",
    "                #         if relevant[idx] == 1\n",
    "                #     })[:k]) / len(actual_modified_files)\n",
    "                # evaluations[metric] = self.calculate_recall(relevant, len(actual_modified_files), k) # DOES NOT WORK FOR COMMIT-BASED APPROACH\n",
    "\n",
    "                evaluations[metric] = self.calculate_recall(retrieved_files, actual_modified_files, relevant, k)\n",
    "\n",
    "\n",
    "        return {k: round(v, 4) for k, v in evaluations.items()}\n",
    "\n",
    "    # def evaluate_file_based(self, search_results, actual_modified_files, aggregation_strategy='sump'):\n",
    "    #     file_relevance = defaultdict(list)\n",
    "\n",
    "    #     # Aggregate relevance scores for each file across all commits\n",
    "    #     for result in search_results:\n",
    "    #         if result.file_path in actual_modified_files:\n",
    "    #             # file_relevance[result.file_path] += 1\n",
    "    #             file_relevance[result.file_path].append(result.score)\n",
    "\n",
    "    #     # Normalize relevance scores based on occurrences in actual modified files\n",
    "    #     # max_relevance = max(file_relevance.values(), default=1)\n",
    "    #     # normalized_relevance = {file: relevance / max_relevance for file, relevance in file_relevance.items()}\n",
    "    #     # sorted_normalized_relevance = sorted(normalized_relevance.items(), key=lambda item: item[1], reverse=True)\n",
    "    #     print(file_relevance)\n",
    "    #     if aggregation_strategy == 'sump':\n",
    "    #         aggregated_scores = {file: sum(relevance) for file, relevance in file_relevance.items()}\n",
    "    #     elif aggregation_strategy == 'firstp':\n",
    "    #         aggregated_scores = {file: relevance[0] for file, relevance in file_relevance.items()}\n",
    "    #     elif aggregation_strategy == 'avgp':\n",
    "    #         aggregated_scores = {file: np.mean(relevance) for file, relevance in file_relevance.items()}\n",
    "    #     else:\n",
    "    #         raise ValueError(f\"Unknown aggregation strategy {aggregation_strategy}\")\n",
    "\n",
    "    #     sorted_aggregated_scores = sorted(aggregated_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    #     print(sorted_aggregated_scores)\n",
    "\n",
    "    #     evaluations = {}\n",
    "    #     for metric in self.metrics:\n",
    "    #         if metric.startswith('P@'):\n",
    "    #             # Compute precision at k for files, not individual commit mentions\n",
    "    #             k = int(metric.split('@')[1])\n",
    "    #             # top_k_files = sorted(normalized_relevance.items(), key=lambda item: item[1], reverse=True)[:k]\n",
    "    #             top_k_files = sorted_aggregated_scores[:k]\n",
    "    #             precision_at_k = sum(1 for file, relevance in top_k_files if file in actual_modified_files) / k\n",
    "    #             evaluations[metric] = precision_at_k\n",
    "    #         elif metric.startswith('Recall@'):\n",
    "    #             k = int(metric.split('@')[1])\n",
    "    #             # top_k_files = sorted(normalized_relevance.items(), key=lambda item: item[1], reverse=True)[:k]\n",
    "    #             top_k_files = sorted_aggregated_scores[:k]\n",
    "    #             recall_at_k = sum(1 for file, relevance in top_k_files if file in actual_modified_files) / len(actual_modified_files)\n",
    "    #             evaluations[metric] = recall_at_k\n",
    "    #         elif metric == 'MAP':\n",
    "    #             # Compute average precision for files, not individual commit mentions\n",
    "    #             average_precision = 0\n",
    "    #             num_relevant_files = 0\n",
    "    #             for idx, (file, relevance) in enumerate(sorted_aggregated_scores):\n",
    "    #                 if file in actual_modified_files:\n",
    "    #                     num_relevant_files += 1\n",
    "    #                     average_precision += num_relevant_files / (idx + 1)\n",
    "    #             average_precision /= len(actual_modified_files)\n",
    "    #             evaluations[metric] = average_precision\n",
    "    #         elif metric == 'MRR':\n",
    "    #             # Compute mean reciprocal rank for files, not individual commit mentions\n",
    "    #             reciprocal_rank = 0\n",
    "    #             for idx, (file, relevance) in enumerate(sorted_aggregated_scores):\n",
    "    #                 if file in actual_modified_files:\n",
    "    #                     reciprocal_rank = 1 / (idx + 1)\n",
    "    #                     break\n",
    "    #             evaluations[metric] = reciprocal_rank\n",
    "\n",
    "    #     return {k: round(v, 4) for k, v in evaluations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, eval_model, combined_df, seed=42):\n",
    "        self.model = model\n",
    "        self.eval_model = eval_model\n",
    "        self.combined_df = combined_df\n",
    "        self.seed = seed\n",
    "\n",
    "    def sample_commits(self, n):\n",
    "        if self.combined_df.commit_id.nunique() < n:\n",
    "            raise ValueError(f'Not enough commits to sample. Required: {n}, available: {self.combined_df.commit_id.nunique()}')\n",
    "        return self.combined_df.drop_duplicates(subset='commit_id').sample(n=n, replace=False, random_state=self.seed)\n",
    "\n",
    "    def evaluate_sampling(self, n=100, k=1000, output_dir='.', skip_existing=False, evaluation_strategy='commit', aggregation_strategy='sump'):\n",
    "        model_name = self.model.__class__.__name__\n",
    "        output_file = f\"{output_dir}/{model_name}_metrics.txt\"\n",
    "\n",
    "        if skip_existing and os.path.exists(output_file):\n",
    "            print(f'Output file {output_file} already exists, skipping...')\n",
    "            return\n",
    "\n",
    "        sampled_commits = self.sample_commits(n)\n",
    "\n",
    "        results = []\n",
    "        for _, row in sampled_commits.iterrows():\n",
    "            # search_results = self.model.search(row['commit_message'], row['commit_date'], ranking_depth=k)\n",
    "            search_results = self.model.pipeline(row['commit_message'], row['commit_date'], ranking_depth=k, aggregation_method=aggregation_strategy)\n",
    "            # if evaluation_strategy == 'commit':\n",
    "            evaluation = self.eval_model.evaluate(search_results,\n",
    "                                                       self.combined_df[self.combined_df['commit_id'] == row['commit_id']]['file_path'].tolist())\n",
    "            # elif evaluation_strategy == 'file':\n",
    "            #     evaluation = self.eval_model.evaluate_file_based(search_results,\n",
    "            #                                                       self.combined_df[self.combined_df['commit_id'] == row['commit_id']]['file_path'].tolist(), aggregation_strategy=aggregation_strategy)\n",
    "            # else:\n",
    "            #     raise ValueError(f'Invalid evaluation strategy: {evaluation_strategy}')\n",
    "            results.append(evaluation)\n",
    "\n",
    "        avg_scores = {metric: round(np.mean([result[metric] for result in results]), 4) for metric in results[0]}\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "        with open(output_file, \"w\") as file:\n",
    "            file.write(f\"Model Name: {model_name}\\n\")\n",
    "            file.write(f\"Sample Size: {n}\\n\")\n",
    "            file.write(\"Evaluation Metrics:\\n\")\n",
    "            for key, value in avg_scores.items():\n",
    "                file.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "        return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.4861111111111111\n",
      "MRR: 0.5\n",
      "P@1: 0.0\n",
      "Recall@1: 0.0\n",
      "P@2: 0.5\n",
      "Recall@2: 0.25\n",
      "P@3: 0.3333333333333333\n",
      "Recall@3: 0.25\n",
      "P@4: 0.5\n",
      "Recall@4: 0.5\n",
      "P@5: 0.4\n",
      "Recall@5: 0.5\n",
      "P@6: 0.5\n",
      "Recall@6: 0.75\n",
      "P@7: 0.42857142857142855\n",
      "Recall@7: 0.75\n",
      "P@8: 0.375\n",
      "Recall@8: 0.75\n",
      "P@9: 0.4444444444444444\n",
      "Recall@9: 1.0\n"
     ]
    }
   ],
   "source": [
    "def tmp():\n",
    "    def calculate_recall(relevant, total_modified_files, k):\n",
    "        return sum(relevant[:k]) / total_modified_files\n",
    "\n",
    "    def calculate_average_precision(relevant):\n",
    "        pred_rel = [1] * len(relevant)\n",
    "        relevant_documents_count = 0\n",
    "        cumulative_precision = 0.0\n",
    "\n",
    "        # We iterate through the predicted relevance scores\n",
    "        for i in range(len(pred_rel)):\n",
    "            # Check if the prediction at this rank is correct (i.e., if it is a relevant document)\n",
    "            if pred_rel[i] == 1 and relevant[i] == 1:\n",
    "                relevant_documents_count += 1\n",
    "                precision_at_i = relevant_documents_count / (i + 1)\n",
    "                cumulative_precision += precision_at_i\n",
    "\n",
    "        # The average precision is the cumulative precision divided by the number of relevant documents\n",
    "        average_precision = cumulative_precision / sum(relevant)\n",
    "        return average_precision\n",
    "\n",
    "    def mean_reciprocal_rank(relevant):\n",
    "        for idx, value in enumerate(relevant):\n",
    "            if value == 1:\n",
    "                return 1 / (idx + 1)\n",
    "        return 0\n",
    "\n",
    "    def precision_at_k(relevant, k):\n",
    "        return sum(relevant[:k]) / k\n",
    "\n",
    "    rel = [0,1,0,1,0,1,0,0,1]\n",
    "    k = 3\n",
    "    # print(calculate_recall(rel, 4, k))\n",
    "    print(f'MAP: {calculate_average_precision(rel)}')\n",
    "    print(f'MRR: {mean_reciprocal_rank(rel)}')\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        print(f'P@{k}: {precision_at_k(rel, k)}')\n",
    "        print(f'Recall@{k}: {calculate_recall(rel, sum(rel), k)}')\n",
    "\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = '../smalldata/fbr/index_commit_tokenized'\n",
    "repo_path = '../smalldata/fbr/'\n",
    "K=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../smalldata/fbr/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 8061856, 'documents': 69835, 'non_empty_documents': 69835, 'unique_terms': 14589}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['MAP', 'P@10', 'P@100', 'P@1000', 'MRR', 'Recall@1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_df(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index at ../smalldata/fbr/index_commit_tokenized\n",
      "Index Stats: {'total_terms': 8061856, 'documents': 69835, 'non_empty_documents': 69835, 'unique_terms': 14589}\n"
     ]
    }
   ],
   "source": [
    "bm25_searcher = BM25Search(index_path)\n",
    "evaluator = SearchEvaluator(metrics)\n",
    "bm25_evaluator = ModelEvaluator(bm25_searcher, evaluator, combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_evaluator.evaluate_sampling(n=100, k=K, output_dir='../tmp/', evaluation_strategy='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "owner                                                             facebook\n",
       "repo_name                                                            react\n",
       "commit_date                                                     1541787469\n",
       "commit_id                         1034e26fe5e42ba07492a736da7bdf5bf2108bc6\n",
       "commit_message                                      Fix typos (#14124)\\n\\n\n",
       "file_path                packages/react-dom/src/server/escapeTextForBro...\n",
       "cur_file_content         /**\\n * Copyright (c) Facebook, Inc. and its a...\n",
       "previous_commit_id                5618da49d8cb9cdb6c623446bbd2c504ee6c0422\n",
       "previous_file_path                                                    <NA>\n",
       "previous_file_content    /**\\n * Copyright (c) Facebook, Inc. and its a...\n",
       "diff                     @@ -56,7 +56,7 @@ function escapeHtml(string) ...\n",
       "status                                                            modified\n",
       "is_merge_request                                                     False\n",
       "file_extension                                                          js\n",
       "Name: 50769, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample a commit from the combined_df\n",
    "random_commit = combined_df.sample(1).iloc[0]\n",
    "random_commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(score=10.71162, file_path='packages/react-reconciler/src/ReactChildFiber.js', commit_id='73527237e6eb311de102791bb3fd2922cc28368a', commit_date=1508494517),\n",
       " SearchResult(score=10.71162, file_path='fixtures/dom/src/components/fixtures/text-inputs/index.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71162, file_path='scripts/bench/server.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71161, file_path='scripts/rollup/build.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71161, file_path='scripts/rollup/modules.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71161, file_path='src/renderers/shared/fiber/ReactFiberCompleteWork.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71161, file_path='src/renderers/shared/fiber/ReactFiberContext.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201),\n",
       " SearchResult(score=10.71161, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368),\n",
       " SearchResult(score=10.71161, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368),\n",
       " SearchResult(score=10.71160, file_path='packages/react-reconciler/src/ReactFiberUnwindWork.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368),\n",
       " SearchResult(score=10.71160, file_path='packages/react-reconciler/src/__tests__/ReactIncrementalErrorReplay-test.internal.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368),\n",
       " SearchResult(score=10.52530, file_path='src/test/ReactTestUtils.js', commit_id='510155e027d56ce3cf5c890c9939d894528cf007', commit_date=1464194810),\n",
       " SearchResult(score=10.52530, file_path='src/test/__tests__/ReactTestUtils-test.js', commit_id='510155e027d56ce3cf5c890c9939d894528cf007', commit_date=1464194810),\n",
       " SearchResult(score=9.54770, file_path='src/renderers/dom/server/ReactServerRenderingTransaction.js', commit_id='7b0764b1d255e7d420a7d6d359ec93783076b207', commit_date=1434352365),\n",
       " SearchResult(score=9.41890, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329),\n",
       " SearchResult(score=9.41890, file_path='src/browser/ui/ReactMount.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329),\n",
       " SearchResult(score=9.41890, file_path='src/core/ReactComponent.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329),\n",
       " SearchResult(score=9.41890, file_path='src/utils/OrderedMap.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329),\n",
       " SearchResult(score=8.77120, file_path='src/renderers/dom/server/ReactServerRenderingTransaction.js', commit_id='cfe428e5102b489b3380e45d2c61aa8b4cf5f7d1', commit_date=1434353573),\n",
       " SearchResult(score=8.74300, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='042c6c794c12b9f8d7cc7470736db896a5fc12a3', commit_date=1415380027)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get search results for the random commit\n",
    "search_results = bm25_searcher.search(random_commit['commit_message'], random_commit['commit_date'], ranking_depth=K)\n",
    "search_results[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AggregatedSearchResult(file_path='src/browser/ui/ReactDOMComponent.js', score=41.675281047821045, contributing_results=[SearchResult(score=9.41890, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329), SearchResult(score=8.74300, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='042c6c794c12b9f8d7cc7470736db896a5fc12a3', commit_date=1415380027), SearchResult(score=6.80090, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='0c1eca7dfcf0e4375f7cfe1164823547fee1ad01', commit_date=1426868489), SearchResult(score=6.80090, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='70f16cc936c8e41881b65d58b165fbbf93b5618f', commit_date=1426870969), SearchResult(score=5.56560, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='de1dacdb2887349d09b839bb79d008ae0bf057b0', commit_date=1414025998), SearchResult(score=4.34599, file_path='src/browser/ui/ReactDOMComponent.js', commit_id='af819d122ef79722d150a81d594d63c56c70ff31', commit_date=1428437611)]),\n",
       " AggregatedSearchResult(file_path='packages/react-reconciler/src/ReactFiberScheduler.js', score=41.462069034576416, contributing_results=[SearchResult(score=10.71161, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368), SearchResult(score=7.21030, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='c44665e83278becfe7a3afdf788789536d63387b', commit_date=1522286289), SearchResult(score=5.02016, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='e27720d7f586cdadb00b0de485e41ec4dbcebe52', commit_date=1541617017), SearchResult(score=4.92180, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='ad5273d3488c39a2127d05925d99006b4b5641b2', commit_date=1522190233), SearchResult(score=4.85338, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='7a833dad95b3059ebfdfba44d3fa68e1301d8e6a', commit_date=1522287702), SearchResult(score=4.37245, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='595b4f945b703128af7e65750726c0cbf073ca58', commit_date=1541079106), SearchResult(score=4.37238, file_path='packages/react-reconciler/src/ReactFiberScheduler.js', commit_id='ebdb47d2c137b399b7d9b4468885887961d9cec5', commit_date=1541451897)]),\n",
       " AggregatedSearchResult(file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', score=40.036003828048706, contributing_results=[SearchResult(score=10.71161, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='e0204084a03e04103864ab36df9456c99bd4ae1b', commit_date=1533906368), SearchResult(score=6.79550, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='3553489f7b26fc3cb952321dd21c0b828a375f55', commit_date=1521650304), SearchResult(score=5.02015, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='f777d196e0943b3975c762e15e35b319a9b85902', commit_date=1541534054), SearchResult(score=4.85338, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='7d31311de3e1b3f698dd0fb7a28c40eafe8cca64', commit_date=1521841973), SearchResult(score=4.37242, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='b67c1a2ee1720628c6d47cab977aeb38564d2df6', commit_date=1541543330), SearchResult(score=4.37238, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='ebdb47d2c137b399b7d9b4468885887961d9cec5', commit_date=1541451897), SearchResult(score=3.91057, file_path='packages/react-reconciler/src/ReactFiberCommitWork.js', commit_id='d38616d6936542cbf8ca34d3c75cd3b9e44945c9', commit_date=1521117050)]),\n",
       " AggregatedSearchResult(file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', score=29.611313819885254, contributing_results=[SearchResult(score=6.14780, file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', commit_id='0af384b4c33bf7d039f513e0869665824e08bb6b', commit_date=1521741291), SearchResult(score=6.14780, file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', commit_id='12687ff331e890391e936ad94873e6212d657b6a', commit_date=1521739606), SearchResult(score=6.14779, file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', commit_id='c1308adb4bbe9e5513bbc4499e0696d97e9c897f', commit_date=1521742614), SearchResult(score=6.14778, file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', commit_id='c1b21a746c7d08554eed8bf55030a4049380c32c', commit_date=1522269332), SearchResult(score=5.02015, file_path='packages/react-reconciler/src/ReactFiberClassComponent.js', commit_id='f777d196e0943b3975c762e15e35b319a9b85902', commit_date=1541534054)]),\n",
       " AggregatedSearchResult(file_path='src/core/ReactComponent.js', score=28.972293853759766, contributing_results=[SearchResult(score=9.41890, file_path='src/core/ReactComponent.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329), SearchResult(score=8.74300, file_path='src/core/ReactComponent.js', commit_id='042c6c794c12b9f8d7cc7470736db896a5fc12a3', commit_date=1415380027), SearchResult(score=5.56560, file_path='src/core/ReactComponent.js', commit_id='de1dacdb2887349d09b839bb79d008ae0bf057b0', commit_date=1414025998), SearchResult(score=5.24480, file_path='src/core/ReactComponent.js', commit_id='381a3392c65b00d12ce1dee4ec6dc601aeb46b7e', commit_date=1384800838)]),\n",
       " AggregatedSearchResult(file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', score=27.087392807006836, contributing_results=[SearchResult(score=5.02016, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='e27720d7f586cdadb00b0de485e41ec4dbcebe52', commit_date=1541617017), SearchResult(score=5.02015, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='f777d196e0943b3975c762e15e35b319a9b85902', commit_date=1541534054), SearchResult(score=4.85338, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='15e3dffb4c9ca9b9466f4ef1a6b8b2293d41e9d6', commit_date=1522347362), SearchResult(score=4.37245, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='5afa1c4eda2e5eaa58d72d7937b640b79984a038', commit_date=1541627772), SearchResult(score=3.91063, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='96d38d178ae3956e0eecbde789e3fcf3e487cfea', commit_date=1531140984), SearchResult(score=3.91062, file_path='packages/react-reconciler/src/ReactFiberBeginWork.js', commit_id='9ea4bc6ed607b0bbd2cff7bbdd4608db99490a5f', commit_date=1539527752)]),\n",
       " AggregatedSearchResult(file_path='src/renderers/shared/event/eventPlugins/ResponderEventPlugin.js', score=26.228947639465332, contributing_results=[SearchResult(score=8.74299, file_path='src/renderers/shared/event/eventPlugins/ResponderEventPlugin.js', commit_id='08862734382c72752e4346bf05de6dcee374492d', commit_date=1450017547), SearchResult(score=8.74298, file_path='src/renderers/shared/event/eventPlugins/ResponderEventPlugin.js', commit_id='892352e95d34a536456fdddc698291ccccd45120', commit_date=1447781863), SearchResult(score=8.74298, file_path='src/renderers/shared/event/eventPlugins/ResponderEventPlugin.js', commit_id='ba8c987391a56c68cf1b0d8decd74e19092069c7', commit_date=1447760369)]),\n",
       " AggregatedSearchResult(file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', score=24.208415031433105, contributing_results=[SearchResult(score=6.14779, file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', commit_id='8c20615b06d22e023ff54a30e2602f0409876441', commit_date=1521743557), SearchResult(score=6.14778, file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', commit_id='c1308adb4bbe9e5513bbc4499e0696d97e9c897f', commit_date=1521742614), SearchResult(score=4.09170, file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', commit_id='f114bad09f7a3ddc11265741cb84250fd08d5890', commit_date=1511388911), SearchResult(score=3.91058, file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', commit_id='c039c16f21d7dd5172a3f46d65a4f484543a14ec', commit_date=1530636460), SearchResult(score=3.91056, file_path='packages/react-test-renderer/src/__tests__/ReactShallowRenderer-test.js', commit_id='d430e1358227f316ef41650c8e1b9674de11ab84', commit_date=1526297720)]),\n",
       " AggregatedSearchResult(file_path='src/core/ReactCompositeComponent.js', score=21.41319513320923, contributing_results=[SearchResult(score=5.56560, file_path='src/core/ReactCompositeComponent.js', commit_id='de1dacdb2887349d09b839bb79d008ae0bf057b0', commit_date=1414025998), SearchResult(score=5.49570, file_path='src/core/ReactCompositeComponent.js', commit_id='e707ec0b1ecc61634062e9911eaf974958a449a9', commit_date=1384337272), SearchResult(score=5.24480, file_path='src/core/ReactCompositeComponent.js', commit_id='381a3392c65b00d12ce1dee4ec6dc601aeb46b7e', commit_date=1384800838), SearchResult(score=5.10710, file_path='src/core/ReactCompositeComponent.js', commit_id='14102e8a4851119afe66866735d63d7901ab470f', commit_date=1372115749)]),\n",
       " AggregatedSearchResult(file_path='packages/react-test-renderer/src/ReactShallowRenderer.js', score=20.297855854034424, contributing_results=[SearchResult(score=6.14779, file_path='packages/react-test-renderer/src/ReactShallowRenderer.js', commit_id='8c20615b06d22e023ff54a30e2602f0409876441', commit_date=1521743557), SearchResult(score=6.14778, file_path='packages/react-test-renderer/src/ReactShallowRenderer.js', commit_id='c1308adb4bbe9e5513bbc4499e0696d97e9c897f', commit_date=1521742614), SearchResult(score=4.09170, file_path='packages/react-test-renderer/src/ReactShallowRenderer.js', commit_id='f114bad09f7a3ddc11265741cb84250fd08d5890', commit_date=1511388911), SearchResult(score=3.91058, file_path='packages/react-test-renderer/src/ReactShallowRenderer.js', commit_id='c039c16f21d7dd5172a3f46d65a4f484543a14ec', commit_date=1530636460)]),\n",
       " AggregatedSearchResult(file_path='packages/react-dom/src/__tests__/ReactDOMRoot-test.internal.js', score=19.538753032684326, contributing_results=[SearchResult(score=7.47507, file_path='packages/react-dom/src/__tests__/ReactDOMRoot-test.internal.js', commit_id='5b975411a1258c2747730ee428140a2d01ea673b', commit_date=1515673489), SearchResult(score=7.21030, file_path='packages/react-dom/src/__tests__/ReactDOMRoot-test.internal.js', commit_id='c44665e83278becfe7a3afdf788789536d63387b', commit_date=1522286289), SearchResult(score=4.85338, file_path='packages/react-dom/src/__tests__/ReactDOMRoot-test.internal.js', commit_id='7a833dad95b3059ebfdfba44d3fa68e1301d8e6a', commit_date=1522287702)]),\n",
       " AggregatedSearchResult(file_path='scripts/rollup/build.js', score=18.99479866027832, contributing_results=[SearchResult(score=10.71161, file_path='scripts/rollup/build.js', commit_id='ccb2f82a833710030136909f4601dec00c2e2ddc', commit_date=1506507201), SearchResult(score=4.37240, file_path='scripts/rollup/build.js', commit_id='cf96d840403d3fb38ef3526252a5fbfd820aad67', commit_date=1514056979), SearchResult(score=3.91079, file_path='scripts/rollup/build.js', commit_id='08e32263f9e347a1713bdd6714d7a76d0019991a', commit_date=1533433858)]),\n",
       " AggregatedSearchResult(file_path='src/test/ReactTestUtils.js', score=18.95096206665039, contributing_results=[SearchResult(score=10.52530, file_path='src/test/ReactTestUtils.js', commit_id='510155e027d56ce3cf5c890c9939d894528cf007', commit_date=1464194810), SearchResult(score=4.51510, file_path='src/test/ReactTestUtils.js', commit_id='6d747a742647f6e22790919647af36829e1f06a4', commit_date=1477784579), SearchResult(score=3.91056, file_path='src/test/ReactTestUtils.js', commit_id='d49dfe7da424c87b3ebab7ef664cc34ac2b644f5', commit_date=1477485886)]),\n",
       " AggregatedSearchResult(file_path='packages/react/src/__tests__/createReactClassIntegration-test.js', score=18.443355083465576, contributing_results=[SearchResult(score=6.14780, file_path='packages/react/src/__tests__/createReactClassIntegration-test.js', commit_id='0af384b4c33bf7d039f513e0869665824e08bb6b', commit_date=1521741291), SearchResult(score=6.14778, file_path='packages/react/src/__tests__/createReactClassIntegration-test.js', commit_id='c1308adb4bbe9e5513bbc4499e0696d97e9c897f', commit_date=1521742614), SearchResult(score=6.14778, file_path='packages/react/src/__tests__/createReactClassIntegration-test.js', commit_id='c1b21a746c7d08554eed8bf55030a4049380c32c', commit_date=1522269332)]),\n",
       " AggregatedSearchResult(file_path='src/renderers/dom/server/ReactServerRenderingTransaction.js', score=18.318900108337402, contributing_results=[SearchResult(score=9.54770, file_path='src/renderers/dom/server/ReactServerRenderingTransaction.js', commit_id='7b0764b1d255e7d420a7d6d359ec93783076b207', commit_date=1434352365), SearchResult(score=8.77120, file_path='src/renderers/dom/server/ReactServerRenderingTransaction.js', commit_id='cfe428e5102b489b3380e45d2c61aa8b4cf5f7d1', commit_date=1434353573)]),\n",
       " AggregatedSearchResult(file_path='src/browser/ui/ReactMount.js', score=18.161897659301758, contributing_results=[SearchResult(score=9.41890, file_path='src/browser/ui/ReactMount.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329), SearchResult(score=8.74300, file_path='src/browser/ui/ReactMount.js', commit_id='042c6c794c12b9f8d7cc7470736db896a5fc12a3', commit_date=1415380027)]),\n",
       " AggregatedSearchResult(file_path='src/utils/OrderedMap.js', score=18.161893844604492, contributing_results=[SearchResult(score=9.41890, file_path='src/utils/OrderedMap.js', commit_id='78ec2501cf9d57fa38d3166ceae0e9b7811071c2', commit_date=1415408329), SearchResult(score=8.74300, file_path='src/utils/OrderedMap.js', commit_id='042c6c794c12b9f8d7cc7470736db896a5fc12a3', commit_date=1415380027)]),\n",
       " AggregatedSearchResult(file_path='src/renderers/dom/client/ReactReconcileTransaction.js', score=17.485963821411133, contributing_results=[SearchResult(score=8.74298, file_path='src/renderers/dom/client/ReactReconcileTransaction.js', commit_id='892352e95d34a536456fdddc698291ccccd45120', commit_date=1447781863), SearchResult(score=8.74298, file_path='src/renderers/dom/client/ReactReconcileTransaction.js', commit_id='ba8c987391a56c68cf1b0d8decd74e19092069c7', commit_date=1447760369)]),\n",
       " AggregatedSearchResult(file_path='src/renderers/dom/shared/HTMLDOMPropertyConfig.js', score=17.4859619140625, contributing_results=[SearchResult(score=8.74298, file_path='src/renderers/dom/shared/HTMLDOMPropertyConfig.js', commit_id='892352e95d34a536456fdddc698291ccccd45120', commit_date=1447781863), SearchResult(score=8.74298, file_path='src/renderers/dom/shared/HTMLDOMPropertyConfig.js', commit_id='ba8c987391a56c68cf1b0d8decd74e19092069c7', commit_date=1447760369)]),\n",
       " AggregatedSearchResult(file_path='src/renderers/shared/event/eventPlugins/__tests__/ResponderEventPlugin-test.js', score=17.485958099365234, contributing_results=[SearchResult(score=8.74298, file_path='src/renderers/shared/event/eventPlugins/__tests__/ResponderEventPlugin-test.js', commit_id='892352e95d34a536456fdddc698291ccccd45120', commit_date=1447781863), SearchResult(score=8.74298, file_path='src/renderers/shared/event/eventPlugins/__tests__/ResponderEventPlugin-test.js', commit_id='ba8c987391a56c68cf1b0d8decd74e19092069c7', commit_date=1447760369)])]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_results = bm25_searcher.aggregate_file_scores(search_results)\n",
    "aggregated_results[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 279)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_results), len(aggregated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.0178,\n",
       " 'P@10': 0.0,\n",
       " 'P@100': 0.0,\n",
       " 'P@1000': 0.006,\n",
       " 'MRR': 0.0087,\n",
       " 'Recall@1000': 0.3333}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the search results\n",
    "evaluation = evaluator.evaluate(search_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.1667,\n",
       " 'P@10': 0.1,\n",
       " 'P@100': 0.01,\n",
       " 'P@1000': 0.001,\n",
       " 'MRR': 0.1667,\n",
       " 'Recall@1000': 0.3333}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_based_evaluation = evaluator.evaluate(aggregated_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "file_based_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Search Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_full = bm25_searcher.search_full(random_commit['commit_message'], random_commit['commit_date'], ranking_depth=K)\n",
    "# search_full[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated_results_full = bm25_searcher.aggregate_file_scores(search_full)\n",
    "# aggregated_results_full[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(search_full), len(aggregated_results_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_full = evaluator.evaluate(search_full, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "# evaluation_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_based_evaluation_full = evaluator.evaluate(aggregated_results_full, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "# file_based_evaluation_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Strategy: sump\n",
      "{'MAP': 0.1667, 'P@10': 0.1, 'P@100': 0.01, 'P@1000': 0.001, 'MRR': 0.1667, 'Recall@1000': 0.3333}\n",
      "Aggregation Strategy: maxp\n",
      "{'MAP': 0.0123, 'P@10': 0.0, 'P@100': 0.01, 'P@1000': 0.001, 'MRR': 0.0123, 'Recall@1000': 0.3333}\n",
      "Aggregation Strategy: avgp\n",
      "{'MAP': 0.0112, 'P@10': 0.0, 'P@100': 0.01, 'P@1000': 0.001, 'MRR': 0.0112, 'Recall@1000': 0.3333}\n"
     ]
    }
   ],
   "source": [
    "# test different aggregation strategies in bm25 search\n",
    "agggreagtion_strategies = ['sump', 'maxp', 'avgp']\n",
    "for strategy in agggreagtion_strategies:\n",
    "    print(f\"Aggregation Strategy: {strategy}\")\n",
    "    aggregated_results = bm25_searcher.aggregate_file_scores(search_results, aggregation_method=strategy)\n",
    "    evaluation = evaluator.evaluate(aggregated_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "    print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.2037,\n",
       " 'P@10': 0.074,\n",
       " 'P@100': 0.0202,\n",
       " 'P@1000': 0.0027,\n",
       " 'MRR': 0.2746,\n",
       " 'Recall@1000': 0.6351}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_evaluator.evaluate_sampling(n=100, k=K, output_dir='../tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Strategy: sump\n",
      "{'MAP': 0.0272, 'P@10': 0.074, 'P@100': 0.0202, 'P@1000': 0.0027, 'MRR': 0.2746, 'Recall@1000': 0.6351}\n",
      "Aggregation Strategy: maxp\n",
      "{'MAP': 0.0272, 'P@10': 0.06, 'P@100': 0.0181, 'P@1000': 0.0027, 'MRR': 0.2688, 'Recall@1000': 0.6351}\n",
      "Aggregation Strategy: avgp\n",
      "{'MAP': 0.0272, 'P@10': 0.048, 'P@100': 0.0149, 'P@1000': 0.0027, 'MRR': 0.1968, 'Recall@1000': 0.6351}\n"
     ]
    }
   ],
   "source": [
    "for strategy in agggreagtion_strategies:\n",
    "    print(f\"Aggregation Strategy: {strategy}\")\n",
    "    results = bm25_evaluator.evaluate_sampling(n=100, k=K, output_dir='../tmp/', evaluation_strategy='file', aggregation_strategy=strategy)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMP seems to be the best aggregation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_based_evaluation = evaluator.evaluate_file_based(search_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "# file_based_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate over the list of aggregation strategies and evaluate each one\n",
    "\n",
    "# aggregation_strategies = ['sump', 'maxp', 'firstp', 'avgp']\n",
    "# for strategy in aggregation_strategies:\n",
    "#     file_based_evaluation = evaluator.evaluate_file_based(search_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist(), aggregation_strategy=strategy)\n",
    "#     print(f\"{strategy}: {file_based_evaluation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do the same for the model evaluator\n",
    "# for strategy in aggregation_strategies:\n",
    "#     model_evaluation = bm25_evaluator.evaluate_sampling(n=1000, k=K, output_dir='../tmp/', evaluation_strategy='file', aggregation_strategy=strategy)\n",
    "#     print(f\"{strategy}: {model_evaluation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from collections import defaultdict\n",
    "\n",
    "class BERTReRanker:\n",
    "    \"\"\"\n",
    "    A class for performing reranking with a BERT-based model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, psgLen=128, psgStride=64, psgCnt=None, scoreAggregation='maxp', batchSize=8):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "\n",
    "        # Passage handling parameters\n",
    "        self.psgLen = psgLen\n",
    "        self.psgStride = psgStride\n",
    "        self.psgCnt = psgCnt\n",
    "        self.scoreAggregation = scoreAggregation\n",
    "\n",
    "        if self.scoreAggregation == 'firstp':\n",
    "            self.psgCnt = 1\n",
    "\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def rerank(self, query, search_results):\n",
    "        \"\"\"\n",
    "        Rerank the search results using the BERT model.\n",
    "\n",
    "        query: The query string.\n",
    "        search_results: A list of SearchResult objects.\n",
    "        \"\"\"\n",
    "        reranked_results = []\n",
    "        # todo - add batching\n",
    "\n",
    "        # Process each SearchResult to create input for BERT\n",
    "        for result in search_results:\n",
    "            passages = self._split_into_passages(query, result.commit_msg)\n",
    "\n",
    "            # Score each passage with BERT\n",
    "            passage_scores = [self._score_passage(query, passage) for passage in passages]\n",
    "\n",
    "            # Aggregate passage scores to get a single document score\n",
    "            doc_score = self._aggregate_scores(passage_scores)\n",
    "\n",
    "            # Create a new SearchResult with the updated score\n",
    "            reranked_results.append((doc_score, result))\n",
    "\n",
    "        # Sort reranked results by the new score\n",
    "        reranked_results.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [result for _, result in reranked_results]\n",
    "\n",
    "    def _split_into_passages(self, query, commit_msg):\n",
    "        # Tokenize the query and commit message\n",
    "        tokens = self.tokenizer.tokenize(query) + self.tokenizer.tokenize(commit_msg)\n",
    "\n",
    "        # Split the tokens into passages\n",
    "        passages = []\n",
    "        for i in range(0, len(tokens), self.psgStride):\n",
    "            passage = tokens[i:i+self.psgLen]\n",
    "            passages.append(self.tokenizer.convert_tokens_to_string(passage))\n",
    "            if self.psgCnt and len(passages) >= self.psgCnt:\n",
    "                break\n",
    "        return passages\n",
    "\n",
    "    def _score_passage(self, query, passage):\n",
    "        # Encode query and passage for BERT\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            query,\n",
    "            passage,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.psgLen,\n",
    "            truncation=\"only_second\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Score the (query, passage) pair with BERT\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            score = outputs.logits.squeeze().item()\n",
    "        return score\n",
    "\n",
    "    def _aggregate_scores(self, passage_scores):\n",
    "        # Aggregate passage scores based on the specified strategy\n",
    "        if self.scoreAggregation == 'firstp':\n",
    "            return passage_scores[0]\n",
    "        elif self.scoreAggregation == 'maxp':\n",
    "            return max(passage_scores)\n",
    "        elif self.scoreAggregation == 'avgp':\n",
    "            return sum(passage_scores) / len(passage_scores)\n",
    "        elif self.scoreAggregation == 'sump':\n",
    "            return sum(passage_scores)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid score aggregation method: {self.scoreAggregation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Assuming bm25_searcher is an instance of BM25Search\n",
    "query = \"Fix login page error\"\n",
    "query_date = 1699261235\n",
    "bm25_results = bm25_search.search(query, query_date, K)\n",
    "\n",
    "# Now rerank those results with BERT\n",
    "bert_reranker = BERTReRanker(model_name=\"bert-base-uncased\")\n",
    "reranked_results = bert_reranker.rerank(query, bm25_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(score: 2.69137, file_path: 'packages/react-reconciler/src/ReactFiberBeginWork.new.js', commit_id: '1faf9e3dd5d6492f3607d5c721055819e4106bc6', commit_date: 1601495853),\n",
       " SearchResult(score: 2.69136, file_path: 'packages/react-reconciler/src/ReactFiberBeginWork.old.js', commit_id: '1faf9e3dd5d6492f3607d5c721055819e4106bc6', commit_date: 1601495853),\n",
       " SearchResult(score: 2.69136, file_path: 'packages/react-reconciler/src/ReactFiberSuspenseComponent.new.js', commit_id: '1faf9e3dd5d6492f3607d5c721055819e4106bc6', commit_date: 1601495853),\n",
       " SearchResult(score: 2.69136, file_path: 'packages/react-reconciler/src/ReactFiberSuspenseComponent.old.js', commit_id: '1faf9e3dd5d6492f3607d5c721055819e4106bc6', commit_date: 1601495853),\n",
       " SearchResult(score: 2.69136, file_path: 'packages/react-reconciler/src/__tests__/ReactCPUSuspense-test.js', commit_id: '1faf9e3dd5d6492f3607d5c721055819e4106bc6', commit_date: 1601495853),\n",
       " SearchResult(score: 3.26617, file_path: 'packages/react-dom-bindings/src/client/ReactFiberConfigDOM.js', commit_id: '8b26f07a883bb341c20283c0099bf5ee6f87bd1f', commit_date: 1694117144),\n",
       " SearchResult(score: 3.26617, file_path: 'packages/react-dom-bindings/src/server/ReactFizzConfigDOM.js', commit_id: '8b26f07a883bb341c20283c0099bf5ee6f87bd1f', commit_date: 1694117144),\n",
       " SearchResult(score: 3.26617, file_path: 'packages/react-dom-bindings/src/server/ReactFizzConfigDOMLegacy.js', commit_id: '8b26f07a883bb341c20283c0099bf5ee6f87bd1f', commit_date: 1694117144),\n",
       " SearchResult(score: 3.26617, file_path: 'packages/react-dom/src/__tests__/ReactDOMFizzServer-test.js', commit_id: '8b26f07a883bb341c20283c0099bf5ee6f87bd1f', commit_date: 1694117144),\n",
       " SearchResult(score: 3.26617, file_path: 'packages/react-reconciler/src/ReactFiberConfigWithNoHydration.js', commit_id: '8b26f07a883bb341c20283c0099bf5ee6f87bd1f', commit_date: 1694117144)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 10 results\n",
    "reranked_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.016,\n",
       " 'P@10': 0.0,\n",
       " 'P@100': 0.0,\n",
       " 'P@1000': 0.016,\n",
       " 'MRR': 0.0031,\n",
       " 'Recall@1000': 0.3913}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the reranked results\n",
    "evaluation = evaluator.evaluate(reranked_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'packages/react-reconciler/src/ReactFiberCompleteWork.js': [2.718986988067627, 3.8634390830993652, 3.863529920578003, 4.273975372314453], 'packages/shared/ReactSymbols.js': [3.5164780616760254], 'packages/shared/ReactTypes.js': [3.6565749645233154, 3.8633739948272705, 3.863521099090576], 'scripts/rollup/bundles.js': [4.612883567810059, 5.564578056335449, 2.7962939739227295], 'packages/react-dom/src/shared/assertValidProps.js': [5.564676284790039], 'packages/react-dom/src/events/DOMEventResponderSystem.js': [3.8635449409484863], 'packages/react-dom/src/events/__tests__/DOMEventResponderSystem-test.internal.js': [3.86354398727417], 'packages/react-events/src/FocusScope.js': [3.863539934158325], 'packages/shared/getComponentName.js': [3.8635189533233643]})\n",
      "[('packages/react-reconciler/src/ReactFiberCompleteWork.js', 14.719931364059448), ('scripts/rollup/bundles.js', 12.973755598068237), ('packages/shared/ReactTypes.js', 11.383470058441162), ('packages/react-dom/src/shared/assertValidProps.js', 5.564676284790039), ('packages/react-dom/src/events/DOMEventResponderSystem.js', 3.8635449409484863), ('packages/react-dom/src/events/__tests__/DOMEventResponderSystem-test.internal.js', 3.86354398727417), ('packages/react-events/src/FocusScope.js', 3.863539934158325), ('packages/shared/getComponentName.js', 3.8635189533233643), ('packages/shared/ReactSymbols.js', 3.5164780616760254)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': 0.3913,\n",
       " 'P@10': 0.9,\n",
       " 'P@100': 0.09,\n",
       " 'P@1000': 0.009,\n",
       " 'MRR': 1.0,\n",
       " 'Recall@1000': 0.3913}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = evaluator.evaluate_file_based(reranked_results, combined_df[combined_df['commit_id'] == random_commit['commit_id']]['file_path'].tolist())\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'MAP': 0.0546,\n",
    " 'P@10': 0.0,\n",
    " 'P@100': 0.05,\n",
    " 'P@1000': 0.019,\n",
    " 'MRR': 0.0119,\n",
    " 'Recall@1000': 0.3478}\n",
    "\n",
    "{'MAP': 0.3478,\n",
    " 'P@10': 0.8,\n",
    " 'P@100': 0.08,\n",
    " 'P@1000': 0.008,\n",
    " 'MRR': 1.0,\n",
    " 'Recall@1000': 0.3478}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
